{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import pandas as pd\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence \n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection   import KFold, StratifiedKFold, cross_val_score,train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix,f1_score\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.externals.joblib import parallel_backend\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code interview.\n",
    "\n",
    "## Description of the task\n",
    "\n",
    "Given the movie database hosted in Kaggle,\n",
    "\n",
    "https://www.kaggle.com/tmdb/tmdb-movie-metadata\n",
    "\n",
    " \n",
    "\n",
    "We are interested in the task of predicting movie genres based on their title and overview (plot summary). For this you can employ any programming language (R, python, etc) that you feel comfortable with, and any NLP technique. We will focus on correctness of the approach, clarity of the code, comments and plots, over the performance obtained with the selected technique. You can submit your solution in plain source code, notebook file or github repository. Your solution should load the movie database, create train/val/test or cross-validation splits, train the genre classifier and evaluate the accuracy.\n",
    "\n",
    " \n",
    "\n",
    "Since movies can be classified into multiple genres, this is a multi-label problem. Can you explain what are the common approaches to multi-label classification problems? How do you evaluate the accuracy of a multi-label classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>keywords</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.avatarmovie.com/</td>\n",
       "      <td>19995</td>\n",
       "      <td>[{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...</td>\n",
       "      <td>en</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
       "      <td>150.437577</td>\n",
       "      <td>[{\"name\": \"Ingenious Film Partners\", \"id\": 289...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2009-12-10</td>\n",
       "      <td>2787965087</td>\n",
       "      <td>162.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Enter the World of Pandora.</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>7.2</td>\n",
       "      <td>11800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300000000</td>\n",
       "      <td>[{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...</td>\n",
       "      <td>http://disney.go.com/disneypictures/pirates/</td>\n",
       "      <td>285</td>\n",
       "      <td>[{\"id\": 270, \"name\": \"ocean\"}, {\"id\": 726, \"na...</td>\n",
       "      <td>en</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>Captain Barbossa, long believed to be dead, ha...</td>\n",
       "      <td>139.082615</td>\n",
       "      <td>[{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2007-05-19</td>\n",
       "      <td>961000000</td>\n",
       "      <td>169.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>At the end of the world, the adventure begins.</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>245000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.sonypictures.com/movies/spectre/</td>\n",
       "      <td>206647</td>\n",
       "      <td>[{\"id\": 470, \"name\": \"spy\"}, {\"id\": 818, \"name...</td>\n",
       "      <td>en</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>A cryptic message from Bondâ€™s past sends him o...</td>\n",
       "      <td>107.376788</td>\n",
       "      <td>[{\"name\": \"Columbia Pictures\", \"id\": 5}, {\"nam...</td>\n",
       "      <td>[{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...</td>\n",
       "      <td>2015-10-26</td>\n",
       "      <td>880674609</td>\n",
       "      <td>148.0</td>\n",
       "      <td>[{\"iso_639_1\": \"fr\", \"name\": \"Fran\\u00e7ais\"},...</td>\n",
       "      <td>Released</td>\n",
       "      <td>A Plan No One Escapes</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>6.3</td>\n",
       "      <td>4466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...</td>\n",
       "      <td>http://www.thedarkknightrises.com/</td>\n",
       "      <td>49026</td>\n",
       "      <td>[{\"id\": 849, \"name\": \"dc comics\"}, {\"id\": 853,...</td>\n",
       "      <td>en</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>Following the death of District Attorney Harve...</td>\n",
       "      <td>112.312950</td>\n",
       "      <td>[{\"name\": \"Legendary Pictures\", \"id\": 923}, {\"...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2012-07-16</td>\n",
       "      <td>1084939099</td>\n",
       "      <td>165.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>The Legend Ends</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>260000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://movies.disney.com/john-carter</td>\n",
       "      <td>49529</td>\n",
       "      <td>[{\"id\": 818, \"name\": \"based on novel\"}, {\"id\":...</td>\n",
       "      <td>en</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>John Carter is a war-weary, former military ca...</td>\n",
       "      <td>43.926995</td>\n",
       "      <td>[{\"name\": \"Walt Disney Pictures\", \"id\": 2}]</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2012-03-07</td>\n",
       "      <td>284139100</td>\n",
       "      <td>132.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Lost in our world, found in another.</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>258000000</td>\n",
       "      <td>[{\"id\": 14, \"name\": \"Fantasy\"}, {\"id\": 28, \"na...</td>\n",
       "      <td>http://www.sonypictures.com/movies/spider-man3/</td>\n",
       "      <td>559</td>\n",
       "      <td>[{\"id\": 851, \"name\": \"dual identity\"}, {\"id\": ...</td>\n",
       "      <td>en</td>\n",
       "      <td>Spider-Man 3</td>\n",
       "      <td>The seemingly invincible Spider-Man goes up ag...</td>\n",
       "      <td>115.699814</td>\n",
       "      <td>[{\"name\": \"Columbia Pictures\", \"id\": 5}, {\"nam...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2007-05-01</td>\n",
       "      <td>890871626</td>\n",
       "      <td>139.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>The battle within.</td>\n",
       "      <td>Spider-Man 3</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>260000000</td>\n",
       "      <td>[{\"id\": 16, \"name\": \"Animation\"}, {\"id\": 10751...</td>\n",
       "      <td>http://disney.go.com/disneypictures/tangled/</td>\n",
       "      <td>38757</td>\n",
       "      <td>[{\"id\": 1562, \"name\": \"hostage\"}, {\"id\": 2343,...</td>\n",
       "      <td>en</td>\n",
       "      <td>Tangled</td>\n",
       "      <td>When the kingdom's most wanted-and most charmi...</td>\n",
       "      <td>48.681969</td>\n",
       "      <td>[{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2010-11-24</td>\n",
       "      <td>591794936</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>They're taking adventure to new lengths.</td>\n",
       "      <td>Tangled</td>\n",
       "      <td>7.4</td>\n",
       "      <td>3330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>280000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://marvel.com/movies/movie/193/avengers_ag...</td>\n",
       "      <td>99861</td>\n",
       "      <td>[{\"id\": 8828, \"name\": \"marvel comic\"}, {\"id\": ...</td>\n",
       "      <td>en</td>\n",
       "      <td>Avengers: Age of Ultron</td>\n",
       "      <td>When Tony Stark tries to jumpstart a dormant p...</td>\n",
       "      <td>134.279229</td>\n",
       "      <td>[{\"name\": \"Marvel Studios\", \"id\": 420}, {\"name...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2015-04-22</td>\n",
       "      <td>1405403694</td>\n",
       "      <td>141.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>A New Age Has Come.</td>\n",
       "      <td>Avengers: Age of Ultron</td>\n",
       "      <td>7.3</td>\n",
       "      <td>6767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>250000000</td>\n",
       "      <td>[{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...</td>\n",
       "      <td>http://harrypotter.warnerbros.com/harrypottera...</td>\n",
       "      <td>767</td>\n",
       "      <td>[{\"id\": 616, \"name\": \"witch\"}, {\"id\": 2343, \"n...</td>\n",
       "      <td>en</td>\n",
       "      <td>Harry Potter and the Half-Blood Prince</td>\n",
       "      <td>As Harry begins his sixth year at Hogwarts, he...</td>\n",
       "      <td>98.885637</td>\n",
       "      <td>[{\"name\": \"Warner Bros.\", \"id\": 6194}, {\"name\"...</td>\n",
       "      <td>[{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...</td>\n",
       "      <td>2009-07-07</td>\n",
       "      <td>933959197</td>\n",
       "      <td>153.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Dark Secrets Revealed</td>\n",
       "      <td>Harry Potter and the Half-Blood Prince</td>\n",
       "      <td>7.4</td>\n",
       "      <td>5293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>250000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.batmanvsupermandawnofjustice.com/</td>\n",
       "      <td>209112</td>\n",
       "      <td>[{\"id\": 849, \"name\": \"dc comics\"}, {\"id\": 7002...</td>\n",
       "      <td>en</td>\n",
       "      <td>Batman v Superman: Dawn of Justice</td>\n",
       "      <td>Fearing the actions of a god-like Super Hero l...</td>\n",
       "      <td>155.790452</td>\n",
       "      <td>[{\"name\": \"DC Comics\", \"id\": 429}, {\"name\": \"A...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2016-03-23</td>\n",
       "      <td>873260194</td>\n",
       "      <td>151.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Justice or revenge</td>\n",
       "      <td>Batman v Superman: Dawn of Justice</td>\n",
       "      <td>5.7</td>\n",
       "      <td>7004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>270000000</td>\n",
       "      <td>[{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...</td>\n",
       "      <td>http://www.superman.com</td>\n",
       "      <td>1452</td>\n",
       "      <td>[{\"id\": 83, \"name\": \"saving the world\"}, {\"id\"...</td>\n",
       "      <td>en</td>\n",
       "      <td>Superman Returns</td>\n",
       "      <td>Superman returns to discover his 5-year absenc...</td>\n",
       "      <td>57.925623</td>\n",
       "      <td>[{\"name\": \"DC Comics\", \"id\": 429}, {\"name\": \"L...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2006-06-28</td>\n",
       "      <td>391081192</td>\n",
       "      <td>154.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Superman Returns</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>200000000</td>\n",
       "      <td>[{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 28, \"...</td>\n",
       "      <td>http://www.mgm.com/view/movie/234/Quantum-of-S...</td>\n",
       "      <td>10764</td>\n",
       "      <td>[{\"id\": 627, \"name\": \"killing\"}, {\"id\": 1568, ...</td>\n",
       "      <td>en</td>\n",
       "      <td>Quantum of Solace</td>\n",
       "      <td>Quantum of Solace continues the adventures of ...</td>\n",
       "      <td>107.928811</td>\n",
       "      <td>[{\"name\": \"Eon Productions\", \"id\": 7576}]</td>\n",
       "      <td>[{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...</td>\n",
       "      <td>2008-10-30</td>\n",
       "      <td>586090727</td>\n",
       "      <td>106.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>For love, for hate, for justice, for revenge.</td>\n",
       "      <td>Quantum of Solace</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>200000000</td>\n",
       "      <td>[{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...</td>\n",
       "      <td>http://disney.go.com/disneypictures/pirates/</td>\n",
       "      <td>58</td>\n",
       "      <td>[{\"id\": 616, \"name\": \"witch\"}, {\"id\": 663, \"na...</td>\n",
       "      <td>en</td>\n",
       "      <td>Pirates of the Caribbean: Dead Man's Chest</td>\n",
       "      <td>Captain Jack Sparrow works his way out of a bl...</td>\n",
       "      <td>145.847379</td>\n",
       "      <td>[{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...</td>\n",
       "      <td>[{\"iso_3166_1\": \"JM\", \"name\": \"Jamaica\"}, {\"is...</td>\n",
       "      <td>2006-06-20</td>\n",
       "      <td>1065659812</td>\n",
       "      <td>151.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Jack is back!</td>\n",
       "      <td>Pirates of the Caribbean: Dead Man's Chest</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>255000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://disney.go.com/the-lone-ranger/</td>\n",
       "      <td>57201</td>\n",
       "      <td>[{\"id\": 1556, \"name\": \"texas\"}, {\"id\": 2673, \"...</td>\n",
       "      <td>en</td>\n",
       "      <td>The Lone Ranger</td>\n",
       "      <td>The Texas Rangers chase down a gang of outlaws...</td>\n",
       "      <td>49.046956</td>\n",
       "      <td>[{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2013-07-03</td>\n",
       "      <td>89289910</td>\n",
       "      <td>149.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Never Take Off the Mask</td>\n",
       "      <td>The Lone Ranger</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>225000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.manofsteel.com/</td>\n",
       "      <td>49521</td>\n",
       "      <td>[{\"id\": 83, \"name\": \"saving the world\"}, {\"id\"...</td>\n",
       "      <td>en</td>\n",
       "      <td>Man of Steel</td>\n",
       "      <td>A young boy learns that he has extraordinary p...</td>\n",
       "      <td>99.398009</td>\n",
       "      <td>[{\"name\": \"Legendary Pictures\", \"id\": 923}, {\"...</td>\n",
       "      <td>[{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...</td>\n",
       "      <td>2013-06-12</td>\n",
       "      <td>662845518</td>\n",
       "      <td>143.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>You will believe that a man can fly.</td>\n",
       "      <td>Man of Steel</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>225000000</td>\n",
       "      <td>[{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 10751...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2454</td>\n",
       "      <td>[{\"id\": 818, \"name\": \"based on novel\"}, {\"id\":...</td>\n",
       "      <td>en</td>\n",
       "      <td>The Chronicles of Narnia: Prince Caspian</td>\n",
       "      <td>One year after their incredible adventures in ...</td>\n",
       "      <td>53.978602</td>\n",
       "      <td>[{\"name\": \"Walt Disney\", \"id\": 5888}, {\"name\":...</td>\n",
       "      <td>[{\"iso_3166_1\": \"CZ\", \"name\": \"Czech Republic\"...</td>\n",
       "      <td>2008-05-15</td>\n",
       "      <td>419651413</td>\n",
       "      <td>150.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Hope has a new face.</td>\n",
       "      <td>The Chronicles of Narnia: Prince Caspian</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>220000000</td>\n",
       "      <td>[{\"id\": 878, \"name\": \"Science Fiction\"}, {\"id\"...</td>\n",
       "      <td>http://marvel.com/avengers_movie/</td>\n",
       "      <td>24428</td>\n",
       "      <td>[{\"id\": 242, \"name\": \"new york\"}, {\"id\": 5539,...</td>\n",
       "      <td>en</td>\n",
       "      <td>The Avengers</td>\n",
       "      <td>When an unexpected enemy emerges and threatens...</td>\n",
       "      <td>144.448633</td>\n",
       "      <td>[{\"name\": \"Paramount Pictures\", \"id\": 4}, {\"na...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2012-04-25</td>\n",
       "      <td>1519557910</td>\n",
       "      <td>143.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Some assembly required.</td>\n",
       "      <td>The Avengers</td>\n",
       "      <td>7.4</td>\n",
       "      <td>11776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>380000000</td>\n",
       "      <td>[{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 28, \"...</td>\n",
       "      <td>http://disney.go.com/pirates/index-on-stranger...</td>\n",
       "      <td>1865</td>\n",
       "      <td>[{\"id\": 658, \"name\": \"sea\"}, {\"id\": 1316, \"nam...</td>\n",
       "      <td>en</td>\n",
       "      <td>Pirates of the Caribbean: On Stranger Tides</td>\n",
       "      <td>Captain Jack Sparrow crosses paths with a woma...</td>\n",
       "      <td>135.413856</td>\n",
       "      <td>[{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2011-05-14</td>\n",
       "      <td>1045713802</td>\n",
       "      <td>136.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Live Forever Or Die Trying.</td>\n",
       "      <td>Pirates of the Caribbean: On Stranger Tides</td>\n",
       "      <td>6.4</td>\n",
       "      <td>4948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>225000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 35, \"nam...</td>\n",
       "      <td>http://www.sonypictures.com/movies/meninblack3/</td>\n",
       "      <td>41154</td>\n",
       "      <td>[{\"id\": 4379, \"name\": \"time travel\"}, {\"id\": 5...</td>\n",
       "      <td>en</td>\n",
       "      <td>Men in Black 3</td>\n",
       "      <td>Agents J (Will Smith) and K (Tommy Lee Jones) ...</td>\n",
       "      <td>52.035179</td>\n",
       "      <td>[{\"name\": \"Amblin Entertainment\", \"id\": 56}, {...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2012-05-23</td>\n",
       "      <td>624026776</td>\n",
       "      <td>106.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>They are back... in time.</td>\n",
       "      <td>Men in Black 3</td>\n",
       "      <td>6.2</td>\n",
       "      <td>4160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>250000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.thehobbit.com/</td>\n",
       "      <td>122917</td>\n",
       "      <td>[{\"id\": 417, \"name\": \"corruption\"}, {\"id\": 603...</td>\n",
       "      <td>en</td>\n",
       "      <td>The Hobbit: The Battle of the Five Armies</td>\n",
       "      <td>Immediately after the events of The Desolation...</td>\n",
       "      <td>120.965743</td>\n",
       "      <td>[{\"name\": \"WingNut Films\", \"id\": 11}, {\"name\":...</td>\n",
       "      <td>[{\"iso_3166_1\": \"NZ\", \"name\": \"New Zealand\"}, ...</td>\n",
       "      <td>2014-12-10</td>\n",
       "      <td>956019788</td>\n",
       "      <td>144.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Witness the defining chapter of the Middle-Ear...</td>\n",
       "      <td>The Hobbit: The Battle of the Five Armies</td>\n",
       "      <td>7.1</td>\n",
       "      <td>4760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>215000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.theamazingspiderman.com</td>\n",
       "      <td>1930</td>\n",
       "      <td>[{\"id\": 1872, \"name\": \"loss of father\"}, {\"id\"...</td>\n",
       "      <td>en</td>\n",
       "      <td>The Amazing Spider-Man</td>\n",
       "      <td>Peter Parker is an outcast high schooler aband...</td>\n",
       "      <td>89.866276</td>\n",
       "      <td>[{\"name\": \"Columbia Pictures\", \"id\": 5}, {\"nam...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2012-06-27</td>\n",
       "      <td>752215857</td>\n",
       "      <td>136.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>The untold story begins.</td>\n",
       "      <td>The Amazing Spider-Man</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>200000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.robinhoodthemovie.com/</td>\n",
       "      <td>20662</td>\n",
       "      <td>[{\"id\": 4147, \"name\": \"robin hood\"}, {\"id\": 43...</td>\n",
       "      <td>en</td>\n",
       "      <td>Robin Hood</td>\n",
       "      <td>When soldier Robin happens upon the dying Robe...</td>\n",
       "      <td>37.668301</td>\n",
       "      <td>[{\"name\": \"Imagine Entertainment\", \"id\": 23}, ...</td>\n",
       "      <td>[{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...</td>\n",
       "      <td>2010-05-12</td>\n",
       "      <td>310669540</td>\n",
       "      <td>140.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Rise and rise again, until lambs become lions.</td>\n",
       "      <td>Robin Hood</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>250000000</td>\n",
       "      <td>[{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...</td>\n",
       "      <td>http://www.thehobbit.com/</td>\n",
       "      <td>57158</td>\n",
       "      <td>[{\"id\": 603, \"name\": \"elves\"}, {\"id\": 604, \"na...</td>\n",
       "      <td>en</td>\n",
       "      <td>The Hobbit: The Desolation of Smaug</td>\n",
       "      <td>The Dwarves, Bilbo and Gandalf have successful...</td>\n",
       "      <td>94.370564</td>\n",
       "      <td>[{\"name\": \"WingNut Films\", \"id\": 11}, {\"name\":...</td>\n",
       "      <td>[{\"iso_3166_1\": \"NZ\", \"name\": \"New Zealand\"}, ...</td>\n",
       "      <td>2013-12-11</td>\n",
       "      <td>958400000</td>\n",
       "      <td>161.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Beyond darkness... beyond desolation... lies t...</td>\n",
       "      <td>The Hobbit: The Desolation of Smaug</td>\n",
       "      <td>7.6</td>\n",
       "      <td>4524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>180000000</td>\n",
       "      <td>[{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...</td>\n",
       "      <td>http://www.goldencompassmovie.com/index_german...</td>\n",
       "      <td>2268</td>\n",
       "      <td>[{\"id\": 392, \"name\": \"england\"}, {\"id\": 1461, ...</td>\n",
       "      <td>en</td>\n",
       "      <td>The Golden Compass</td>\n",
       "      <td>After overhearing a shocking secret, precociou...</td>\n",
       "      <td>42.990906</td>\n",
       "      <td>[{\"name\": \"New Line Cinema\", \"id\": 12}, {\"name...</td>\n",
       "      <td>[{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...</td>\n",
       "      <td>2007-12-04</td>\n",
       "      <td>372234864</td>\n",
       "      <td>113.0</td>\n",
       "      <td>[{\"iso_639_1\": \"is\", \"name\": \"\\u00cdslenska\"},...</td>\n",
       "      <td>Released</td>\n",
       "      <td>There are worlds beyond our own - the compass ...</td>\n",
       "      <td>The Golden Compass</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>207000000</td>\n",
       "      <td>[{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 18, \"...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>254</td>\n",
       "      <td>[{\"id\": 774, \"name\": \"film business\"}, {\"id\": ...</td>\n",
       "      <td>en</td>\n",
       "      <td>King Kong</td>\n",
       "      <td>In 1933 New York, an overly ambitious movie pr...</td>\n",
       "      <td>61.226010</td>\n",
       "      <td>[{\"name\": \"WingNut Films\", \"id\": 11}, {\"name\":...</td>\n",
       "      <td>[{\"iso_3166_1\": \"NZ\", \"name\": \"New Zealand\"}, ...</td>\n",
       "      <td>2005-12-14</td>\n",
       "      <td>550000000</td>\n",
       "      <td>187.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>The eighth wonder of the world.</td>\n",
       "      <td>King Kong</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>200000000</td>\n",
       "      <td>[{\"id\": 18, \"name\": \"Drama\"}, {\"id\": 10749, \"n...</td>\n",
       "      <td>http://www.titanicmovie.com</td>\n",
       "      <td>597</td>\n",
       "      <td>[{\"id\": 2580, \"name\": \"shipwreck\"}, {\"id\": 298...</td>\n",
       "      <td>en</td>\n",
       "      <td>Titanic</td>\n",
       "      <td>84 years later, a 101-year-old woman named Ros...</td>\n",
       "      <td>100.025899</td>\n",
       "      <td>[{\"name\": \"Paramount Pictures\", \"id\": 4}, {\"na...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>1997-11-18</td>\n",
       "      <td>1845034188</td>\n",
       "      <td>194.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Nothing on Earth could come between them.</td>\n",
       "      <td>Titanic</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>250000000</td>\n",
       "      <td>[{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 28, \"...</td>\n",
       "      <td>http://marvel.com/captainamericapremiere</td>\n",
       "      <td>271110</td>\n",
       "      <td>[{\"id\": 393, \"name\": \"civil war\"}, {\"id\": 6091...</td>\n",
       "      <td>en</td>\n",
       "      <td>Captain America: Civil War</td>\n",
       "      <td>Following the events of Age of Ultron, the col...</td>\n",
       "      <td>198.372395</td>\n",
       "      <td>[{\"name\": \"Studio Babelsberg\", \"id\": 264}, {\"n...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2016-04-27</td>\n",
       "      <td>1153304495</td>\n",
       "      <td>147.0</td>\n",
       "      <td>[{\"iso_639_1\": \"ro\", \"name\": \"Rom\\u00e2n\\u0103...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Divided We Fall</td>\n",
       "      <td>Captain America: Civil War</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>209000000</td>\n",
       "      <td>[{\"id\": 53, \"name\": \"Thriller\"}, {\"id\": 28, \"n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44833</td>\n",
       "      <td>[{\"id\": 1721, \"name\": \"fight\"}, {\"id\": 4410, \"...</td>\n",
       "      <td>en</td>\n",
       "      <td>Battleship</td>\n",
       "      <td>When mankind beams a radio signal into space, ...</td>\n",
       "      <td>64.928382</td>\n",
       "      <td>[{\"name\": \"Universal Pictures\", \"id\": 33}, {\"n...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2012-04-11</td>\n",
       "      <td>303025485</td>\n",
       "      <td>131.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>The Battle for Earth Begins at Sea</td>\n",
       "      <td>Battleship</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>150000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.jurassicworld.com/</td>\n",
       "      <td>135397</td>\n",
       "      <td>[{\"id\": 1299, \"name\": \"monster\"}, {\"id\": 1718,...</td>\n",
       "      <td>en</td>\n",
       "      <td>Jurassic World</td>\n",
       "      <td>Twenty-two years after the events of Jurassic ...</td>\n",
       "      <td>418.708552</td>\n",
       "      <td>[{\"name\": \"Universal Studios\", \"id\": 13}, {\"na...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2015-06-09</td>\n",
       "      <td>1513528810</td>\n",
       "      <td>124.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>The park is open.</td>\n",
       "      <td>Jurassic World</td>\n",
       "      <td>6.5</td>\n",
       "      <td>8662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>200000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.skyfall-movie.com</td>\n",
       "      <td>37724</td>\n",
       "      <td>[{\"id\": 470, \"name\": \"spy\"}, {\"id\": 4289, \"nam...</td>\n",
       "      <td>en</td>\n",
       "      <td>Skyfall</td>\n",
       "      <td>When Bond's latest assignment goes gravely wro...</td>\n",
       "      <td>93.004993</td>\n",
       "      <td>[{\"name\": \"Columbia Pictures\", \"id\": 5}]</td>\n",
       "      <td>[{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...</td>\n",
       "      <td>2012-10-25</td>\n",
       "      <td>1108561013</td>\n",
       "      <td>143.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Think on your sins.</td>\n",
       "      <td>Skyfall</td>\n",
       "      <td>6.9</td>\n",
       "      <td>7604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4773</th>\n",
       "      <td>27000</td>\n",
       "      <td>[{\"id\": 35, \"name\": \"Comedy\"}]</td>\n",
       "      <td>http://www.miramax.com/movie/clerks/</td>\n",
       "      <td>2292</td>\n",
       "      <td>[{\"id\": 1361, \"name\": \"salesclerk\"}, {\"id\": 30...</td>\n",
       "      <td>en</td>\n",
       "      <td>Clerks</td>\n",
       "      <td>Convenience and video store clerks Dante and R...</td>\n",
       "      <td>19.748658</td>\n",
       "      <td>[{\"name\": \"Miramax Films\", \"id\": 14}, {\"name\":...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>1994-09-13</td>\n",
       "      <td>3151130</td>\n",
       "      <td>92.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Just because they serve you doesn't mean they ...</td>\n",
       "      <td>Clerks</td>\n",
       "      <td>7.4</td>\n",
       "      <td>755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4774</th>\n",
       "      <td>27000</td>\n",
       "      <td>[{\"id\": 18, \"name\": \"Drama\"}, {\"id\": 10749, \"n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42497</td>\n",
       "      <td>[{\"id\": 1566, \"name\": \"dream\"}, {\"id\": 13059, ...</td>\n",
       "      <td>en</td>\n",
       "      <td>Pink Narcissus</td>\n",
       "      <td>An erotic poem set in the fantasies of a young...</td>\n",
       "      <td>0.027811</td>\n",
       "      <td>[{\"name\": \"Strand Releasing\", \"id\": 3923}]</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>1971-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>A unique experience in visual fantasy!</td>\n",
       "      <td>Pink Narcissus</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4775</th>\n",
       "      <td>0</td>\n",
       "      <td>[{\"id\": 18, \"name\": \"Drama\"}, {\"id\": 35, \"name...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33693</td>\n",
       "      <td>[{\"id\": 171993, \"name\": \"mumblecore\"}]</td>\n",
       "      <td>en</td>\n",
       "      <td>Funny Ha Ha</td>\n",
       "      <td>Unsure of what to do next, 23-year-old Marnie ...</td>\n",
       "      <td>0.362633</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2002-09-20</td>\n",
       "      <td>76901</td>\n",
       "      <td>85.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Funny Ha Ha</td>\n",
       "      <td>6.3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4776</th>\n",
       "      <td>0</td>\n",
       "      <td>[{\"id\": 35, \"name\": \"Comedy\"}, {\"id\": 18, \"nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14585</td>\n",
       "      <td>[{\"id\": 1438, \"name\": \"office\"}, {\"id\": 9673, ...</td>\n",
       "      <td>en</td>\n",
       "      <td>In the Company of Men</td>\n",
       "      <td>Two business executives--one an avowed misogyn...</td>\n",
       "      <td>2.634007</td>\n",
       "      <td>[{\"name\": \"Alliance Atlantis Communications\", ...</td>\n",
       "      <td>[{\"iso_3166_1\": \"CA\", \"name\": \"Canada\"}, {\"iso...</td>\n",
       "      <td>1997-01-19</td>\n",
       "      <td>0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Are all men bastards...or just misunderstood?</td>\n",
       "      <td>In the Company of Men</td>\n",
       "      <td>6.8</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4777</th>\n",
       "      <td>0</td>\n",
       "      <td>[{\"id\": 18, \"name\": \"Drama\"}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>185465</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>Manito</td>\n",
       "      <td>Fifteen years ago, their Washington Heights ne...</td>\n",
       "      <td>0.039264</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2002-01-15</td>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>[{\"iso_639_1\": \"es\", \"name\": \"Espa\\u00f1ol\"}, ...</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Manito</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4778</th>\n",
       "      <td>0</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 18, \"nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38780</td>\n",
       "      <td>[{\"id\": 10022, \"name\": \"rampage\"}, {\"id\": 1454...</td>\n",
       "      <td>en</td>\n",
       "      <td>Rampage</td>\n",
       "      <td>The boredom of small town life is eating Bill ...</td>\n",
       "      <td>7.101197</td>\n",
       "      <td>[{\"name\": \"Boll Kino Beteiligungs GmbH &amp; Co. K...</td>\n",
       "      <td>[{\"iso_3166_1\": \"CA\", \"name\": \"Canada\"}, {\"iso...</td>\n",
       "      <td>2009-08-14</td>\n",
       "      <td>0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Vengeance is ruthless.</td>\n",
       "      <td>Rampage</td>\n",
       "      <td>6.0</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4779</th>\n",
       "      <td>0</td>\n",
       "      <td>[{\"id\": 35, \"name\": \"Comedy\"}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14022</td>\n",
       "      <td>[{\"id\": 305, \"name\": \"moon\"}, {\"id\": 490, \"nam...</td>\n",
       "      <td>en</td>\n",
       "      <td>Slacker</td>\n",
       "      <td>Presents a day in the life in Austin, Texas am...</td>\n",
       "      <td>3.320622</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>1990-07-27</td>\n",
       "      <td>0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Slacker</td>\n",
       "      <td>6.4</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4780</th>\n",
       "      <td>0</td>\n",
       "      <td>[{\"id\": 53, \"name\": \"Thriller\"}, {\"id\": 80, \"n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>366967</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>Dutch Kills</td>\n",
       "      <td>A desperate ex-con is forced to gather his old...</td>\n",
       "      <td>0.038143</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2015-10-02</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dutch Kills</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4781</th>\n",
       "      <td>22000</td>\n",
       "      <td>[{\"id\": 35, \"name\": \"Comedy\"}, {\"id\": 10749, \"...</td>\n",
       "      <td>https://www.facebook.com/DrySpellMovie</td>\n",
       "      <td>255266</td>\n",
       "      <td>[{\"id\": 13043, \"name\": \"dating\"}, {\"id\": 15160...</td>\n",
       "      <td>en</td>\n",
       "      <td>Dry Spell</td>\n",
       "      <td>Sasha tries to get her soon-to-be ex husband K...</td>\n",
       "      <td>0.048948</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2013-02-14</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Getting divorced does funny things to a girl</td>\n",
       "      <td>Dry Spell</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4782</th>\n",
       "      <td>0</td>\n",
       "      <td>[{\"id\": 18, \"name\": \"Drama\"}, {\"id\": 10751, \"n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17345</td>\n",
       "      <td>[{\"id\": 186, \"name\": \"christianity\"}, {\"id\": 4...</td>\n",
       "      <td>en</td>\n",
       "      <td>Flywheel</td>\n",
       "      <td>Jay Austin wants to sell you a used car, but w...</td>\n",
       "      <td>1.048524</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Flywheel</td>\n",
       "      <td>6.8</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4783</th>\n",
       "      <td>0</td>\n",
       "      <td>[{\"id\": 53, \"name\": \"Thriller\"}, {\"id\": 27, \"n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>226458</td>\n",
       "      <td>[{\"id\": 9712, \"name\": \"possession\"}]</td>\n",
       "      <td>en</td>\n",
       "      <td>Backmask</td>\n",
       "      <td>During an all-night, drug-fueled party at an a...</td>\n",
       "      <td>3.619167</td>\n",
       "      <td>[{\"name\": \"GO Productions\", \"id\": 2943}, {\"nam...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2015-01-16</td>\n",
       "      <td>0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>nederlands</td>\n",
       "      <td>Backmask</td>\n",
       "      <td>4.7</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4784</th>\n",
       "      <td>0</td>\n",
       "      <td>[{\"id\": 18, \"name\": \"Drama\"}, {\"id\": 35, \"name...</td>\n",
       "      <td>http://www.thepuffychairmovie.com</td>\n",
       "      <td>24055</td>\n",
       "      <td>[{\"id\": 171993, \"name\": \"mumblecore\"}]</td>\n",
       "      <td>en</td>\n",
       "      <td>The Puffy Chair</td>\n",
       "      <td>Josh's life is pretty much in the toilet. He's...</td>\n",
       "      <td>1.243955</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2005-01-17</td>\n",
       "      <td>0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Puffy Chair</td>\n",
       "      <td>6.2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4785</th>\n",
       "      <td>0</td>\n",
       "      <td>[{\"id\": 18, \"name\": \"Drama\"}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>287625</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>Stories of Our Lives</td>\n",
       "      <td>Created by the members of a Nairobi-based arts...</td>\n",
       "      <td>0.327794</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"iso_3166_1\": \"KE\", \"name\": \"Kenya\"}]</td>\n",
       "      <td>2014-09-05</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>[{\"iso_639_1\": \"sw\", \"name\": \"Kiswahili\"}, {\"i...</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stories of Our Lives</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4786</th>\n",
       "      <td>0</td>\n",
       "      <td>[{\"id\": 35, \"name\": \"Comedy\"}, {\"id\": 10749, \"...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44990</td>\n",
       "      <td>[{\"id\": 10183, \"name\": \"independent film\"}]</td>\n",
       "      <td>en</td>\n",
       "      <td>Breaking Upwards</td>\n",
       "      <td>'Breaking Upwards' explores a young, real-life...</td>\n",
       "      <td>0.674570</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2009-03-14</td>\n",
       "      <td>0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Breaking Upwards</td>\n",
       "      <td>5.6</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4787</th>\n",
       "      <td>0</td>\n",
       "      <td>[{\"id\": 878, \"name\": \"Science Fiction\"}, {\"id\"...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86304</td>\n",
       "      <td>[{\"id\": 9715, \"name\": \"superhero\"}]</td>\n",
       "      <td>en</td>\n",
       "      <td>All Superheroes Must Die</td>\n",
       "      <td>Masked vigilantes Charge (Jason Trost), Cutthr...</td>\n",
       "      <td>3.545991</td>\n",
       "      <td>[{\"name\": \"Grindfest\", \"id\": 18818}]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2011-10-26</td>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>May The Best Man Win</td>\n",
       "      <td>All Superheroes Must Die</td>\n",
       "      <td>4.2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4788</th>\n",
       "      <td>12000</td>\n",
       "      <td>[{\"id\": 27, \"name\": \"Horror\"}, {\"id\": 35, \"nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>692</td>\n",
       "      <td>[{\"id\": 237, \"name\": \"gay\"}, {\"id\": 900, \"name...</td>\n",
       "      <td>en</td>\n",
       "      <td>Pink Flamingos</td>\n",
       "      <td>Notorious Baltimore criminal and underground f...</td>\n",
       "      <td>4.553644</td>\n",
       "      <td>[{\"name\": \"Dreamland Productions\", \"id\": 407}]</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>1972-03-12</td>\n",
       "      <td>6000000</td>\n",
       "      <td>93.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>An exercise in poor taste.</td>\n",
       "      <td>Pink Flamingos</td>\n",
       "      <td>6.2</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4789</th>\n",
       "      <td>0</td>\n",
       "      <td>[{\"id\": 18, \"name\": \"Drama\"}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39851</td>\n",
       "      <td>[{\"id\": 6782, \"name\": \"addiction\"}, {\"id\": 155...</td>\n",
       "      <td>en</td>\n",
       "      <td>Clean</td>\n",
       "      <td>After losing her husband to a heroin overdose,...</td>\n",
       "      <td>1.464566</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...</td>\n",
       "      <td>2004-09-01</td>\n",
       "      <td>0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>[{\"iso_639_1\": \"cn\", \"name\": \"\\u5e7f\\u5dde\\u8b...</td>\n",
       "      <td>Released</td>\n",
       "      <td>When you don't have a choice, you change.</td>\n",
       "      <td>Clean</td>\n",
       "      <td>6.7</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4790</th>\n",
       "      <td>0</td>\n",
       "      <td>[{\"id\": 18, \"name\": \"Drama\"}, {\"id\": 10769, \"n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13898</td>\n",
       "      <td>[]</td>\n",
       "      <td>fa</td>\n",
       "      <td>Ø¯Ø§ÛŒØ±Ù‡</td>\n",
       "      <td>Various women struggle to function in the oppr...</td>\n",
       "      <td>1.193779</td>\n",
       "      <td>[{\"name\": \"Jafar Panahi Film Productions\", \"id...</td>\n",
       "      <td>[{\"iso_3166_1\": \"IR\", \"name\": \"Iran\"}]</td>\n",
       "      <td>2000-09-08</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>[{\"iso_639_1\": \"fa\", \"name\": \"\\u0641\\u0627\\u06...</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Circle</td>\n",
       "      <td>6.6</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4791</th>\n",
       "      <td>13</td>\n",
       "      <td>[{\"id\": 27, \"name\": \"Horror\"}]</td>\n",
       "      <td>http://tincanmanthemovie.com/</td>\n",
       "      <td>157185</td>\n",
       "      <td>[{\"id\": 14903, \"name\": \"home invasion\"}]</td>\n",
       "      <td>en</td>\n",
       "      <td>Tin Can Man</td>\n",
       "      <td>Recently dumped by his girlfirend for another ...</td>\n",
       "      <td>0.332679</td>\n",
       "      <td>[{\"name\": \"Park Films\", \"id\": 21871}, {\"name\":...</td>\n",
       "      <td>[{\"iso_3166_1\": \"IE\", \"name\": \"Ireland\"}]</td>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Everything You've Heard is True</td>\n",
       "      <td>Tin Can Man</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4792</th>\n",
       "      <td>20000</td>\n",
       "      <td>[{\"id\": 80, \"name\": \"Crime\"}, {\"id\": 27, \"name...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36095</td>\n",
       "      <td>[{\"id\": 233, \"name\": \"japan\"}, {\"id\": 549, \"na...</td>\n",
       "      <td>ja</td>\n",
       "      <td>ã‚­ãƒ¥ã‚¢</td>\n",
       "      <td>A wave of gruesome murders is sweeping Tokyo. ...</td>\n",
       "      <td>0.212443</td>\n",
       "      <td>[{\"name\": \"Daiei Studios\", \"id\": 881}]</td>\n",
       "      <td>[{\"iso_3166_1\": \"JP\", \"name\": \"Japan\"}]</td>\n",
       "      <td>1997-11-06</td>\n",
       "      <td>99000</td>\n",
       "      <td>111.0</td>\n",
       "      <td>[{\"iso_639_1\": \"ja\", \"name\": \"\\u65e5\\u672c\\u8a...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Madness. Terror. Murder.</td>\n",
       "      <td>Cure</td>\n",
       "      <td>7.4</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4793</th>\n",
       "      <td>0</td>\n",
       "      <td>[{\"id\": 18, \"name\": \"Drama\"}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>182291</td>\n",
       "      <td>[{\"id\": 718, \"name\": \"confession\"}, {\"id\": 100...</td>\n",
       "      <td>en</td>\n",
       "      <td>On The Downlow</td>\n",
       "      <td>Isaac and Angel are two young Latinos involved...</td>\n",
       "      <td>0.029757</td>\n",
       "      <td>[{\"name\": \"Iconoclast Films\", \"id\": 26677}]</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2004-04-11</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Two gangs. One secret. One crossroad.</td>\n",
       "      <td>On The Downlow</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4794</th>\n",
       "      <td>0</td>\n",
       "      <td>[{\"id\": 53, \"name\": \"Thriller\"}, {\"id\": 27, \"n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>286939</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>Sanctuary: Quite a Conundrum</td>\n",
       "      <td>It should have been just a normal day of sex, ...</td>\n",
       "      <td>0.166513</td>\n",
       "      <td>[{\"name\": \"Gold Lion Films\", \"id\": 37870}, {\"n...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2012-01-20</td>\n",
       "      <td>0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sanctuary: Quite a Conundrum</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4795</th>\n",
       "      <td>0</td>\n",
       "      <td>[{\"id\": 18, \"name\": \"Drama\"}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>124606</td>\n",
       "      <td>[{\"id\": 10726, \"name\": \"gang\"}, {\"id\": 33928, ...</td>\n",
       "      <td>en</td>\n",
       "      <td>Bang</td>\n",
       "      <td>A young woman in L.A. is having a bad day: she...</td>\n",
       "      <td>0.918116</td>\n",
       "      <td>[{\"name\": \"Asylum Films\", \"id\": 10571}, {\"name...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>1995-09-09</td>\n",
       "      <td>0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Sometimes you've got to break the rules</td>\n",
       "      <td>Bang</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4796</th>\n",
       "      <td>7000</td>\n",
       "      <td>[{\"id\": 878, \"name\": \"Science Fiction\"}, {\"id\"...</td>\n",
       "      <td>http://www.primermovie.com</td>\n",
       "      <td>14337</td>\n",
       "      <td>[{\"id\": 1448, \"name\": \"distrust\"}, {\"id\": 2101...</td>\n",
       "      <td>en</td>\n",
       "      <td>Primer</td>\n",
       "      <td>Friends/fledgling entrepreneurs invent a devic...</td>\n",
       "      <td>23.307949</td>\n",
       "      <td>[{\"name\": \"Thinkfilm\", \"id\": 446}]</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2004-10-08</td>\n",
       "      <td>424760</td>\n",
       "      <td>77.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>What happens if it actually works?</td>\n",
       "      <td>Primer</td>\n",
       "      <td>6.9</td>\n",
       "      <td>658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4797</th>\n",
       "      <td>0</td>\n",
       "      <td>[{\"id\": 10769, \"name\": \"Foreign\"}, {\"id\": 53, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67238</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>Cavite</td>\n",
       "      <td>Adam, a security guard, travels from Californi...</td>\n",
       "      <td>0.022173</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2005-03-12</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cavite</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4798</th>\n",
       "      <td>220000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9367</td>\n",
       "      <td>[{\"id\": 5616, \"name\": \"united states\\u2013mexi...</td>\n",
       "      <td>es</td>\n",
       "      <td>El Mariachi</td>\n",
       "      <td>El Mariachi just wants to play his guitar and ...</td>\n",
       "      <td>14.269792</td>\n",
       "      <td>[{\"name\": \"Columbia Pictures\", \"id\": 5}]</td>\n",
       "      <td>[{\"iso_3166_1\": \"MX\", \"name\": \"Mexico\"}, {\"iso...</td>\n",
       "      <td>1992-09-04</td>\n",
       "      <td>2040920</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[{\"iso_639_1\": \"es\", \"name\": \"Espa\\u00f1ol\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>He didn't come looking for trouble, but troubl...</td>\n",
       "      <td>El Mariachi</td>\n",
       "      <td>6.6</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4799</th>\n",
       "      <td>9000</td>\n",
       "      <td>[{\"id\": 35, \"name\": \"Comedy\"}, {\"id\": 10749, \"...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72766</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>Newlyweds</td>\n",
       "      <td>A newlywed couple's honeymoon is upended by th...</td>\n",
       "      <td>0.642552</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2011-12-26</td>\n",
       "      <td>0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>Released</td>\n",
       "      <td>A newlywed couple's honeymoon is upended by th...</td>\n",
       "      <td>Newlyweds</td>\n",
       "      <td>5.9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4800</th>\n",
       "      <td>0</td>\n",
       "      <td>[{\"id\": 35, \"name\": \"Comedy\"}, {\"id\": 18, \"nam...</td>\n",
       "      <td>http://www.hallmarkchannel.com/signedsealeddel...</td>\n",
       "      <td>231617</td>\n",
       "      <td>[{\"id\": 248, \"name\": \"date\"}, {\"id\": 699, \"nam...</td>\n",
       "      <td>en</td>\n",
       "      <td>Signed, Sealed, Delivered</td>\n",
       "      <td>\"Signed, Sealed, Delivered\" introduces a dedic...</td>\n",
       "      <td>1.444476</td>\n",
       "      <td>[{\"name\": \"Front Street Pictures\", \"id\": 3958}...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2013-10-13</td>\n",
       "      <td>0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Signed, Sealed, Delivered</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4801</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>http://shanghaicalling.com/</td>\n",
       "      <td>126186</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>Shanghai Calling</td>\n",
       "      <td>When ambitious New York attorney Sam is sent t...</td>\n",
       "      <td>0.857008</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2012-05-03</td>\n",
       "      <td>0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>A New Yorker in Shanghai</td>\n",
       "      <td>Shanghai Calling</td>\n",
       "      <td>5.7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4802</th>\n",
       "      <td>0</td>\n",
       "      <td>[{\"id\": 99, \"name\": \"Documentary\"}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25975</td>\n",
       "      <td>[{\"id\": 1523, \"name\": \"obsession\"}, {\"id\": 224...</td>\n",
       "      <td>en</td>\n",
       "      <td>My Date with Drew</td>\n",
       "      <td>Ever since the second grade when he first saw ...</td>\n",
       "      <td>1.929883</td>\n",
       "      <td>[{\"name\": \"rusty bear entertainment\", \"id\": 87...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2005-08-05</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My Date with Drew</td>\n",
       "      <td>6.3</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4803 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         budget                                             genres  \\\n",
       "0     237000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "1     300000000  [{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...   \n",
       "2     245000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "3     250000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...   \n",
       "4     260000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "5     258000000  [{\"id\": 14, \"name\": \"Fantasy\"}, {\"id\": 28, \"na...   \n",
       "6     260000000  [{\"id\": 16, \"name\": \"Animation\"}, {\"id\": 10751...   \n",
       "7     280000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "8     250000000  [{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...   \n",
       "9     250000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "10    270000000  [{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...   \n",
       "11    200000000  [{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 28, \"...   \n",
       "12    200000000  [{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...   \n",
       "13    255000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "14    225000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "15    225000000  [{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 10751...   \n",
       "16    220000000  [{\"id\": 878, \"name\": \"Science Fiction\"}, {\"id\"...   \n",
       "17    380000000  [{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 28, \"...   \n",
       "18    225000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 35, \"nam...   \n",
       "19    250000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "20    215000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "21    200000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "22    250000000  [{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...   \n",
       "23    180000000  [{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...   \n",
       "24    207000000  [{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 18, \"...   \n",
       "25    200000000  [{\"id\": 18, \"name\": \"Drama\"}, {\"id\": 10749, \"n...   \n",
       "26    250000000  [{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 28, \"...   \n",
       "27    209000000  [{\"id\": 53, \"name\": \"Thriller\"}, {\"id\": 28, \"n...   \n",
       "28    150000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "29    200000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "...         ...                                                ...   \n",
       "4773      27000                     [{\"id\": 35, \"name\": \"Comedy\"}]   \n",
       "4774      27000  [{\"id\": 18, \"name\": \"Drama\"}, {\"id\": 10749, \"n...   \n",
       "4775          0  [{\"id\": 18, \"name\": \"Drama\"}, {\"id\": 35, \"name...   \n",
       "4776          0  [{\"id\": 35, \"name\": \"Comedy\"}, {\"id\": 18, \"nam...   \n",
       "4777          0                      [{\"id\": 18, \"name\": \"Drama\"}]   \n",
       "4778          0  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 18, \"nam...   \n",
       "4779          0                     [{\"id\": 35, \"name\": \"Comedy\"}]   \n",
       "4780          0  [{\"id\": 53, \"name\": \"Thriller\"}, {\"id\": 80, \"n...   \n",
       "4781      22000  [{\"id\": 35, \"name\": \"Comedy\"}, {\"id\": 10749, \"...   \n",
       "4782          0  [{\"id\": 18, \"name\": \"Drama\"}, {\"id\": 10751, \"n...   \n",
       "4783          0  [{\"id\": 53, \"name\": \"Thriller\"}, {\"id\": 27, \"n...   \n",
       "4784          0  [{\"id\": 18, \"name\": \"Drama\"}, {\"id\": 35, \"name...   \n",
       "4785          0                      [{\"id\": 18, \"name\": \"Drama\"}]   \n",
       "4786          0  [{\"id\": 35, \"name\": \"Comedy\"}, {\"id\": 10749, \"...   \n",
       "4787          0  [{\"id\": 878, \"name\": \"Science Fiction\"}, {\"id\"...   \n",
       "4788      12000  [{\"id\": 27, \"name\": \"Horror\"}, {\"id\": 35, \"nam...   \n",
       "4789          0                      [{\"id\": 18, \"name\": \"Drama\"}]   \n",
       "4790          0  [{\"id\": 18, \"name\": \"Drama\"}, {\"id\": 10769, \"n...   \n",
       "4791         13                     [{\"id\": 27, \"name\": \"Horror\"}]   \n",
       "4792      20000  [{\"id\": 80, \"name\": \"Crime\"}, {\"id\": 27, \"name...   \n",
       "4793          0                      [{\"id\": 18, \"name\": \"Drama\"}]   \n",
       "4794          0  [{\"id\": 53, \"name\": \"Thriller\"}, {\"id\": 27, \"n...   \n",
       "4795          0                      [{\"id\": 18, \"name\": \"Drama\"}]   \n",
       "4796       7000  [{\"id\": 878, \"name\": \"Science Fiction\"}, {\"id\"...   \n",
       "4797          0  [{\"id\": 10769, \"name\": \"Foreign\"}, {\"id\": 53, ...   \n",
       "4798     220000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...   \n",
       "4799       9000  [{\"id\": 35, \"name\": \"Comedy\"}, {\"id\": 10749, \"...   \n",
       "4800          0  [{\"id\": 35, \"name\": \"Comedy\"}, {\"id\": 18, \"nam...   \n",
       "4801          0                                                 []   \n",
       "4802          0                [{\"id\": 99, \"name\": \"Documentary\"}]   \n",
       "\n",
       "                                               homepage      id  \\\n",
       "0                           http://www.avatarmovie.com/   19995   \n",
       "1          http://disney.go.com/disneypictures/pirates/     285   \n",
       "2           http://www.sonypictures.com/movies/spectre/  206647   \n",
       "3                    http://www.thedarkknightrises.com/   49026   \n",
       "4                  http://movies.disney.com/john-carter   49529   \n",
       "5       http://www.sonypictures.com/movies/spider-man3/     559   \n",
       "6          http://disney.go.com/disneypictures/tangled/   38757   \n",
       "7     http://marvel.com/movies/movie/193/avengers_ag...   99861   \n",
       "8     http://harrypotter.warnerbros.com/harrypottera...     767   \n",
       "9          http://www.batmanvsupermandawnofjustice.com/  209112   \n",
       "10                              http://www.superman.com    1452   \n",
       "11    http://www.mgm.com/view/movie/234/Quantum-of-S...   10764   \n",
       "12         http://disney.go.com/disneypictures/pirates/      58   \n",
       "13                http://disney.go.com/the-lone-ranger/   57201   \n",
       "14                           http://www.manofsteel.com/   49521   \n",
       "15                                                  NaN    2454   \n",
       "16                    http://marvel.com/avengers_movie/   24428   \n",
       "17    http://disney.go.com/pirates/index-on-stranger...    1865   \n",
       "18      http://www.sonypictures.com/movies/meninblack3/   41154   \n",
       "19                            http://www.thehobbit.com/  122917   \n",
       "20                   http://www.theamazingspiderman.com    1930   \n",
       "21                    http://www.robinhoodthemovie.com/   20662   \n",
       "22                            http://www.thehobbit.com/   57158   \n",
       "23    http://www.goldencompassmovie.com/index_german...    2268   \n",
       "24                                                  NaN     254   \n",
       "25                          http://www.titanicmovie.com     597   \n",
       "26             http://marvel.com/captainamericapremiere  271110   \n",
       "27                                                  NaN   44833   \n",
       "28                        http://www.jurassicworld.com/  135397   \n",
       "29                         http://www.skyfall-movie.com   37724   \n",
       "...                                                 ...     ...   \n",
       "4773               http://www.miramax.com/movie/clerks/    2292   \n",
       "4774                                                NaN   42497   \n",
       "4775                                                NaN   33693   \n",
       "4776                                                NaN   14585   \n",
       "4777                                                NaN  185465   \n",
       "4778                                                NaN   38780   \n",
       "4779                                                NaN   14022   \n",
       "4780                                                NaN  366967   \n",
       "4781             https://www.facebook.com/DrySpellMovie  255266   \n",
       "4782                                                NaN   17345   \n",
       "4783                                                NaN  226458   \n",
       "4784                  http://www.thepuffychairmovie.com   24055   \n",
       "4785                                                NaN  287625   \n",
       "4786                                                NaN   44990   \n",
       "4787                                                NaN   86304   \n",
       "4788                                                NaN     692   \n",
       "4789                                                NaN   39851   \n",
       "4790                                                NaN   13898   \n",
       "4791                      http://tincanmanthemovie.com/  157185   \n",
       "4792                                                NaN   36095   \n",
       "4793                                                NaN  182291   \n",
       "4794                                                NaN  286939   \n",
       "4795                                                NaN  124606   \n",
       "4796                         http://www.primermovie.com   14337   \n",
       "4797                                                NaN   67238   \n",
       "4798                                                NaN    9367   \n",
       "4799                                                NaN   72766   \n",
       "4800  http://www.hallmarkchannel.com/signedsealeddel...  231617   \n",
       "4801                        http://shanghaicalling.com/  126186   \n",
       "4802                                                NaN   25975   \n",
       "\n",
       "                                               keywords original_language  \\\n",
       "0     [{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...                en   \n",
       "1     [{\"id\": 270, \"name\": \"ocean\"}, {\"id\": 726, \"na...                en   \n",
       "2     [{\"id\": 470, \"name\": \"spy\"}, {\"id\": 818, \"name...                en   \n",
       "3     [{\"id\": 849, \"name\": \"dc comics\"}, {\"id\": 853,...                en   \n",
       "4     [{\"id\": 818, \"name\": \"based on novel\"}, {\"id\":...                en   \n",
       "5     [{\"id\": 851, \"name\": \"dual identity\"}, {\"id\": ...                en   \n",
       "6     [{\"id\": 1562, \"name\": \"hostage\"}, {\"id\": 2343,...                en   \n",
       "7     [{\"id\": 8828, \"name\": \"marvel comic\"}, {\"id\": ...                en   \n",
       "8     [{\"id\": 616, \"name\": \"witch\"}, {\"id\": 2343, \"n...                en   \n",
       "9     [{\"id\": 849, \"name\": \"dc comics\"}, {\"id\": 7002...                en   \n",
       "10    [{\"id\": 83, \"name\": \"saving the world\"}, {\"id\"...                en   \n",
       "11    [{\"id\": 627, \"name\": \"killing\"}, {\"id\": 1568, ...                en   \n",
       "12    [{\"id\": 616, \"name\": \"witch\"}, {\"id\": 663, \"na...                en   \n",
       "13    [{\"id\": 1556, \"name\": \"texas\"}, {\"id\": 2673, \"...                en   \n",
       "14    [{\"id\": 83, \"name\": \"saving the world\"}, {\"id\"...                en   \n",
       "15    [{\"id\": 818, \"name\": \"based on novel\"}, {\"id\":...                en   \n",
       "16    [{\"id\": 242, \"name\": \"new york\"}, {\"id\": 5539,...                en   \n",
       "17    [{\"id\": 658, \"name\": \"sea\"}, {\"id\": 1316, \"nam...                en   \n",
       "18    [{\"id\": 4379, \"name\": \"time travel\"}, {\"id\": 5...                en   \n",
       "19    [{\"id\": 417, \"name\": \"corruption\"}, {\"id\": 603...                en   \n",
       "20    [{\"id\": 1872, \"name\": \"loss of father\"}, {\"id\"...                en   \n",
       "21    [{\"id\": 4147, \"name\": \"robin hood\"}, {\"id\": 43...                en   \n",
       "22    [{\"id\": 603, \"name\": \"elves\"}, {\"id\": 604, \"na...                en   \n",
       "23    [{\"id\": 392, \"name\": \"england\"}, {\"id\": 1461, ...                en   \n",
       "24    [{\"id\": 774, \"name\": \"film business\"}, {\"id\": ...                en   \n",
       "25    [{\"id\": 2580, \"name\": \"shipwreck\"}, {\"id\": 298...                en   \n",
       "26    [{\"id\": 393, \"name\": \"civil war\"}, {\"id\": 6091...                en   \n",
       "27    [{\"id\": 1721, \"name\": \"fight\"}, {\"id\": 4410, \"...                en   \n",
       "28    [{\"id\": 1299, \"name\": \"monster\"}, {\"id\": 1718,...                en   \n",
       "29    [{\"id\": 470, \"name\": \"spy\"}, {\"id\": 4289, \"nam...                en   \n",
       "...                                                 ...               ...   \n",
       "4773  [{\"id\": 1361, \"name\": \"salesclerk\"}, {\"id\": 30...                en   \n",
       "4774  [{\"id\": 1566, \"name\": \"dream\"}, {\"id\": 13059, ...                en   \n",
       "4775             [{\"id\": 171993, \"name\": \"mumblecore\"}]                en   \n",
       "4776  [{\"id\": 1438, \"name\": \"office\"}, {\"id\": 9673, ...                en   \n",
       "4777                                                 []                en   \n",
       "4778  [{\"id\": 10022, \"name\": \"rampage\"}, {\"id\": 1454...                en   \n",
       "4779  [{\"id\": 305, \"name\": \"moon\"}, {\"id\": 490, \"nam...                en   \n",
       "4780                                                 []                en   \n",
       "4781  [{\"id\": 13043, \"name\": \"dating\"}, {\"id\": 15160...                en   \n",
       "4782  [{\"id\": 186, \"name\": \"christianity\"}, {\"id\": 4...                en   \n",
       "4783               [{\"id\": 9712, \"name\": \"possession\"}]                en   \n",
       "4784             [{\"id\": 171993, \"name\": \"mumblecore\"}]                en   \n",
       "4785                                                 []                en   \n",
       "4786        [{\"id\": 10183, \"name\": \"independent film\"}]                en   \n",
       "4787                [{\"id\": 9715, \"name\": \"superhero\"}]                en   \n",
       "4788  [{\"id\": 237, \"name\": \"gay\"}, {\"id\": 900, \"name...                en   \n",
       "4789  [{\"id\": 6782, \"name\": \"addiction\"}, {\"id\": 155...                en   \n",
       "4790                                                 []                fa   \n",
       "4791           [{\"id\": 14903, \"name\": \"home invasion\"}]                en   \n",
       "4792  [{\"id\": 233, \"name\": \"japan\"}, {\"id\": 549, \"na...                ja   \n",
       "4793  [{\"id\": 718, \"name\": \"confession\"}, {\"id\": 100...                en   \n",
       "4794                                                 []                en   \n",
       "4795  [{\"id\": 10726, \"name\": \"gang\"}, {\"id\": 33928, ...                en   \n",
       "4796  [{\"id\": 1448, \"name\": \"distrust\"}, {\"id\": 2101...                en   \n",
       "4797                                                 []                en   \n",
       "4798  [{\"id\": 5616, \"name\": \"united states\\u2013mexi...                es   \n",
       "4799                                                 []                en   \n",
       "4800  [{\"id\": 248, \"name\": \"date\"}, {\"id\": 699, \"nam...                en   \n",
       "4801                                                 []                en   \n",
       "4802  [{\"id\": 1523, \"name\": \"obsession\"}, {\"id\": 224...                en   \n",
       "\n",
       "                                   original_title  \\\n",
       "0                                          Avatar   \n",
       "1        Pirates of the Caribbean: At World's End   \n",
       "2                                         Spectre   \n",
       "3                           The Dark Knight Rises   \n",
       "4                                     John Carter   \n",
       "5                                    Spider-Man 3   \n",
       "6                                         Tangled   \n",
       "7                         Avengers: Age of Ultron   \n",
       "8          Harry Potter and the Half-Blood Prince   \n",
       "9              Batman v Superman: Dawn of Justice   \n",
       "10                               Superman Returns   \n",
       "11                              Quantum of Solace   \n",
       "12     Pirates of the Caribbean: Dead Man's Chest   \n",
       "13                                The Lone Ranger   \n",
       "14                                   Man of Steel   \n",
       "15       The Chronicles of Narnia: Prince Caspian   \n",
       "16                                   The Avengers   \n",
       "17    Pirates of the Caribbean: On Stranger Tides   \n",
       "18                                 Men in Black 3   \n",
       "19      The Hobbit: The Battle of the Five Armies   \n",
       "20                         The Amazing Spider-Man   \n",
       "21                                     Robin Hood   \n",
       "22            The Hobbit: The Desolation of Smaug   \n",
       "23                             The Golden Compass   \n",
       "24                                      King Kong   \n",
       "25                                        Titanic   \n",
       "26                     Captain America: Civil War   \n",
       "27                                     Battleship   \n",
       "28                                 Jurassic World   \n",
       "29                                        Skyfall   \n",
       "...                                           ...   \n",
       "4773                                       Clerks   \n",
       "4774                               Pink Narcissus   \n",
       "4775                                  Funny Ha Ha   \n",
       "4776                        In the Company of Men   \n",
       "4777                                       Manito   \n",
       "4778                                      Rampage   \n",
       "4779                                      Slacker   \n",
       "4780                                  Dutch Kills   \n",
       "4781                                    Dry Spell   \n",
       "4782                                     Flywheel   \n",
       "4783                                     Backmask   \n",
       "4784                              The Puffy Chair   \n",
       "4785                         Stories of Our Lives   \n",
       "4786                             Breaking Upwards   \n",
       "4787                     All Superheroes Must Die   \n",
       "4788                               Pink Flamingos   \n",
       "4789                                        Clean   \n",
       "4790                                        Ø¯Ø§ÛŒØ±Ù‡   \n",
       "4791                                  Tin Can Man   \n",
       "4792                                          ã‚­ãƒ¥ã‚¢   \n",
       "4793                               On The Downlow   \n",
       "4794                 Sanctuary: Quite a Conundrum   \n",
       "4795                                         Bang   \n",
       "4796                                       Primer   \n",
       "4797                                       Cavite   \n",
       "4798                                  El Mariachi   \n",
       "4799                                    Newlyweds   \n",
       "4800                    Signed, Sealed, Delivered   \n",
       "4801                             Shanghai Calling   \n",
       "4802                            My Date with Drew   \n",
       "\n",
       "                                               overview  popularity  \\\n",
       "0     In the 22nd century, a paraplegic Marine is di...  150.437577   \n",
       "1     Captain Barbossa, long believed to be dead, ha...  139.082615   \n",
       "2     A cryptic message from Bondâ€™s past sends him o...  107.376788   \n",
       "3     Following the death of District Attorney Harve...  112.312950   \n",
       "4     John Carter is a war-weary, former military ca...   43.926995   \n",
       "5     The seemingly invincible Spider-Man goes up ag...  115.699814   \n",
       "6     When the kingdom's most wanted-and most charmi...   48.681969   \n",
       "7     When Tony Stark tries to jumpstart a dormant p...  134.279229   \n",
       "8     As Harry begins his sixth year at Hogwarts, he...   98.885637   \n",
       "9     Fearing the actions of a god-like Super Hero l...  155.790452   \n",
       "10    Superman returns to discover his 5-year absenc...   57.925623   \n",
       "11    Quantum of Solace continues the adventures of ...  107.928811   \n",
       "12    Captain Jack Sparrow works his way out of a bl...  145.847379   \n",
       "13    The Texas Rangers chase down a gang of outlaws...   49.046956   \n",
       "14    A young boy learns that he has extraordinary p...   99.398009   \n",
       "15    One year after their incredible adventures in ...   53.978602   \n",
       "16    When an unexpected enemy emerges and threatens...  144.448633   \n",
       "17    Captain Jack Sparrow crosses paths with a woma...  135.413856   \n",
       "18    Agents J (Will Smith) and K (Tommy Lee Jones) ...   52.035179   \n",
       "19    Immediately after the events of The Desolation...  120.965743   \n",
       "20    Peter Parker is an outcast high schooler aband...   89.866276   \n",
       "21    When soldier Robin happens upon the dying Robe...   37.668301   \n",
       "22    The Dwarves, Bilbo and Gandalf have successful...   94.370564   \n",
       "23    After overhearing a shocking secret, precociou...   42.990906   \n",
       "24    In 1933 New York, an overly ambitious movie pr...   61.226010   \n",
       "25    84 years later, a 101-year-old woman named Ros...  100.025899   \n",
       "26    Following the events of Age of Ultron, the col...  198.372395   \n",
       "27    When mankind beams a radio signal into space, ...   64.928382   \n",
       "28    Twenty-two years after the events of Jurassic ...  418.708552   \n",
       "29    When Bond's latest assignment goes gravely wro...   93.004993   \n",
       "...                                                 ...         ...   \n",
       "4773  Convenience and video store clerks Dante and R...   19.748658   \n",
       "4774  An erotic poem set in the fantasies of a young...    0.027811   \n",
       "4775  Unsure of what to do next, 23-year-old Marnie ...    0.362633   \n",
       "4776  Two business executives--one an avowed misogyn...    2.634007   \n",
       "4777  Fifteen years ago, their Washington Heights ne...    0.039264   \n",
       "4778  The boredom of small town life is eating Bill ...    7.101197   \n",
       "4779  Presents a day in the life in Austin, Texas am...    3.320622   \n",
       "4780  A desperate ex-con is forced to gather his old...    0.038143   \n",
       "4781  Sasha tries to get her soon-to-be ex husband K...    0.048948   \n",
       "4782  Jay Austin wants to sell you a used car, but w...    1.048524   \n",
       "4783  During an all-night, drug-fueled party at an a...    3.619167   \n",
       "4784  Josh's life is pretty much in the toilet. He's...    1.243955   \n",
       "4785  Created by the members of a Nairobi-based arts...    0.327794   \n",
       "4786  'Breaking Upwards' explores a young, real-life...    0.674570   \n",
       "4787  Masked vigilantes Charge (Jason Trost), Cutthr...    3.545991   \n",
       "4788  Notorious Baltimore criminal and underground f...    4.553644   \n",
       "4789  After losing her husband to a heroin overdose,...    1.464566   \n",
       "4790  Various women struggle to function in the oppr...    1.193779   \n",
       "4791  Recently dumped by his girlfirend for another ...    0.332679   \n",
       "4792  A wave of gruesome murders is sweeping Tokyo. ...    0.212443   \n",
       "4793  Isaac and Angel are two young Latinos involved...    0.029757   \n",
       "4794  It should have been just a normal day of sex, ...    0.166513   \n",
       "4795  A young woman in L.A. is having a bad day: she...    0.918116   \n",
       "4796  Friends/fledgling entrepreneurs invent a devic...   23.307949   \n",
       "4797  Adam, a security guard, travels from Californi...    0.022173   \n",
       "4798  El Mariachi just wants to play his guitar and ...   14.269792   \n",
       "4799  A newlywed couple's honeymoon is upended by th...    0.642552   \n",
       "4800  \"Signed, Sealed, Delivered\" introduces a dedic...    1.444476   \n",
       "4801  When ambitious New York attorney Sam is sent t...    0.857008   \n",
       "4802  Ever since the second grade when he first saw ...    1.929883   \n",
       "\n",
       "                                   production_companies  \\\n",
       "0     [{\"name\": \"Ingenious Film Partners\", \"id\": 289...   \n",
       "1     [{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...   \n",
       "2     [{\"name\": \"Columbia Pictures\", \"id\": 5}, {\"nam...   \n",
       "3     [{\"name\": \"Legendary Pictures\", \"id\": 923}, {\"...   \n",
       "4           [{\"name\": \"Walt Disney Pictures\", \"id\": 2}]   \n",
       "5     [{\"name\": \"Columbia Pictures\", \"id\": 5}, {\"nam...   \n",
       "6     [{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...   \n",
       "7     [{\"name\": \"Marvel Studios\", \"id\": 420}, {\"name...   \n",
       "8     [{\"name\": \"Warner Bros.\", \"id\": 6194}, {\"name\"...   \n",
       "9     [{\"name\": \"DC Comics\", \"id\": 429}, {\"name\": \"A...   \n",
       "10    [{\"name\": \"DC Comics\", \"id\": 429}, {\"name\": \"L...   \n",
       "11            [{\"name\": \"Eon Productions\", \"id\": 7576}]   \n",
       "12    [{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...   \n",
       "13    [{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...   \n",
       "14    [{\"name\": \"Legendary Pictures\", \"id\": 923}, {\"...   \n",
       "15    [{\"name\": \"Walt Disney\", \"id\": 5888}, {\"name\":...   \n",
       "16    [{\"name\": \"Paramount Pictures\", \"id\": 4}, {\"na...   \n",
       "17    [{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...   \n",
       "18    [{\"name\": \"Amblin Entertainment\", \"id\": 56}, {...   \n",
       "19    [{\"name\": \"WingNut Films\", \"id\": 11}, {\"name\":...   \n",
       "20    [{\"name\": \"Columbia Pictures\", \"id\": 5}, {\"nam...   \n",
       "21    [{\"name\": \"Imagine Entertainment\", \"id\": 23}, ...   \n",
       "22    [{\"name\": \"WingNut Films\", \"id\": 11}, {\"name\":...   \n",
       "23    [{\"name\": \"New Line Cinema\", \"id\": 12}, {\"name...   \n",
       "24    [{\"name\": \"WingNut Films\", \"id\": 11}, {\"name\":...   \n",
       "25    [{\"name\": \"Paramount Pictures\", \"id\": 4}, {\"na...   \n",
       "26    [{\"name\": \"Studio Babelsberg\", \"id\": 264}, {\"n...   \n",
       "27    [{\"name\": \"Universal Pictures\", \"id\": 33}, {\"n...   \n",
       "28    [{\"name\": \"Universal Studios\", \"id\": 13}, {\"na...   \n",
       "29             [{\"name\": \"Columbia Pictures\", \"id\": 5}]   \n",
       "...                                                 ...   \n",
       "4773  [{\"name\": \"Miramax Films\", \"id\": 14}, {\"name\":...   \n",
       "4774         [{\"name\": \"Strand Releasing\", \"id\": 3923}]   \n",
       "4775                                                 []   \n",
       "4776  [{\"name\": \"Alliance Atlantis Communications\", ...   \n",
       "4777                                                 []   \n",
       "4778  [{\"name\": \"Boll Kino Beteiligungs GmbH & Co. K...   \n",
       "4779                                                 []   \n",
       "4780                                                 []   \n",
       "4781                                                 []   \n",
       "4782                                                 []   \n",
       "4783  [{\"name\": \"GO Productions\", \"id\": 2943}, {\"nam...   \n",
       "4784                                                 []   \n",
       "4785                                                 []   \n",
       "4786                                                 []   \n",
       "4787               [{\"name\": \"Grindfest\", \"id\": 18818}]   \n",
       "4788     [{\"name\": \"Dreamland Productions\", \"id\": 407}]   \n",
       "4789                                                 []   \n",
       "4790  [{\"name\": \"Jafar Panahi Film Productions\", \"id...   \n",
       "4791  [{\"name\": \"Park Films\", \"id\": 21871}, {\"name\":...   \n",
       "4792             [{\"name\": \"Daiei Studios\", \"id\": 881}]   \n",
       "4793        [{\"name\": \"Iconoclast Films\", \"id\": 26677}]   \n",
       "4794  [{\"name\": \"Gold Lion Films\", \"id\": 37870}, {\"n...   \n",
       "4795  [{\"name\": \"Asylum Films\", \"id\": 10571}, {\"name...   \n",
       "4796                 [{\"name\": \"Thinkfilm\", \"id\": 446}]   \n",
       "4797                                                 []   \n",
       "4798           [{\"name\": \"Columbia Pictures\", \"id\": 5}]   \n",
       "4799                                                 []   \n",
       "4800  [{\"name\": \"Front Street Pictures\", \"id\": 3958}...   \n",
       "4801                                                 []   \n",
       "4802  [{\"name\": \"rusty bear entertainment\", \"id\": 87...   \n",
       "\n",
       "                                   production_countries release_date  \\\n",
       "0     [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2009-12-10   \n",
       "1     [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2007-05-19   \n",
       "2     [{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...   2015-10-26   \n",
       "3     [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2012-07-16   \n",
       "4     [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2012-03-07   \n",
       "5     [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2007-05-01   \n",
       "6     [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2010-11-24   \n",
       "7     [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2015-04-22   \n",
       "8     [{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...   2009-07-07   \n",
       "9     [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2016-03-23   \n",
       "10    [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2006-06-28   \n",
       "11    [{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...   2008-10-30   \n",
       "12    [{\"iso_3166_1\": \"JM\", \"name\": \"Jamaica\"}, {\"is...   2006-06-20   \n",
       "13    [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2013-07-03   \n",
       "14    [{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...   2013-06-12   \n",
       "15    [{\"iso_3166_1\": \"CZ\", \"name\": \"Czech Republic\"...   2008-05-15   \n",
       "16    [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2012-04-25   \n",
       "17    [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2011-05-14   \n",
       "18    [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2012-05-23   \n",
       "19    [{\"iso_3166_1\": \"NZ\", \"name\": \"New Zealand\"}, ...   2014-12-10   \n",
       "20    [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2012-06-27   \n",
       "21    [{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...   2010-05-12   \n",
       "22    [{\"iso_3166_1\": \"NZ\", \"name\": \"New Zealand\"}, ...   2013-12-11   \n",
       "23    [{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...   2007-12-04   \n",
       "24    [{\"iso_3166_1\": \"NZ\", \"name\": \"New Zealand\"}, ...   2005-12-14   \n",
       "25    [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   1997-11-18   \n",
       "26    [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2016-04-27   \n",
       "27    [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2012-04-11   \n",
       "28    [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2015-06-09   \n",
       "29    [{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...   2012-10-25   \n",
       "...                                                 ...          ...   \n",
       "4773  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   1994-09-13   \n",
       "4774  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   1971-01-01   \n",
       "4775  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2002-09-20   \n",
       "4776  [{\"iso_3166_1\": \"CA\", \"name\": \"Canada\"}, {\"iso...   1997-01-19   \n",
       "4777  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2002-01-15   \n",
       "4778  [{\"iso_3166_1\": \"CA\", \"name\": \"Canada\"}, {\"iso...   2009-08-14   \n",
       "4779  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   1990-07-27   \n",
       "4780                                                 []   2015-10-02   \n",
       "4781  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2013-02-14   \n",
       "4782  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2003-01-01   \n",
       "4783  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2015-01-16   \n",
       "4784                                                 []   2005-01-17   \n",
       "4785            [{\"iso_3166_1\": \"KE\", \"name\": \"Kenya\"}]   2014-09-05   \n",
       "4786  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2009-03-14   \n",
       "4787                                                 []   2011-10-26   \n",
       "4788  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   1972-03-12   \n",
       "4789  [{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...   2004-09-01   \n",
       "4790             [{\"iso_3166_1\": \"IR\", \"name\": \"Iran\"}]   2000-09-08   \n",
       "4791          [{\"iso_3166_1\": \"IE\", \"name\": \"Ireland\"}]   2007-01-01   \n",
       "4792            [{\"iso_3166_1\": \"JP\", \"name\": \"Japan\"}]   1997-11-06   \n",
       "4793  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2004-04-11   \n",
       "4794  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2012-01-20   \n",
       "4795  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   1995-09-09   \n",
       "4796  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2004-10-08   \n",
       "4797                                                 []   2005-03-12   \n",
       "4798  [{\"iso_3166_1\": \"MX\", \"name\": \"Mexico\"}, {\"iso...   1992-09-04   \n",
       "4799                                                 []   2011-12-26   \n",
       "4800  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2013-10-13   \n",
       "4801  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2012-05-03   \n",
       "4802  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2005-08-05   \n",
       "\n",
       "         revenue  runtime                                   spoken_languages  \\\n",
       "0     2787965087    162.0  [{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...   \n",
       "1      961000000    169.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "2      880674609    148.0  [{\"iso_639_1\": \"fr\", \"name\": \"Fran\\u00e7ais\"},...   \n",
       "3     1084939099    165.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "4      284139100    132.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "5      890871626    139.0  [{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...   \n",
       "6      591794936    100.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "7     1405403694    141.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "8      933959197    153.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "9      873260194    151.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "10     391081192    154.0  [{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...   \n",
       "11     586090727    106.0  [{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...   \n",
       "12    1065659812    151.0  [{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...   \n",
       "13      89289910    149.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "14     662845518    143.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "15     419651413    150.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "16    1519557910    143.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "17    1045713802    136.0  [{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...   \n",
       "18     624026776    106.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "19     956019788    144.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "20     752215857    136.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "21     310669540    140.0  [{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...   \n",
       "22     958400000    161.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "23     372234864    113.0  [{\"iso_639_1\": \"is\", \"name\": \"\\u00cdslenska\"},...   \n",
       "24     550000000    187.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "25    1845034188    194.0  [{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...   \n",
       "26    1153304495    147.0  [{\"iso_639_1\": \"ro\", \"name\": \"Rom\\u00e2n\\u0103...   \n",
       "27     303025485    131.0  [{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...   \n",
       "28    1513528810    124.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "29    1108561013    143.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "...          ...      ...                                                ...   \n",
       "4773     3151130     92.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "4774           0     64.0  [{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...   \n",
       "4775       76901     85.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "4776           0     97.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "4777           0     78.0  [{\"iso_639_1\": \"es\", \"name\": \"Espa\\u00f1ol\"}, ...   \n",
       "4778           0     85.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "4779           0     97.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "4780           0     90.0                                                 []   \n",
       "4781           0     90.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "4782           0    120.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "4783           0     91.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "4784           0     85.0                                                 []   \n",
       "4785           0     60.0  [{\"iso_639_1\": \"sw\", \"name\": \"Kiswahili\"}, {\"i...   \n",
       "4786           0     88.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "4787           0     78.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "4788     6000000     93.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "4789           0    111.0  [{\"iso_639_1\": \"cn\", \"name\": \"\\u5e7f\\u5dde\\u8b...   \n",
       "4790           0     90.0  [{\"iso_639_1\": \"fa\", \"name\": \"\\u0641\\u0627\\u06...   \n",
       "4791           0     84.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "4792       99000    111.0  [{\"iso_639_1\": \"ja\", \"name\": \"\\u65e5\\u672c\\u8a...   \n",
       "4793           0     90.0                                                 []   \n",
       "4794           0     82.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "4795           0     98.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "4796      424760     77.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "4797           0     80.0                                                 []   \n",
       "4798     2040920     81.0      [{\"iso_639_1\": \"es\", \"name\": \"Espa\\u00f1ol\"}]   \n",
       "4799           0     85.0                                                 []   \n",
       "4800           0    120.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "4801           0     98.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "4802           0     90.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "\n",
       "        status                                            tagline  \\\n",
       "0     Released                        Enter the World of Pandora.   \n",
       "1     Released     At the end of the world, the adventure begins.   \n",
       "2     Released                              A Plan No One Escapes   \n",
       "3     Released                                    The Legend Ends   \n",
       "4     Released               Lost in our world, found in another.   \n",
       "5     Released                                 The battle within.   \n",
       "6     Released           They're taking adventure to new lengths.   \n",
       "7     Released                                A New Age Has Come.   \n",
       "8     Released                              Dark Secrets Revealed   \n",
       "9     Released                                 Justice or revenge   \n",
       "10    Released                                                NaN   \n",
       "11    Released      For love, for hate, for justice, for revenge.   \n",
       "12    Released                                      Jack is back!   \n",
       "13    Released                            Never Take Off the Mask   \n",
       "14    Released               You will believe that a man can fly.   \n",
       "15    Released                               Hope has a new face.   \n",
       "16    Released                            Some assembly required.   \n",
       "17    Released                        Live Forever Or Die Trying.   \n",
       "18    Released                          They are back... in time.   \n",
       "19    Released  Witness the defining chapter of the Middle-Ear...   \n",
       "20    Released                           The untold story begins.   \n",
       "21    Released     Rise and rise again, until lambs become lions.   \n",
       "22    Released  Beyond darkness... beyond desolation... lies t...   \n",
       "23    Released  There are worlds beyond our own - the compass ...   \n",
       "24    Released                    The eighth wonder of the world.   \n",
       "25    Released          Nothing on Earth could come between them.   \n",
       "26    Released                                    Divided We Fall   \n",
       "27    Released                 The Battle for Earth Begins at Sea   \n",
       "28    Released                                  The park is open.   \n",
       "29    Released                                Think on your sins.   \n",
       "...        ...                                                ...   \n",
       "4773  Released  Just because they serve you doesn't mean they ...   \n",
       "4774  Released             A unique experience in visual fantasy!   \n",
       "4775  Released                                                NaN   \n",
       "4776  Released      Are all men bastards...or just misunderstood?   \n",
       "4777  Released                                                NaN   \n",
       "4778  Released                             Vengeance is ruthless.   \n",
       "4779  Released                                                NaN   \n",
       "4780  Released                                                NaN   \n",
       "4781  Released       Getting divorced does funny things to a girl   \n",
       "4782  Released                                                NaN   \n",
       "4783  Released                                         nederlands   \n",
       "4784  Released                                                NaN   \n",
       "4785  Released                                                NaN   \n",
       "4786  Released                                                NaN   \n",
       "4787  Released                               May The Best Man Win   \n",
       "4788  Released                         An exercise in poor taste.   \n",
       "4789  Released          When you don't have a choice, you change.   \n",
       "4790  Released                                                NaN   \n",
       "4791  Released                    Everything You've Heard is True   \n",
       "4792  Released                           Madness. Terror. Murder.   \n",
       "4793  Released              Two gangs. One secret. One crossroad.   \n",
       "4794  Released                                                NaN   \n",
       "4795  Released            Sometimes you've got to break the rules   \n",
       "4796  Released                 What happens if it actually works?   \n",
       "4797  Released                                                NaN   \n",
       "4798  Released  He didn't come looking for trouble, but troubl...   \n",
       "4799  Released  A newlywed couple's honeymoon is upended by th...   \n",
       "4800  Released                                                NaN   \n",
       "4801  Released                           A New Yorker in Shanghai   \n",
       "4802  Released                                                NaN   \n",
       "\n",
       "                                            title  vote_average  vote_count  \n",
       "0                                          Avatar           7.2       11800  \n",
       "1        Pirates of the Caribbean: At World's End           6.9        4500  \n",
       "2                                         Spectre           6.3        4466  \n",
       "3                           The Dark Knight Rises           7.6        9106  \n",
       "4                                     John Carter           6.1        2124  \n",
       "5                                    Spider-Man 3           5.9        3576  \n",
       "6                                         Tangled           7.4        3330  \n",
       "7                         Avengers: Age of Ultron           7.3        6767  \n",
       "8          Harry Potter and the Half-Blood Prince           7.4        5293  \n",
       "9              Batman v Superman: Dawn of Justice           5.7        7004  \n",
       "10                               Superman Returns           5.4        1400  \n",
       "11                              Quantum of Solace           6.1        2965  \n",
       "12     Pirates of the Caribbean: Dead Man's Chest           7.0        5246  \n",
       "13                                The Lone Ranger           5.9        2311  \n",
       "14                                   Man of Steel           6.5        6359  \n",
       "15       The Chronicles of Narnia: Prince Caspian           6.3        1630  \n",
       "16                                   The Avengers           7.4       11776  \n",
       "17    Pirates of the Caribbean: On Stranger Tides           6.4        4948  \n",
       "18                                 Men in Black 3           6.2        4160  \n",
       "19      The Hobbit: The Battle of the Five Armies           7.1        4760  \n",
       "20                         The Amazing Spider-Man           6.5        6586  \n",
       "21                                     Robin Hood           6.2        1398  \n",
       "22            The Hobbit: The Desolation of Smaug           7.6        4524  \n",
       "23                             The Golden Compass           5.8        1303  \n",
       "24                                      King Kong           6.6        2337  \n",
       "25                                        Titanic           7.5        7562  \n",
       "26                     Captain America: Civil War           7.1        7241  \n",
       "27                                     Battleship           5.5        2114  \n",
       "28                                 Jurassic World           6.5        8662  \n",
       "29                                        Skyfall           6.9        7604  \n",
       "...                                           ...           ...         ...  \n",
       "4773                                       Clerks           7.4         755  \n",
       "4774                               Pink Narcissus           6.0           9  \n",
       "4775                                  Funny Ha Ha           6.3           8  \n",
       "4776                        In the Company of Men           6.8          44  \n",
       "4777                                       Manito           5.5           2  \n",
       "4778                                      Rampage           6.0         131  \n",
       "4779                                      Slacker           6.4          77  \n",
       "4780                                  Dutch Kills           0.0           0  \n",
       "4781                                    Dry Spell           6.0           1  \n",
       "4782                                     Flywheel           6.8          19  \n",
       "4783                                     Backmask           4.7          79  \n",
       "4784                              The Puffy Chair           6.2          15  \n",
       "4785                         Stories of Our Lives           0.0           0  \n",
       "4786                             Breaking Upwards           5.6          12  \n",
       "4787                     All Superheroes Must Die           4.2          13  \n",
       "4788                               Pink Flamingos           6.2         110  \n",
       "4789                                        Clean           6.7          17  \n",
       "4790                                   The Circle           6.6          17  \n",
       "4791                                  Tin Can Man           2.0           1  \n",
       "4792                                         Cure           7.4          63  \n",
       "4793                               On The Downlow           6.0           2  \n",
       "4794                 Sanctuary: Quite a Conundrum           0.0           0  \n",
       "4795                                         Bang           6.0           1  \n",
       "4796                                       Primer           6.9         658  \n",
       "4797                                       Cavite           7.5           2  \n",
       "4798                                  El Mariachi           6.6         238  \n",
       "4799                                    Newlyweds           5.9           5  \n",
       "4800                    Signed, Sealed, Delivered           7.0           6  \n",
       "4801                             Shanghai Calling           5.7           7  \n",
       "4802                            My Date with Drew           6.3          16  \n",
       "\n",
       "[4803 rows x 20 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./tmdb_5000_movies.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameTitle2genre = {(row[\"original_title\"],row[\"overview\"]) : list(map(lambda x: x[\"name\"],json.loads(row[\"genres\"])))\n",
    "                   for index,row in df.iterrows()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genre distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LetÂ´s take a look at the frequency of each genre..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAE9CAYAAAACk7UUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3XecZFWZ//HPlyEqWQZEgoM4iGBAHBGEdUEUCQZcRQEDYsAEghnDb0HUXQwYwAUlKSoiKLqiIjA7EkSCDDAkBZkFFAQJEhdM4PP74zk1U91TXXVvVXWYvt/361Wv6b5dp+6p6a773HPOc85RRGBmZs2zzGRXwMzMJocDgJlZQzkAmJk1lAOAmVlDOQCYmTWUA4CZWUM5AJiZNZQDgJlZQzkAmJk11LKTXYFu1lprrZg1a9ZkV8PMbKly+eWX3xMRM3s9b0oHgFmzZjF//vzJroaZ2VJF0u+rPM9dQGZmDeUAYGbWUA4AZmYN5QBgZtZQDgBmZg3lAGBm1lAOAGZmDeUAYGbWUA4AZmYNNaVnAtvEm3Xwz2o9/5bDdxunmpjZeHMLwMysoRwAzMwaygHAzKyhHADMzBrKAcDMrKEcAMzMGsoBwMysoRwAzMwaygHAzKyhHADMzBrKAcDMrKEcAMzMGsoBwMysoRwAzMwaygHAzKyhHADMzBrKAcDMrKEcAMzMGsoBwMysoRwAzMwaygHAzKyhHADMzBqqZwCQtIGkcyX9VtJ1kg4sx9eUNFfSjeXfNcpxSTpS0kJJV0vasu219inPv1HSPuP3tszMrJcqLYBHgQ9ExNOBrYH3SNoMOBiYFxGzgXnle4BdgNnlsR9wDGTAAA4Bng9sBRzSChpmZjbxegaAiLgjIq4oXz8E/BZYD3glcFJ52knA7uXrVwLfinQJsLqkdYGXAnMj4t6IuA+YC+w81HdjZmaV1RoDkDQLeA5wKbBORNwBGSSAtcvT1gNubSt2Wzk21vHR59hP0nxJ8+++++461TMzsxoqBwBJKwOnAwdFxIPdntrhWHQ5PvJAxLERMSci5sycObNq9czMrKZKAUDScuTF/+SI+GE5fGfp2qH8e1c5fhuwQVvx9YHbuxw3M7NJUCULSMAJwG8j4ottPzoDaGXy7AP8uO34m0o20NbAA6WL6GxgJ0lrlMHfncoxMzObBMtWeM62wBuBayQtKMc+BhwOnCbprcAfgD3Kz84EdgUWAo8A+wJExL2SPgVcVp53WETcO5R3YWZmtfUMABFxIZ377wF27PD8AN4zxmudCJxYp4JmZjY+PBPYzKyhHADMzBrKAcDMrKEcAMzMGsoBwMysoRwAzMwaygHAzKyhHADMzBrKAcDMrKEcAMzMGsoBwMysoRwAzMwaygHAzKyhHADMzBrKAcDMrKEcAMzMGsoBwMysoRwAzMwaygHAzKyhqmwKb2ZjmHXwz2qXueXw3cahJmb1uQVgZtZQDgBmZg3lAGBm1lAOAGZmDeUAYGbWUA4AZmYN5QBgZtZQDgBmZg3lAGBm1lAOAGZmDeUAYGbWUA4AZmYN5QBgZtZQDgBmZg3lAGBm1lAOAGZmDdUzAEg6UdJdkq5tO3aopD9KWlAeu7b97KOSFkq6QdJL247vXI4tlHTw8N+KmZnVUaUF8E1g5w7HvxQRW5THmQCSNgP2BDYvZY6WNEPSDOC/gF2AzYC9ynPNzGyS9NwSMiIukDSr4uu9EvheRPwNuFnSQmCr8rOFEXETgKTvlef+pnaNzcxsKAYZA9hf0tWli2iNcmw94Na259xWjo11fAmS9pM0X9L8u+++e4DqmZlZN/0GgGOAjYEtgDuAI8pxdXhudDm+5MGIYyNiTkTMmTlzZp/VMzOzXnp2AXUSEXe2vpZ0HPDT8u1twAZtT10fuL18PdZxMzObBH21ACSt2/btq4BWhtAZwJ6SVpC0ETAb+DVwGTBb0kaSlicHis/ov9pmZjaoni0ASacA2wNrSboNOATYXtIWZDfOLcA7ACLiOkmnkYO7jwLviYjHyuvsD5wNzABOjIjrhv5uzMyssipZQHt1OHxCl+d/BvhMh+NnAmfWqp2ZmY0bzwQ2M2soBwAzs4ZyADAzaygHADOzhnIAMDNrKAcAM7OGcgAwM2soBwAzs4ZyADAzaygHADOzhnIAMDNrKAcAM7OGcgAwM2soBwAzs4ZyADAza6i+toQ062TWwT+r9fxbDt9tnGpiZlW4BWBm1lAOAGZmDeUAYGbWUA4AZmYN5QBgZtZQDgBmZg3lAGBm1lAOAGZmDeUAYGbWUA4AZmYNNa2XgvDSBGZmY3MLwMysoRwAzMwaygHAzKyhHADMzBrKAcDMrKEcAMzMGsoBwMysoRwAzMwaygHAzKyhegYASSdKukvStW3H1pQ0V9KN5d81ynFJOlLSQklXS9qyrcw+5fk3StpnfN6OmZlVVaUF8E1g51HHDgbmRcRsYF75HmAXYHZ57AccAxkwgEOA5wNbAYe0goaZmU2OngEgIi4A7h11+JXASeXrk4Dd245/K9IlwOqS1gVeCsyNiHsj4j5gLksGFTMzm0D9jgGsExF3AJR/1y7H1wNubXvebeXYWMfNzGySDHsQWB2ORZfjS76AtJ+k+ZLm33333UOtnJmZLdZvALizdO1Q/r2rHL8N2KDteesDt3c5voSIODYi5kTEnJkzZ/ZZPTMz66XfAHAG0Mrk2Qf4cdvxN5VsoK2BB0oX0dnATpLWKIO/O5VjZmY2SXpuCCPpFGB7YC1Jt5HZPIcDp0l6K/AHYI/y9DOBXYGFwCPAvgARca+kTwGXlecdFhGjB5bNzGwC9QwAEbHXGD/ascNzA3jPGK9zInBirdqZmdm48UxgM7OGcgAwM2soBwAzs4ZyADAza6ieg8BmNn5mHfyzWs+/5fDdxqkm1kRuAZiZNZQDgJlZQzkAmJk1lAOAmVlDOQCYmTWUA4CZWUM5AJiZNZQDgJlZQ3ki2Bg8QcfMpju3AMzMGsoBwMysoRwAzMwaygHAzKyhHADMzBrKAcDMrKEcAMzMGsoBwMysoTwRbJrxBDYzq8otADOzhnIAMDNrKAcAM7OGcgAwM2soBwAzs4ZyADAzaygHADOzhnIAMDNrKAcAM7OGcgAwM2soBwAzs4ZyADAzaygHADOzhhpoNVBJtwAPAY8Bj0bEHElrAqcCs4BbgNdGxH2SBHwF2BV4BHhzRFwxyPmnK6/oaWYTYRgtgB0iYouImFO+PxiYFxGzgXnle4BdgNnlsR9wzBDObWZmfRqP/QBeCWxfvj4JOA/4SDn+rYgI4BJJq0taNyLuGIc6WMM0sdXUxPdswzVoCyCAcyRdLmm/cmyd1kW9/Lt2Ob4ecGtb2dvKMTMzmwSDtgC2jYjbJa0NzJV0fZfnqsOxWOJJGUj2A9hwww0HrJ6ZmY1loBZARNxe/r0L+BGwFXCnpHUByr93laffBmzQVnx94PYOr3lsRMyJiDkzZ84cpHpmZtZF3wFA0uMlrdL6GtgJuBY4A9inPG0f4Mfl6zOANyltDTzg/n8zs8kzSBfQOsCPMruTZYHvRsRZki4DTpP0VuAPwB7l+WeSKaALyTTQfQc4t5mZDajvABARNwHP7nD8z8COHY4H8J5+z2dmZsPlmcBmZg01HvMAGq9ufjY4R9vMJp5bAGZmDeUAYGbWUA4AZmYN5QBgZtZQDgBmZg3lAGBm1lBOAzVrKC8nbW4BmJk1lAOAmVlDOQCYmTWUA4CZWUM5AJiZNZQDgJlZQzkAmJk1lAOAmVlDOQCYmTWUA4CZWUN5KQibEryLmtnEcwvAzKyhHADMzBrKXUBmVptXEp0eHADMbKni4DM87gIyM2soBwAzs4ZyADAzayiPAZjZhPKcj6nDLQAzs4ZyADAzayh3AZlZYziFdCS3AMzMGsotAGs83xVaU7kFYGbWUA4AZmYN5QBgZtZQEx4AJO0s6QZJCyUdPNHnNzOzNKGDwJJmAP8FvAS4DbhM0hkR8ZuJrIeZWV3TcQbzRLcAtgIWRsRNEfF34HvAKye4DmZmxsSnga4H3Nr2/W3A8ye4DmZmE24qphsrIsb9JItOJu0BvDQi3la+fyOwVUQc0Pac/YD9yrdPA24Yh6qsBdwzCWUn89yud3PO7Xo369ydPDkiZvZ8VkRM2APYBji77fuPAh+dyDqU886fjLKTeW7Xuznndr2bde5BHhM9BnAZMFvSRpKWB/YEzpjgOpiZGRM8BhARj0raHzgbmAGcGBHXTWQdzMwsTfhaQBFxJnDmRJ93lGMnqexkntv1bs65Xe9mnbtvEzoIbGZmU4eXgjAzaygHADOzhvJ+AFOcpPWAJ9P2u4qICyavRt1JWgZ4TUScNtl1salNkoD1I+LWnk+2ceEWQA9Kb5D07+X7DSVtVfM1ZvR57s8CvwI+AXyoPD7Yx+s8vp/z9yMi/gnsP8hrSJoh6Unl/3pDSRvWLH+6pN1KMJowkvaXtMYQXqfW76v8f/3PgOd8Wb//X5LW7Kdc5ADkf/dTdhgGec8DnncTSfMkXVu+f5akT0x0PaAhAUDSTEkfk3SspBNbj4rFjyYnsO1Vvn+IXNCujoWSPi9ps5rldgeeFhG7RsTLy+MVVQtLeoGk3wC/Ld8/W9LRNcrPlvQDSb+RdFPrUaHoXEkflLSBpDVbj4rnPAC4E5gL/Kw8flq1zsUxwN7AjZIOl7RpxXNvK2mupN+V93pzxffb8kRygcPTyqq3qlPpfn9fEfEY8Iik1eqcb5Q9yf+vz0l6es2yl0r6vqRd675n4BJJz6tZZpHy+1q97fs1JJ1dsfgg77l1IT9O0jmSftF6VCh6HDkJ9h8AEXF1qcvEm6wZaBP5AC4CPgu8Fnh161Gx7BXl3yvbjl1V8/yrAG8v9biEXOpi1Qrlfg6sPMD7vhTYYFTdr61R/kJgR+BqshvqUOCTFcrd3OFxU8VzLgSeMKTf+2rAO8n1py4C9gWW6/L864FdgLWBJ7QeNc8p4KXkQocLgf8ANh7v3xdwGvAH4ATgyNajZt1XBd5R/kYvLn+nq1R8zy8BTgH+t7znTSqe8zfAo6Xc1cA1wNU16nxllWPDfs+l7FXAu8hFLp/belQod9noegILhvE3X/fRlDGAx0XER/os+4/ShZN/6dJM4J91XiAiHiKj/nGSXkh+UL4k6QfApyJi4RhFHwEWSJoH/K3t9d5b49y3jrope6xG1VeKiHmSFBG/Bw6V9EvgkB7n3KjGOUa7FXhggPIASHoC8AbgjcCVwMnAdsA+wPZjFHsgIn4+yHkjIiT9CfgTeWFbA/iBpLkR8eEK5fv9fbVaS32LiAclnQ6sBBwEvAr4kKQjI+KoLuWCbLHNlbQD8B3g3ZKuAg6OiIu7nHaXQeoM/FPShhHxBwBJT6Z8Vqvo9z0Xj0bEMX3U+R5JG7P4mvIa4I4+XmdgTQkAP5W0a+QktLqOBH4ErC3pM8BryD75ykoA2Y28A50FHEFekP6FnBS3yRhFz2CwpTJulfQCIMrSG++ldC9U9NfSR3pjmcH9R/LuuCtJjwPeD2wYEftJmk12ZVXpyrkJOE/SzxgZ9L5YtdKSfghsCnwbeHlEtD5cp0qa36XouZI+D/xw1LmvqHje95IB5h7geOBDEfGP1v8h0CsA9P37ioiTSpnW39INEfGPKmVL3V9B/n1uTP6/bRURd5Xf5W+BMS+Go4LtncAB5N/tFsD3gTFvCMqNBZLWBlasWt82HwculHR++f6FLF5MsqtB3nPxE0nvJq8P7X8v9/Yo9x5y8temkv5ItpDfUKXOw9aIiWCSHgIeD/yd0u9G3risWrH8pmRXiIB5EVHnIkrpRz4XOCEiLhr1syO73dEP+KFeC/gK8OJS93OAAyPizxXLP4/8IKwOfIrsUvlcRFzSo9ypwOXAmyLiGZJWAi6OiC0qnLNj6yIiPlmlzuU1XhQRVfpiR5c7t/Op40UVyx9G/o5/3+FnT+/1dzPI70vS9sBJwC2l7AbAPlExY0zSSaXuSzxf0o4RMa9L2d+RF9BvRMRto372kYj4bJeyryBviJ4E3EV2Nf42IjavUu/yGmsBW5Pv++KIqLSy5iDvuTzn5g6HIyKeUvH8jweWKT0Ek6IRAaBf5c7t6oh4xoCvs3JE/F8f5bZngA/1ZJE0PyLmSLoyIp5Tjl0VEc+u8RqrkB+myv9vkv6t288j4oddyvadvtprgLvCHeHAJF0O7B0RN5TvNwFOiYjnVig7g1yl98V9nHcG8PmIeH/dsqX8VcCLgP+JiOeULqS9IqLrXbykTSPieklbdvp5r1bbIO+5X5LeEBHfkdTx/6pOK3dYmtIF1LrTeGH59rwq3RER8U9JV7X3Mfbp3yV9GvgLcBbwbOCgiPhOj3JHADuN/lCTg009SdqIbI7PYuQ8gkqZRJLmkE3s0fMQntWj6N/LXX+rj3Nj2prIPc75DPJucs3y/T1kS6LKooEv7/KzILt2Ov8wf9f7k4OpdV1eXl/AhsB95evVyYHZSmMi5Y70wIi4v3y/BnBERLylQvHlWn8nABHxO0nLVTlvRDwm6RFJq0VErfGXUrZyYO/gHxHxZ0nLSFomIs5Vpj/38n6yq+eITtUig8qYBnnPLWPccDwAXBMRd3X4WSu9d5V+zjceGhEAJB0OPI/sdwc4UNJ2EVFlU/p1gesk/Rp4uHWw6kW02CkiPizpVeQuaHuQXUK9AkDfH+riv8mskJ9Qc+C6OJmce3BNzfKHkIFuA0knA9sCb65Y9ljg/RFxLixqBR0HvKBXwYjYt0YdO5kr6YPAqYz8XXe9g28Nekv6GnBGa6xJ0i5kd05Vz2pd/Mvr3ifpORXLzpd0Ahk8AV5PBqaq/gpcI2kuI997lYSDBZLOIPv728uOGXDb3C9pZeCXwMmS7iIHz7tqtRAiYocK5xjLIO8Z4K1kinir63B7MptoE0mHRcS3258cEV8vXx4dEXcPUO+haUQXkKSrgS0iJym1mn9XVriTRdK/djoeEed3Oj7Ga1wXEZtLOg44PSLOqtIlopyrEIz8UC9b9UIn6dKI6HvLTUkXRsR2fZZ9Aov7ZS+p0S+7xP9L1e6jQZvYQ+jTvXx0l0urO6xi+auA7SPivvL9msD5EfHMCmVXIAcXtyP/zy8gLzRVW177dDoeESdVKPuNzkXHbrlIOoic5PhbMtttGfLvezXg5BrjVHsAZ0XEQ8rJVFuSmXVXVijb93su5X8CvC0i7izfr0POQXkbcMFYXceSbiQHfk8Fftj6fU+GRrQAitWB1p1c5QkzdS70XfxE0vVkF9C7lamkf61Q7l3kh/q9tH2oa5z3K2VQ9Rz6yGoBDpF0PDA6DbXjnV2H/thW9s2GpRutynlvkvT/WBz03kB+WKoYqIkdg6WvQqb3fYJs2QVZ90oXsuII4CJlejBkS/EzvQqVG5oTIuINQF/9yJFZRCuRmVu1tmHts+W1PjngvSmZ/38RGRB+UnPM5P9FxPclbUfOv/gC8DUq7DVe9ULfxazWxb+4i5z/cK+kMZM1ImK2cjWBPYGPKyf/fa9Cl/DQNaUFsBdwONlUEzkW8NGI+F6Fsg+xOK94eWA54OGomEHU9jprAA+WvsfHkRPB/lTnNeqS9J9kat7/srgLJ6J6Vst3yA/odaPKd7yzU+csmpZK5y3/T59k5J3soRNxl6TB0ldbd+yHkH9fQdb9sDoXNEmbAzuwOOPsNxXLnU2mvP696rlGlX85efFcPiI2krQFWfeeXZ2S1idTJrcl3/eF5FjGbV0LsijLbQ7ZxbdNedwfEZVmzbcSDcrf+jUR8d325IMeZWcD/wlsRlsKao0W39HkmM/3y6FXk128HwJ+WqV7SpnB9EXg9RHR15Ixg2hEAACQtC45DiDg0n4vvpJ2J/OFP1az3DNY8g/tW2M897SIeK2ka+gwqaVK11V5nevJfuV+LwrXVOl+mGr6HfzWAOmro16nr6yvUnYGsA4j690zAUHS18nujzMY2Z9dqUWgzCJ6EZkg0crcqvT7L33o32Vkq+31EfGSCmVXIy/625Z/Vycv5FW7OX9Kzk95MZkc8Rfg1xW7DC8kA/aXyASCfclrYteJjm3lRV70tyWvKxeSXbxdL6qSViUnnO1JzkH4EXBaRNQZsxmKaR0ANGCqWJfXvSQitq7x/EPIAaLNyIlfuwAXRsRrxnj+uhFxh3JW4xKiQ575GK9zKnDAGBkJVcofB3ypxl3oIGmYX46Ig0q/aqegV2cNpKvIwe8Rg9e9uvM0YPqqchLX8eTyHRsqs2PeERHvrlj+APKCdCc5A1hZ7UpjVQPNn2iNF41671dXPPeC0UGy07FRPz8W2JxcW+tScvD0krotvdJq25kMGjeWG71nRsQ5FcpeHhHPbQ90kn4ZEf9Spw51lbGm/yYv+t1mSY+76T4GMFCqGCxxUVuGbK7WjZqvIVM/r4yIfctg0fFjPTkWz1x9d4xawkKZIld1WYt1gOslXcbIPvyqF9PtgH3KH+zf6H1B6jsNk8V3j1+oWLdu/hoRR/ZRru/01eJLZD/0GQARcZVy6Y+qDiS7nOqMG7RaDStHxIfqlBvlWkl7AzNK18h7yX75Ku6R9AYyRRly4cRe72FDYAVyhvQfya6T+7uW6GwtYD6AFq8ae33Fsv3OdL8wIrYb1T0Miz8fvbqHnxIRIWmVQVqLwzCtWwAtklaMiL/2OjZG2fYMh0fJSVnH1bmrlvTriNiqNLN3IO96ro0esx0lXRERW446VumurDx3oAymQVsg/ZB0YER8pdexHq+xNzCbmoPfknYi5z1sVspuC+wbJSW1wnk73UXXaUGcC7wkInqmQXYoOy8idqxbrq3848j3vlM5dDaZTdMzAJYL71fJLpwgA8d7e3VdlS6Uzcn+/xcAzyATNS6u0Q3T6iYV2b26ETljvudMYi05031Vcqb7pVXO3S+NnOsi4G5ygue143neTqZ7C6DlIrJ/tNexTo6PiF+1H5C0LTniX9V85ZK1x5F9zP8H/HqsJ0t6F/BuYGNlCmvLKlS/Kxs4gylqrtOi4cx03IfMDmn35g7HunkmOfj9ItoGr+k9OeicEqRb6asHRsX01WLQtZcGWQdpkFx8gN0i4uNkEAAWpVh+f+wii2wwulVZPiNdA0DpK79W0v3kBKoHgJeRq2tWCgCjxyhKd+87qpQls3guIz+P+5bye5BdUpUos49mR8Q3yoDuKhHRK2ut01yXY6kw12XYpnULQNITgfXItLy9yQ81ZKT/WkT0XCd+jLvwJY7VqNMsMgPo6i7PWY1cRfI/gfbJag9FhYySITRRW69Ta50WSe+IiK/30x+tzNTam+x2+mXbj1YBHosaU/b7HfzudBdd585ag6+91Hc/vvrIxR9Vvu+/837KKhfOewHZyvoHmQJ6cfn3mihzdvoxnvUe9dxDyC7hp0XEJpKeBHw/IrbtUa7vuS7DNt1bAC8l7x7XJy9krQDwINA1i0fSNuQf6MxRd7SrArXStdovIhFxy+hjo0VOTX9A0leAe6MsFlX6DJ/fq4kaZfJWRAw65fxT5N3wiHVaupz366U/+sGI+FLNc11EzhtYi5FjNg+ReeJ1XEU26yu10iStCDwOWEuZhtp+o/CkqictrYXX16vqiPKVF7zrULavWdDK2cq7AutJah83WZUeM3IH/IzMAn4AvK9tzKu2UeddhmzVd51lO8h7HuVVwHOAKwAi4nblGla9DDLXZaimdQCInOhxkqRXR8TpNYsvD6xM/h+1/1IfJAd1exrCheUYRnZTPdzh2FjnHsZCdrXXaYmc5/AKckC0stLd9HuyH3lQdQe/30GuBf8ksouu/Uah8u5vGnztpZnkktGbMzJduEqyQr+5+LeTg6ivYOTSEQ8B7+tRtu/PSPS5eFwH7ed9lNwToddnfZD33O7vZTC3lTRQdSvPt5BzXX4Ii+a6DLqMSV+mdRdQi6T/IAd32hfZ+kBE9FzXX9KT+x30lHQgiy8sf2TkheW4iPhqj/Kd0uvqDAKfTE5462shO+U+s7uTXVFrkXfUz4uIrn2Vyn0TVmPJNXV6pt1K2pq8kD2dvMDMoObEu34HvyUdEL03AelWvq/007by55D/Zx8kdzLbB7g7KmxmpAFy8Uv55aIsNV4+Hxt066YcVXbRZ6TceKwcEQ9WKTuZ2t9zn+U/SCYbvIT8jLwF+O4gf0MTrSkBYImZgTX6CTchP5CzGHlXV2k2bXmNvi4syo1NziPv+iEHhneIiN0rlv8FOfmtr4Xsyh3NX6i5TosGWFdfuWHLnuTg4xzgTcBTywDluFLndWU+XSVwlfKDrr3UyktfFOQlnR8RHQPaqLK1c/FHPfc88o54WWAB2Y1yfpU7dUnfJQPWY+Qd9WrAFyPi81XO3Y8y4D2mKn/jZaD6UBavdtsaI6s0E7i8xkvIzCmRy0vPHc86D9u07gJqM0PSClFS2pS53itULPt9cm2R46m3neIiEXFUyQ6Zxcgg0nEmcJt3kjuSfYJs1s+jwm5Hkp5KdoOM7lP+V7Il0lPpy/9xGXz9J7kvQSUx2AqNRMRCSTMiNzv/hqTKmU8wUCui07oyx1BhXZli0LWXWnejd0jajeyqWL9i2X5y8dutFrk94tvIjV0O0cgMtG42K2VfT050/AgZCMYtAJBdhbeS7/dSFreu6ziB7PK5nJqfbY3cT2DMi/4ow6jzUDUlAHwHmNeWKbEv1S9o/e77uYikb5NTvhew+A8tgK4BIHKuwZ59nPLLwMdGN+ElPUym153Q6wVigPXSlStTvpolA95hFYo/okyhXCDpc+TAcNW+1ZavsmQrYnaFcq3fzW7AMRHxY0mH1jhvX+mnbT6tzAD7ABnAVqV6n/RbyPf9JRbn4lfKACqWVc6ifS1tqaAVLadcpnx34KuR22COd9fCE8mul1b22M/IDXCq7BvR0vce0H1+PoZR56FqRACIiM+Vu5lWet5ZZLOvin73/Ww3h7xLqvShkPThUuej6LwsQq/1ymd16r+NiPnKNNSq+l0v/cdkTvfl1JtJC3kBnQHsT178NiCDSS19tiL+qFxT58XAZ0sgW6bGaV9FzvLsa+2lWLzo3APkhME6Zf9AduH06zBy8teFEXGZpKeQs3Sr+DoJDwP8AAAN+UlEQVQ5QfIq4ALlBMJxHQMov9ezgLPK72kvcg7FYTW6WwfaA5qan48h1XmoGhEAij+Rd2WvJVOuqmYFtdYMb59mH0DlfkLgWjL6V013a00e6raBeTfdJm2tVON1flYeda0fETv3Ua59lvFfWLILq6p+WxGvJdeV+UJE3F/uiOssr1Ar/XS0frKIxrpJaCtbdXOTeRGxaNJXRNxExcAbuexGezrl70vK8LgqF9HdyAvprFKHqhPfYHHXXvt+DXVabLU/H0Oo81BN6wBQBnD3ZHF/6KnkwHflP84YfI14yAya3yh3FauSlvjz8vN+1yu/TNLbI+K49oOS3kqNXaIi14ifWb6us4PRRZKeGRHX1CjTquPLyPkHowfm6iy//Ubyzr1WKyIiHlHuSLUdeff7KNXvgmHwtZf62cGt/Sbhk1ScQdvBpZIWAN8Afl6ltaoeM7/pc2+CKpTbZz6D/Kx8MvpYRmEIY1UnlRuNTcqhG7plFQ2jzsM2rbOAJP2TnFX61ohYWI7dVHOUf6A14str1EpLbM9QknRURBxQ9VylzDpkl9XfWXzBn0MOiL4qeiyFLUnkhWR/8gK8DHkxPKpbP76ka8kL17Jkn/tNVFtErv01FgL/Rs4GrfXHqQH3blafMzvbyg+69tKgWUSV1sEfo6zIrq+3kEsxnAp8MyJ+16VM3zO/B1U+261ul75mu5fPyX8AT4qIXSRtBmwTET3HyEr57cmxxFvKeTcg1/S5YLzqPHQRMW0fZJ/sqeTI+3HAjsDNNV/jVHJyzrXl+5WABeNc7yvbvr5igNfZgexSOAB4UY1y7yMzGzZqO/YUso/4fV3K3UfeuXd8VDz3ucAyfb7fK9q+Pr2P8gvID2P7///VNV9jHXI9m5cBa9csuzcZeLchU1C3BLbs5/0P+Pe3A5ktdj9wPnlRHJe/9cl8kHfirwWuKt8vS954VC1/OXmz0Pp+E+DyyX5fdR7TugsoIn4E/Kjks+9OXtjWkXQM8KOosGY4sHFEvE65Vg0R8Zdyt1RZH2mJQ2mWRS42VWkly1HeRK5KuWghtIi4qaQZnsPYs3xvjsFXCv0wcKak86m/IFr776XOGE1LvzM7Kc9/LZn6eF6py1GSPhQRP+hacLFBs4j6ptzD+Q3l/HeSNw1nAFuQ2VRLdIVq5DIKS4jq4w+TZa2IOE3SRwEi4lFJddJBl4u27TMj4nclG2qpMa0DQEtEPAycDJys3LZvD3KRtSoBYNA14qF+WuKmJWtJjFwRtHJXyoCWiw6rYEbE3T3+wNfu0h9c9SL+GXJ1xhXJYFlHjPF1VaeVLKDVJb2d7A45rkeZdh8nZ0rfBYuWdvgfcs2bKmpnEWnkgn+Pk9TKvqnbrXAxOYt49xi5fMR8SV8bo0z7eNIg4w+T5eES+Fqf7a3JDKyq5ks6gcWzr19PjTG2qaARAaBdZPrm18ujikPJ1K0NlEsrbEsuMFf3vHXSEp9e9/WHrNsFqNvPZpBrwwwywWXNiNip99M6ena5AApYqerFUNJB5CqUXya7Px4Engb8e3SZ2dnBMjFyn4g/Uy+NtHYWUQy+4F/L06L0Y3Q4R8f1n6ItSUHSQTH4JusT7f1kK2djSb8CZlJxna/iXcB7yGW/W2v6HD3sSo6naT0IPCzlLqG1Rvwlne6Oe5S/gBxgO55MR70DeHNMwvKvVZRm8MOdfgSsGBEdWwEaYJnsttc4HPhFxe65oZD0BXJVy03JlUcvoixPHPU2dP888CwWz8Z9HTmGUGkHN+VyDM8C+s0iqk1DWp5gGL/7ySBpWTLYix5ZPG1l+ko2kPRVcq2gWjPbx5MDQA/lA3IKcEbpSurnNZ5M9qsuT45DrAYcHSUzaboYJAul7TUeInP2/0YujTBhGRIlpW8OGQy2KY/7I2KzHuWeCqwTEb9SbiG6HVnv+8i1k/634vkHyiLqh6S76bI8QdVzL40BQLmcw24sOe+ia1flqCy90yOi0nwJ5eKQewLrksklp0TEgv5qPxwOAD2UD+XryD+UX5O/uJ9Gte0kB0pLXNpIWrPOHfNUo1yGYRuym28bsjvmmuix1r6kn9J56Y05wCER0W2v5NGvtQ65gB/Ar6PG1qP9KBfB1vIEz6LG8gSjxx+AR1o/YrLSGmuQdCZlNi8jV2/tmr6qkVt+1r7pKTeEe5bHimTw/V50SbkdLw4AFZUPyouAtwM7V/nj7vdOYdRrrETOQbih55OXYpI2jYjrlVv6LSGqT8/v59zHkmvwP0TeBV9CdvXdV7H8tTHGvguSrolR2xZ2eZ3RWUT/AtTJIhqIFi9P8Hlg0pYnmCiqsbT6qHLtn+uBWj6SngOcSO5gV2ujqWFo3CBwP8pF+OVkS2BLqi8kN1BaoqSXkytSLg9sJGkL8oM54cvGToD3kyudHtHhZ+OdCrkhuTrsjWT++21kDnxVw1p6Y9Asor5oii1PMIF+LmmnPsab+ko2aCmZdDuTLYAdybkW4zZprhsHgB4knUquGXIWuTvUeVF9v9JB0xIPJWdlngcQEQtUbzG3pUZE7Ff+Hfc1ZDqce+cyt2Nzsv//A8AzJN1LDgT3Sm8cytIbDJ5FVJum4PIEE+gScp7QMtQYb+r3Tl25d8BeLO5O/h6wX79ji8PgLqAeJO0MzC3pm3XLtrJpRN4J1uojVVkaYFSfY1/N1qWJ+ts7YVjnXp8cA3gBOZv3CRGxeo8yAy290fY6nbKIromID9d9H1VNyeUJJoikm8gJorWXHenzfFeSaaKnT5WxMgeAMZRsjjFFxLg3kcskk3nkpLVXk/nGy0XEO8f73JNFY+ydEOM4q1TSe8kL/rbkneCvyIlRvyIvDpVafMoVMFtjAddFxC/6qEt7FtEFkbPZbRxIOhvYpUaLftDzDZwlN2wOAGPQ4s1j1iYvDq0P8w5kN1DXADGkOjyO7BduTYw6m9yisGcG0tJK0m+psXfCkM75RUruf0RUXbJ73JXEgz0j4uTJrst0JOmb5Njcz6m/7Eg/57uNLiukjtd5u/EYwBhaqX8lxW+z1oVBuUb8f01QHR4hA8C474c7hdTdO2FgUWHf2/EkaVVyRul65MzUueX7D5EtIQeA8XFzeSxP/WVH+jEDGNbM7aFwC6CH0Sl+ZcDomojYfALOPRfYIyLuL9+vQeYLv3S8zz1ZlBvKb0EOkrXuyiIiXjl5tRpfkn5MThq7mMwKWYO8IB042ROFbHim4mQ5twB6O6/0FZ5CDpLtSfbLT4S1Whd/gIi4T9LaE3TuyXJo29ci+8P3mpyqTJintOYKSDoeuIec+/HQ5FZreis3G522XB2vlONJ3wR+NAeAHiJif0mvAl5YDl1Mrvk+Ef7ZPpu4zCCc1k22iDi/zHfYm8Xbd461GuV0sWj9mcjNxm/2xX9CfLDt6xXJRItHx/F8O47ja/fFAaCam8mlAeruJzyojwMXKtfGhwxC+03QuSeUhrB951KsNbEIRk4umvapmJMpIkbP0fhV22dtPM43JVI/23kMYAxjXJA+GBFPnuB6rMXilUgvjporkS4tNITtO83qUO4N0rIM8FzgyIh42iRVacK5BTC268kL0svbLkjvm4R6rADcS/6uNpNEjLHn6FLu1WTAPVfSWeQsySnXZ2rTyuVkl6rIrp+bgbdOao0mmFsAYyj9/nuScwBaF6TjI2KJrfHGsQ6fJWeDXkfbFoHTdC0ggNY2jLuTLa8XkesuVd2+08xqcADoYTIvSJJuIFcJrLsF5bSgxdt3vm4cMzOsoSS9h9yvoT3Neq+IWKp29RqEA0ANE31BkvRzch7A/433ucyaRtKCiNhi1LEpt1zDePIYQA1Rfz/hQT0CLJA0j5FT1cdtXRyzBllGklrLjpSlNyZiRvCU4QAwtZ1RHmY2fGcDp0n6GjkY/E5yvK8x3AU0xTVlRzCziVaWdXkHOUFLwDlkokftpd+XVg4AU1j7jmARMd13BDObcJKWB55GtgBuiIh/9CgyrYzrbkM2sEPJHcHuh9wRDJiwNFSz6UzS9uQ2oF8lN2r5naQXdi00zXgMYGp7NCIeyN0KF3GTzWw4jgB2anWvltn/p5AzghvBLYCp7VpJewMzJM2WdBS5cYmZDW659rG1iPgdsNwk1mfCeQxgChu1I5jIrIVPTecdwcwmiqQTyRb1t8uh1wPLtjaDagIHADNrJEkrkDuvLdqDGTi6STPvHQCmIElfjoiDJP2EzhtWOAvIbAgkzQSIiLsnuy6TwYPAU1OrSfqFSa2F2TSkzKo4BNifvPOXpMeAoyLisEmt3ARzC2AKKwvR/SUi/lm+nwGsUDaLN7M+lGXddwX2i4iby7GnAMcAZ0XElyazfhPJAWAKk3QJ8OLWYnCSVgbOiYgXTG7NzJZekq4EXjJ6c6XSHXROkxaDcxro1LZi+0qg5evHTWJ9zKaD5TrtrFfGARqVBuoAMLU9LGnL1jeSngv8ZRLrYzYd/L3Pn0077gKawiQ9j9yJ7PZyaF1yL4LRm1mbWUVlwPfhTj8iW92NaQU4AExxkpYjF6sScH3TFqsys/HjLqApSNLzJD0RoFzwtwQ+DRxRdiUzMxuYA8DU9HVKX2RZnfBw4FvAA8Cxk1gvM5tGPBFsappRtp8EeB1wbEScDpwuacEk1svMphG3AKamGZJawXlH4BdtP3PQNrOh8MVkajoFOF/SPWTa5y8BJD2V7AYyMxuYs4CmKElbk2mf50TEw+XYJsDKEXHFpFbOzKYFBwAzs4byGICZWUM5AJiZNZQDgJlZQzkAmJk1lAOAmVlD/X9Wi0V02UrbDAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1778152a8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "genreDistribution = Counter([genre for genres in nameTitle2genre.values() for genre in genres])\n",
    "\n",
    "plt.bar(range(len(genreDistribution)), genreDistribution.values(), align='center')\n",
    "plt.xticks(range(len(genreDistribution)), genreDistribution.keys(), rotation = \"vertical\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like there are some genres with few examples... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TV Movie</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Foreign</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Western</th>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Documentary</th>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>War</th>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Music</th>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>History</th>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Animation</th>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mystery</th>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fantasy</th>\n",
       "      <td>424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Family</th>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horror</th>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Science Fiction</th>\n",
       "      <td>535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crime</th>\n",
       "      <td>696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adventure</th>\n",
       "      <td>790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Romance</th>\n",
       "      <td>894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Action</th>\n",
       "      <td>1154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thriller</th>\n",
       "      <td>1274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comedy</th>\n",
       "      <td>1722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drama</th>\n",
       "      <td>2297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0\n",
       "TV Movie            8\n",
       "Foreign            34\n",
       "Western            82\n",
       "Documentary       110\n",
       "War               144\n",
       "Music             185\n",
       "History           197\n",
       "Animation         234\n",
       "Mystery           348\n",
       "Fantasy           424\n",
       "Family            513\n",
       "Horror            519\n",
       "Science Fiction   535\n",
       "Crime             696\n",
       "Adventure         790\n",
       "Romance           894\n",
       "Action           1154\n",
       "Thriller         1274\n",
       "Comedy           1722\n",
       "Drama            2297"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genreDistDF = pd.DataFrame.from_dict(genreDistribution,orient=\"index\")\n",
    "genreDistDF.sort_values(by=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, IÂ´d propose to do an 70-15-15 Train-CV-Test split.\n",
    "\n",
    "The problem is, we donÂ´t have a lot of data...\n",
    "\n",
    "We need a significant number of examples of each class in the test set for our results to be  meaningful. Otherwise, our evaluation metrics over the test set wouldnÂ´t be statistically  significant.  IÂ´d propose that we should have at least 50 instances of each category in the test set. That means we should have over 50/0.15 = 333 instances in  total of each category. For instance if we  set aside 15% of the 234 animation movies, we would only have 35 examples for testing... we hardly can evaluate with that little data, even if we use precision and recall in view of our skewed data.\n",
    "\n",
    "If the business contexts allows it, IÂ´d propose to treat categories with less than 333 examples as an \"Others\" category. In the next section, I write -  optional - code for doing so. If we want to keep all categories, skip its execution. Other alternatives would be to:\n",
    "\n",
    "1) Keep all the categories and work with an 80-20% dev-test set split, using k-folds (k not too big ton ensure every fold is big enough, maybe = 4) or LOO CV on the 80% for model selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask poorly represented genres.\n",
    "\n",
    "If it is important to keep every genre, skip this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Animation': 'Others',\n",
       " 'Documentary': 'Others',\n",
       " 'Foreign': 'Others',\n",
       " 'History': 'Others',\n",
       " 'Music': 'Others',\n",
       " 'TV Movie': 'Others',\n",
       " 'War': 'Others',\n",
       " 'Western': 'Others'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maskDict = {genre:\"Others\" for genre in map(lambda x: x[0],\n",
    "                                        filter(lambda item:item[1]<333,\n",
    "                                               genreDistribution.items()))}\n",
    "maskDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Others', 'Action')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def maskGenre(genre,maskDict):\n",
    "    if genre in  maskDict:\n",
    "        return maskDict[genre]\n",
    "    return genre\n",
    "maskGenre(\"Western\",maskDict),maskGenre(\"Action\",maskDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameTitle2genre = {(name,title) :list(map(lambda genre: maskGenre(genre,maskDict),genres)) \n",
    "                   for (name,title),genres in nameTitle2genre.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mystery</th>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fantasy</th>\n",
       "      <td>424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Family</th>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horror</th>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Science Fiction</th>\n",
       "      <td>535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crime</th>\n",
       "      <td>696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adventure</th>\n",
       "      <td>790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Romance</th>\n",
       "      <td>894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Others</th>\n",
       "      <td>994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Action</th>\n",
       "      <td>1154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thriller</th>\n",
       "      <td>1274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comedy</th>\n",
       "      <td>1722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drama</th>\n",
       "      <td>2297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Frequency\n",
       "Mystery                348\n",
       "Fantasy                424\n",
       "Family                 513\n",
       "Horror                 519\n",
       "Science Fiction        535\n",
       "Crime                  696\n",
       "Adventure              790\n",
       "Romance                894\n",
       "Others                 994\n",
       "Action                1154\n",
       "Thriller              1274\n",
       "Comedy                1722\n",
       "Drama                 2297"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genreDistribution = Counter([genre for genres in nameTitle2genre.values() for genre in genres])\n",
    "genreDistDF = pd.DataFrame.from_dict(genreDistribution,orient=\"index\")\n",
    "genreDistDF.columns= [\"Frequency\"]\n",
    "genreDistDF.sort_values(by=\"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is in better shape now for doing predictive modelling!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-CV-Test partitioniong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have one more issue before firing our ML algos: the data is multi-labeled and skewed: most of the movies are dramas (2297) and very few mistery films (348).\n",
    "\n",
    "WeÂ´ll use precision/recall/f-measure for measuring the quality of the models, but weÂ´ll get back to that later. \n",
    "\n",
    "To ensure that our training,cv and test sets are representative  of our population, we should use stratified sampling. By doing this, we ensure that in our training, cv and test sets, the distribution of genres stays the same. Otherwise we could have proportionately more movies of  a genre in one set than in the other.\n",
    "\n",
    "The problem is, in this multi-label context, how do you stratify your data? Do you keep the distribution of individual genres? Or the distribution of combinations of genres? There are $2^{n}$ - with n = the number of categories -  possible combinations of genres,  so given the size of our dataset, the former doesnÂ´t seem viable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have very few data for the combinations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>['Action', 'Horror', 'Mystery', 'Science Fiction', 'Thriller']</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Family', 'Adventure', 'Others']</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Romance', 'Adventure', 'Action', 'Others']</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Others', 'Action', 'Drama']</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Science Fiction', 'Adventure']</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Adventure', 'Drama', 'Action', 'Comedy', 'Romance']</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Fantasy', 'Comedy', 'Science Fiction', 'Family']</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Adventure', 'Fantasy', 'Others', 'Science Fiction', 'Family']</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Fantasy', 'Others', 'Adventure']</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Thriller', 'Science Fiction', 'Action']</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Romance', 'Science Fiction', 'Drama']</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Others', 'Drama', 'Thriller', 'Crime', 'Mystery']</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Drama', 'Romance', 'Crime', 'Mystery']</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Crime', 'Drama', 'Mystery', 'Thriller', 'Action']</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Family', 'Horror']</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Action', 'Adventure', 'Crime', 'Science Fiction', 'Thriller']</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Drama', 'Comedy', 'Thriller', 'Others', 'Romance']</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Romance', 'Drama', 'Others', 'Others', 'Others']</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Drama', 'Mystery', 'Crime']</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Others', 'Adventure', 'Romance']</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Others', 'Comedy', 'Others']</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Action', 'Thriller', 'Science Fiction', 'Horror']</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Comedy', 'Family', 'Adventure', 'Crime']</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Comedy', 'Others', 'Action']</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Adventure', 'Family', 'Drama', 'Comedy']</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Thriller', 'Drama', 'Crime', 'Romance']</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Drama', 'Romance', 'Comedy', 'Others']</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Fantasy', 'Family']</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Action', 'Comedy', 'Fantasy', 'Science Fiction']</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Crime', 'Action', 'Drama']</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Thriller']</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Horror', 'Mystery', 'Thriller']</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Adventure', 'Action', 'Thriller']</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Action', 'Crime', 'Drama', 'Thriller']</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Drama', 'Crime']</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[]</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Others', 'Family']</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Others', 'Drama']</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Comedy', 'Crime']</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Action', 'Crime', 'Thriller']</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Comedy', 'Others']</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Crime', 'Drama']</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Drama', 'Others', 'Romance']</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Drama', 'Comedy', 'Romance']</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Action', 'Comedy']</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Comedy', 'Family']</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Action', 'Thriller']</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Crime', 'Drama', 'Thriller']</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Drama', 'Comedy']</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Drama', 'Thriller']</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Horror']</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Drama', 'Others']</th>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Horror', 'Thriller']</th>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Others']</th>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Comedy', 'Drama', 'Romance']</th>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Comedy', 'Drama']</th>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Comedy', 'Romance']</th>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Drama', 'Romance']</th>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Comedy']</th>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['Drama']</th>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1078 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0\n",
       "['Action', 'Horror', 'Mystery', 'Science Fictio...    1\n",
       "['Family', 'Adventure', 'Others']                     1\n",
       "['Romance', 'Adventure', 'Action', 'Others']          1\n",
       "['Others', 'Action', 'Drama']                         1\n",
       "['Science Fiction', 'Adventure']                      1\n",
       "['Adventure', 'Drama', 'Action', 'Comedy', 'Rom...    1\n",
       "['Fantasy', 'Comedy', 'Science Fiction', 'Family']    1\n",
       "['Adventure', 'Fantasy', 'Others', 'Science Fic...    1\n",
       "['Fantasy', 'Others', 'Adventure']                    1\n",
       "['Thriller', 'Science Fiction', 'Action']             1\n",
       "['Romance', 'Science Fiction', 'Drama']               1\n",
       "['Others', 'Drama', 'Thriller', 'Crime', 'Myste...    1\n",
       "['Drama', 'Romance', 'Crime', 'Mystery']              1\n",
       "['Crime', 'Drama', 'Mystery', 'Thriller', 'Acti...    1\n",
       "['Family', 'Horror']                                  1\n",
       "['Action', 'Adventure', 'Crime', 'Science Ficti...    1\n",
       "['Drama', 'Comedy', 'Thriller', 'Others', 'Roma...    1\n",
       "['Romance', 'Drama', 'Others', 'Others', 'Others']    1\n",
       "['Drama', 'Mystery', 'Crime']                         1\n",
       "['Others', 'Adventure', 'Romance']                    1\n",
       "['Others', 'Comedy', 'Others']                        1\n",
       "['Action', 'Thriller', 'Science Fiction', 'Horr...    1\n",
       "['Comedy', 'Family', 'Adventure', 'Crime']            1\n",
       "['Comedy', 'Others', 'Action']                        1\n",
       "['Adventure', 'Family', 'Drama', 'Comedy']            1\n",
       "['Thriller', 'Drama', 'Crime', 'Romance']             1\n",
       "['Drama', 'Romance', 'Comedy', 'Others']              1\n",
       "['Fantasy', 'Family']                                 1\n",
       "['Action', 'Comedy', 'Fantasy', 'Science Fiction']    1\n",
       "['Crime', 'Action', 'Drama']                          1\n",
       "...                                                 ...\n",
       "['Thriller']                                         23\n",
       "['Horror', 'Mystery', 'Thriller']                    23\n",
       "['Adventure', 'Action', 'Thriller']                  24\n",
       "['Action', 'Crime', 'Drama', 'Thriller']             25\n",
       "['Drama', 'Crime']                                   26\n",
       "[]                                                   28\n",
       "['Others', 'Family']                                 28\n",
       "['Others', 'Drama']                                  28\n",
       "['Comedy', 'Crime']                                  30\n",
       "['Action', 'Crime', 'Thriller']                      30\n",
       "['Comedy', 'Others']                                 31\n",
       "['Crime', 'Drama']                                   33\n",
       "['Drama', 'Others', 'Romance']                       33\n",
       "['Drama', 'Comedy', 'Romance']                       35\n",
       "['Action', 'Comedy']                                 36\n",
       "['Comedy', 'Family']                                 36\n",
       "['Action', 'Thriller']                               40\n",
       "['Crime', 'Drama', 'Thriller']                       43\n",
       "['Drama', 'Comedy']                                  46\n",
       "['Drama', 'Thriller']                                62\n",
       "['Horror']                                           64\n",
       "['Drama', 'Others']                                  85\n",
       "['Horror', 'Thriller']                               88\n",
       "['Others']                                           94\n",
       "['Comedy', 'Drama', 'Romance']                      109\n",
       "['Comedy', 'Drama']                                 142\n",
       "['Comedy', 'Romance']                               144\n",
       "['Drama', 'Romance']                                164\n",
       "['Comedy']                                          282\n",
       "['Drama']                                           370\n",
       "\n",
       "[1078 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genreCombinationsDistribution = Counter([str(genres) for genres in nameTitle2genre.values()])\n",
    "genreDistDF = pd.DataFrame.from_dict(genreCombinationsDistribution,orient=\"index\")\n",
    "genreDistDF.sort_values(by=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In any case, stratified Sampling for multi-labeled data is not easy and has been examined in the literature: http://lpis.csd.auth.gr/publications/sechidis-ecmlpkdd-2011.pdf. \n",
    "\n",
    "In Scikit-learn, stratified sampling for multi-labeled data stratifies over combinations: https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/model_selection/_split.py\n",
    "\n",
    "So, there is no easy way to do stratified sampling (or not one that I know of). \n",
    "\n",
    "LetÂ´s do a normal random train-test split and look at the distributions. If they are more or less the same, letÂ´s carry on. If they vary a lot, we could randomly generate multiple random splits and pick the one that preserves the most the genres distribution of the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = zip(*nameTitle2genre.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test_cv, y_train, y_test_cv = train_test_split(X, \n",
    "                                                          y, \n",
    "                                                          test_size=0.30, \n",
    "                                                          random_state=40)\n",
    "X_test, X_cv, y_test, y_cv  = train_test_split(X_test_cv, \n",
    "                                               y_test_cv, \n",
    "                                               test_size=0.50, \n",
    "                                               random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeCounter(counter):\n",
    "    normalizedCounter = {}\n",
    "    total = sum(counter.values(), 0.0)\n",
    "    for key in counter:\n",
    "        normalizedCounter[key] = counter[key]/ total\n",
    "        normalizedCounter[key]*=100\n",
    "    return normalizedCounter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>Y %</th>\n",
       "      <th>Y train</th>\n",
       "      <th>Y train%</th>\n",
       "      <th>Y test</th>\n",
       "      <th>Y test%</th>\n",
       "      <th>Y cv</th>\n",
       "      <th>Y cv%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Action</th>\n",
       "      <td>1154.0</td>\n",
       "      <td>9.490132</td>\n",
       "      <td>820.0</td>\n",
       "      <td>9.594010</td>\n",
       "      <td>171.0</td>\n",
       "      <td>9.457965</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.030471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adventure</th>\n",
       "      <td>790.0</td>\n",
       "      <td>6.496711</td>\n",
       "      <td>556.0</td>\n",
       "      <td>6.505207</td>\n",
       "      <td>124.0</td>\n",
       "      <td>6.858407</td>\n",
       "      <td>110.0</td>\n",
       "      <td>6.094183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comedy</th>\n",
       "      <td>1722.0</td>\n",
       "      <td>14.161184</td>\n",
       "      <td>1174.0</td>\n",
       "      <td>13.735814</td>\n",
       "      <td>284.0</td>\n",
       "      <td>15.707965</td>\n",
       "      <td>264.0</td>\n",
       "      <td>14.626039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crime</th>\n",
       "      <td>696.0</td>\n",
       "      <td>5.723684</td>\n",
       "      <td>502.0</td>\n",
       "      <td>5.873406</td>\n",
       "      <td>105.0</td>\n",
       "      <td>5.807522</td>\n",
       "      <td>89.0</td>\n",
       "      <td>4.930748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drama</th>\n",
       "      <td>2297.0</td>\n",
       "      <td>18.889803</td>\n",
       "      <td>1602.0</td>\n",
       "      <td>18.743419</td>\n",
       "      <td>334.0</td>\n",
       "      <td>18.473451</td>\n",
       "      <td>361.0</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Family</th>\n",
       "      <td>513.0</td>\n",
       "      <td>4.218750</td>\n",
       "      <td>352.0</td>\n",
       "      <td>4.118404</td>\n",
       "      <td>74.0</td>\n",
       "      <td>4.092920</td>\n",
       "      <td>87.0</td>\n",
       "      <td>4.819945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fantasy</th>\n",
       "      <td>424.0</td>\n",
       "      <td>3.486842</td>\n",
       "      <td>294.0</td>\n",
       "      <td>3.439803</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.539823</td>\n",
       "      <td>66.0</td>\n",
       "      <td>3.656510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horror</th>\n",
       "      <td>519.0</td>\n",
       "      <td>4.268092</td>\n",
       "      <td>366.0</td>\n",
       "      <td>4.282204</td>\n",
       "      <td>77.0</td>\n",
       "      <td>4.258850</td>\n",
       "      <td>76.0</td>\n",
       "      <td>4.210526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mystery</th>\n",
       "      <td>348.0</td>\n",
       "      <td>2.861842</td>\n",
       "      <td>264.0</td>\n",
       "      <td>3.088803</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.323009</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.326870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Others</th>\n",
       "      <td>994.0</td>\n",
       "      <td>8.174342</td>\n",
       "      <td>691.0</td>\n",
       "      <td>8.084708</td>\n",
       "      <td>140.0</td>\n",
       "      <td>7.743363</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.030471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Romance</th>\n",
       "      <td>894.0</td>\n",
       "      <td>7.351974</td>\n",
       "      <td>633.0</td>\n",
       "      <td>7.406107</td>\n",
       "      <td>129.0</td>\n",
       "      <td>7.134956</td>\n",
       "      <td>132.0</td>\n",
       "      <td>7.313019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Science Fiction</th>\n",
       "      <td>535.0</td>\n",
       "      <td>4.399671</td>\n",
       "      <td>398.0</td>\n",
       "      <td>4.656605</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3.871681</td>\n",
       "      <td>67.0</td>\n",
       "      <td>3.711911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thriller</th>\n",
       "      <td>1274.0</td>\n",
       "      <td>10.476974</td>\n",
       "      <td>895.0</td>\n",
       "      <td>10.471510</td>\n",
       "      <td>194.0</td>\n",
       "      <td>10.730088</td>\n",
       "      <td>185.0</td>\n",
       "      <td>10.249307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Y        Y %  Y train   Y train%  Y test    Y test%  \\\n",
       "Action           1154.0   9.490132    820.0   9.594010   171.0   9.457965   \n",
       "Adventure         790.0   6.496711    556.0   6.505207   124.0   6.858407   \n",
       "Comedy           1722.0  14.161184   1174.0  13.735814   284.0  15.707965   \n",
       "Crime             696.0   5.723684    502.0   5.873406   105.0   5.807522   \n",
       "Drama            2297.0  18.889803   1602.0  18.743419   334.0  18.473451   \n",
       "Family            513.0   4.218750    352.0   4.118404    74.0   4.092920   \n",
       "Fantasy           424.0   3.486842    294.0   3.439803    64.0   3.539823   \n",
       "Horror            519.0   4.268092    366.0   4.282204    77.0   4.258850   \n",
       "Mystery           348.0   2.861842    264.0   3.088803    42.0   2.323009   \n",
       "Others            994.0   8.174342    691.0   8.084708   140.0   7.743363   \n",
       "Romance           894.0   7.351974    633.0   7.406107   129.0   7.134956   \n",
       "Science Fiction   535.0   4.399671    398.0   4.656605    70.0   3.871681   \n",
       "Thriller         1274.0  10.476974    895.0  10.471510   194.0  10.730088   \n",
       "\n",
       "                  Y cv      Y cv%  \n",
       "Action           163.0   9.030471  \n",
       "Adventure        110.0   6.094183  \n",
       "Comedy           264.0  14.626039  \n",
       "Crime             89.0   4.930748  \n",
       "Drama            361.0  20.000000  \n",
       "Family            87.0   4.819945  \n",
       "Fantasy           66.0   3.656510  \n",
       "Horror            76.0   4.210526  \n",
       "Mystery           42.0   2.326870  \n",
       "Others           163.0   9.030471  \n",
       "Romance          132.0   7.313019  \n",
       "Science Fiction   67.0   3.711911  \n",
       "Thriller         185.0  10.249307  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genreDistributionY = Counter([genre for genres in y for genre in genres])\n",
    "genreDistributionY_train = Counter([genre for genres in y_train for genre in genres])\n",
    "genreDistributionY_test = Counter([genre for genres in y_test for genre in genres])\n",
    "genreDistributionY_cv = Counter([genre for genres in y_cv for genre in genres])\n",
    "\n",
    "yDistributionsDF = pd.DataFrame.from_dict([genreDistributionY,\n",
    "                                         normalizeCounter(genreDistributionY),\n",
    "                                         genreDistributionY_train,\n",
    "                                         normalizeCounter(genreDistributionY_train),\n",
    "                                         genreDistributionY_test,\n",
    "                                         normalizeCounter(genreDistributionY_test),\n",
    "                                         genreDistributionY_cv,\n",
    "                                         normalizeCounter(genreDistributionY_cv),]).transpose()\n",
    "yDistributionsDF.columns = ['Y', \n",
    "                          'Y %',\n",
    "                          'Y train', \n",
    "                          'Y train%',\n",
    "                          'Y test', \n",
    "                          'Y test%',\n",
    "                          'Y cv', \n",
    "                          'Y cv%',]\n",
    "yDistributionsDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have enough data, the distributions should be preserved. Note that some genres have more data in one set than in  other. But in  general the differences are not that big. \n",
    "\n",
    "LetÂ´s carry on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that we are in a multilabel setting, where each movie can belong to multiple genres, we must pay attention not to treat this problem as a typical multi-class task, where all the task are mutually exclusive. Also, in our problem, the genres are not independent: a thriller is less likely to also be a comedy movie than a mistery one.\n",
    "\n",
    "Having said that, there are multiple ways to address this issue. \n",
    "\n",
    "The first alternative is to treat every combination of labels as a single label. For instance, a movie that is both a comedy and a romance would have a \"comedy, romantic\" label. This is called in the literature the label power-set method, because as said before, you would $2^n$ labels. In our case,  this method is not reasonable: as we have seen before, we have little data in comparison to the number of possible categories. \n",
    "\n",
    "Another alternative is the binary relevance method, in which you train one binary classifier per label, that measures the relevance of a label. That is, you go category by category and train a classifier that asks: does this movie have this label or not?. It has a number of advantages: itÂ´s simple, can work with little data and isnÂ´t computationally expensive. The main drawback  is that is assumes independence between categories, which is not our case. As seen before, thereÂ´s quite a few romantic comedies and very little crime-action  dramas.\n",
    "\n",
    "A variant of the binary relevance method is the classifier chain method, in which you also train one classifier per label, and you iteratively train them, in  order. You train your classifier for the first category, then move on  to the second category *and* you pass the decision taken by the former classifiers as a category itself. That way you can model dependences. Given that the order in which you process the categories matters, you can pick the best models or you can go for an ensemble of classifiers.\n",
    "\n",
    "For simplicity, and given that I also wanted to use Neural Networks in this exercise, we can work with  a fourth alternative: use algorithms that can be adapted for multi-label contexts. Such is the  case of Random Forest. Random forests are ensembles of decision trees, which in turn can be adapted for multi-label context. Such is the case of the implementation  in Scikit Learn (http://scikit-learn.org/stable/modules/tree.html#tree-multioutput). In a nutshell, decision trees look at the values of given features and pick these using an optimal splitting criteria like entropy: in case of a multi-label problem, you use splitting criteria that looks at the average reduction over all the features.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LetÂ´s finish getting our data in shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, we have two different strings for doing prediction: title and overview.\n",
    "\n",
    "We could  possibly use the title and the overview as different features. We would do that by concatenating their vector representations.\n",
    "\n",
    "For simplicity, I  will concatenate their strings and treat them a single feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(map(lambda x: str(x[0])+\" \"+str(x[1]), X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = list(map(lambda x: str(x[0])+\" \"+str(x[1]), X_train))\n",
    "X_test = list(map(lambda x: str(x[0])+\" \"+str(x[1]), X_test))\n",
    "X_cv = list(map(lambda x: str(x[0])+\" \"+str(x[1]), X_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last but not least, letÂ´s binarize our data and get it into a one hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "genres = sorted(set([genre for genres in y_train for genre in genres]))\n",
    "\n",
    "mlb = MultiLabelBinarizer(classes = genres)\n",
    "\n",
    "y_train_oh = mlb.fit_transform(y_train) #One hot encoding\n",
    "y_cv_oh = mlb.transform(y_cv) #One hot encoding\n",
    "y_test_oh = mlb.transform(y_test) #One hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First approach: multi-label random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start with, letÂ´s use Random Forests with a standard TF-IDF vectorization. Given that we have little data, I will:\n",
    "\n",
    "1) Use stemming for normalizing words and reducing.\n",
    "\n",
    "2) Refrain from using n-grams (combinations of 2 tokens). We would need more data for this to be sensible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not stemmed:\n",
      "Romance & Cigarettes Down-and-dirty musical love story set in the world of the working class. Nick is an ironworker who builds and repairs bridges. He's married to Kitty, a dressmaker, a strong and gentle woman with whom he has three daughters. He is carrying on a torrid affair with a redheaded woman named Tula. Nick is basically a good, hardworking man driven forward by will and blinded by his urges. \n",
      "\n",
      "Stemmed:\n",
      "romanc cigarett down and dirti music love stori set in the world of the work class nick is an ironwork who build and repair bridg he s marri to kitti a dressmak a strong and gentl woman with whom he has three daughter he is carri on a torrid affair with a redhead woman name tula nick is basic a good hardwork man driven forward by will and blind by his urg\n"
     ]
    }
   ],
   "source": [
    "#Tokenizer function with english stemming\n",
    "def textPreprocessing(string):\n",
    "\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(string)\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    stemmed_text = [stemmer.stem(i) for i in tokens]\n",
    "    return stemmed_text\n",
    "\n",
    "print(\"Not stemmed:\")\n",
    "print(X_train[0],\"\\n\")\n",
    "print(\"Stemmed:\")\n",
    "print(\" \".join(textPreprocessing(X_train[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LetÂ´s set up our sklearn pipeline as previously defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=Tr...timators=10, n_jobs=-1,\n",
       "            oob_score=False, random_state=40, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_rf = RandomForestClassifier(n_jobs=-1,random_state=40)\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words = 'english',\n",
    "                                tokenizer = textPreprocessing,\n",
    "                                #norm = \"l2\",\n",
    "                                ngram_range = (1,1),\n",
    "                                #max_features=5000\n",
    "                                       )\n",
    "tfidf_multilabel_rf = Pipeline([('vectorizer', tfidf), ('classifier', multilabel_rf)])\n",
    "tfidf_multilabel_rf.fit(X_train,y_train_oh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### WhatÂ´s our accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.077669902912621352"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_multilabel_rf.score(X_cv,y_cv_oh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7,7% only? WhatÂ´s going on? LetÂ´s look at accuracy on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83878643664485431"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_multilabel_rf.score(X_train,y_train_oh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ThatÂ´s not good. 84% accuracy in the training set and only 8% in our CV? WhatÂ´s precision and recall looking like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision - Training \n",
      "[ 1.          1.          0.99729973  1.          0.99177215  1.          1.\n",
      "  1.          1.          1.          0.99822695  0.99713467  1.        ]\n",
      "Precision - CV \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\foru\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.67567568  0.4         0.62264151  0.38461538  0.64094955  1.          1.\n",
      "  0.66666667  0.          1.          0.5862069   0.58333333  0.50943396]\n",
      "Recall - Training \n",
      "[ 0.88170732  0.85611511  0.94378194  0.89442231  0.97815231  0.84090909\n",
      "  0.79931973  0.84972678  0.79924242  0.86184211  0.88941548  0.87437186\n",
      "  0.91955307]\n",
      "Recall - CV \n",
      "[ 0.15337423  0.03636364  0.25        0.05617978  0.59833795  0.01149425\n",
      "  0.01515152  0.02631579  0.          0.02068966  0.12878788  0.10447761\n",
      "  0.14594595]\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision - Training \")\n",
    "print(precision_score(y_train_oh,tfidf_multilabel_rf.predict(X_train),average= None))\n",
    "print(\"Precision - CV \")\n",
    "print(precision_score(y_cv_oh,tfidf_multilabel_rf.predict(X_cv),average= None))\n",
    "\n",
    "print(\"Recall - Training \")\n",
    "print(recall_score(y_train_oh,tfidf_multilabel_rf.predict(X_train),average= None))\n",
    "print(\"Recall - CV \")\n",
    "print(recall_score(y_cv_oh,tfidf_multilabel_rf.predict(X_cv),average= None))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not good either. WhatÂ´s the weighted average of F1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 0.946598654163\n",
      "CV 0.262908465065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\foru\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train\",f1_score(y_train_oh,\n",
    "                       tfidf_multilabel_rf.predict(X_train),average= \"weighted\"))\n",
    "print(\"CV\",f1_score(y_cv_oh,\n",
    "                       tfidf_multilabel_rf.predict(X_cv),average= \"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we are heavily overfitting our data. \n",
    "\n",
    "If let unchecked, the decision trees of the random forest can grow a lot and  overfit. Possible solutions would be to limit the trees depth, and size, tune the number of trees in the forest,reduce vocabulary or as usually in presence of overfitting, get more data - which is not an option in our case -.\n",
    "\n",
    "I donÂ´t have much experience working with multi-label Random Forests, so it could be the case than when trying to partition the branches looking at all categories at  the same time, itÂ´s overfitting the data. LetÂ´s pivot back to the simpler binary relevance solution and then built on top of that...\n",
    "\n",
    "IÂ´ll also stop looking at accuracy and start optimizing in  terms of f1. F1 aka f-measure is the harmonic average of precision  and recall, two good metrics for skewed distributions.  Given more business context, we could choose to optimize/threshold precision and recall. For instance, you could optimize recall, constraining precision to be above a certain threshold.\n",
    "\n",
    "For simplicity, letÂ´s assume we donÂ´t prefer high precision or high recall and set as an objetive high f1, their harmonic mean. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second approach: binary relevance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LetÂ´s start with random forests with binary relevance.\n",
    "\n",
    "Scikit learn' s OneVsRest classifiers elegantly allows us to use the binary relevance method, training one binary classifier per category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=Pipeline(memory=None,\n",
       "     steps=[('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=Tr...timators=10, n_jobs=-1,\n",
       "            oob_score=False, random_state=40, verbose=0, warm_start=False))]),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_rf = RandomForestClassifier(n_jobs=-1,random_state=40)\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words = 'english',\n",
    "                                tokenizer = textPreprocessing,\n",
    "                                #norm = \"l2\",\n",
    "                                ngram_range = (1,1),\n",
    "                                #max_features=5000\n",
    "                                       )\n",
    "tfidf_binary_rf = Pipeline([('vectorizer', tfidf), ('classifier', binary_rf)])\n",
    "\n",
    "# Run classifier\n",
    "ovr_rf_tfidf = OneVsRestClassifier(tfidf_binary_rf) # \n",
    "ovr_rf_tfidf.fit(X_train, y_train_oh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LetÂ´s look at the weighted f1 (weighted by doc class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 0.94657320638\n",
      "CV 0.302833012743\n"
     ]
    }
   ],
   "source": [
    "print(\"Train\",f1_score(y_train_oh,\n",
    "                       ovr_rf_tfidf.predict(X_train),average= \"weighted\"))\n",
    "print(\"CV\",f1_score(y_cv_oh,\n",
    "                       ovr_rf_tfidf.predict(X_cv),average= \"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woohoo! The training-cv gap is smaller, but it seems like we are still overfitting. \n",
    "\n",
    "Random forests have different approaches for reducing variance: pruning the trees, increasing the size  of the forests and particularly in sklearn, playing with max_depth, min_samples_split or min_samples_leaf. ThatÂ´s a lot of parameters to tune.\n",
    "\n",
    "LetÂ´s try a simpler algorithm: SVM with a linear kernel. SVM offer two ways to reduce overfitting: the C parameter and the kernel. Linear kernels are the least complex, so letÂ´s fix that parameter and play with C and/or vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=Pipeline(memory=None,\n",
       "     steps=[('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=Tr...r',\n",
       "  max_iter=-1, probability=False, random_state=40, shrinking=True,\n",
       "  tol=0.001, verbose=False))]),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_SVC = SVC(kernel='linear',random_state=40)\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words = 'english',\n",
    "                                tokenizer = textPreprocessing,\n",
    "                                norm = \"l2\",\n",
    "                                ngram_range = (1,1),\n",
    "                                min_df = 1\n",
    "                                #max_features=5000\n",
    "                                       )\n",
    "tfidf_binary_linear_svc = Pipeline([('vectorizer', tfidf), ('classifier', linear_SVC)])\n",
    "\n",
    "ovr_tfidf_binary_linear_svc = OneVsRestClassifier(tfidf_binary_linear_svc)\n",
    "ovr_tfidf_binary_linear_svc.fit(X_train, y_train_oh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weighted average of f1..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 0.883087359943\n",
      "CV 0.501105812882\n"
     ]
    }
   ],
   "source": [
    "print(\"Train\",f1_score(y_train_oh,\n",
    "                       ovr_tfidf_binary_linear_svc.predict(X_train),average= \"weighted\"))\n",
    "print(\"CV\",f1_score(y_cv_oh,\n",
    "                       ovr_tfidf_binary_linear_svc.predict(X_cv),average= \"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ThatÂ´s looking even better, in terms of variance (over-fitting reduction), but we still have a significant gap and F1-Score = 0.5 can be improved. LetÂ´s look at precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision - Training \n",
      "[ 0.98457223  0.99253731  0.984689    0.98684211  0.9606599   1.\n",
      "  0.99418605  0.99317406  1.          1.          0.98755187  0.99071207\n",
      "  0.97526042]\n",
      "Precision - CV \n",
      "[ 0.71774194  0.85365854  0.76404494  0.63265306  0.70893372  0.91666667\n",
      "  0.81818182  0.88888889  0.5         0.76190476  0.63333333  0.86956522\n",
      "  0.67241379]\n",
      "Recall - Training \n",
      "[ 0.85609756  0.7176259   0.87649063  0.74701195  0.94506866  0.72727273\n",
      "  0.58163265  0.79508197  0.45454545  0.74177632  0.75197472  0.8040201\n",
      "  0.83687151]\n",
      "Recall - CV \n",
      "[ 0.54601227  0.31818182  0.51515152  0.34831461  0.68144044  0.12643678\n",
      "  0.13636364  0.21052632  0.02380952  0.22068966  0.28787879  0.29850746\n",
      "  0.42162162]\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision - Training \")\n",
    "print(precision_score(y_train_oh,ovr_tfidf_binary_linear_svc.predict(X_train),average= None))\n",
    "print(\"Precision - CV \")\n",
    "print(precision_score(y_cv_oh,ovr_tfidf_binary_linear_svc.predict(X_cv),average= None))\n",
    "\n",
    "print(\"Recall - Training \")\n",
    "print(recall_score(y_train_oh,ovr_tfidf_binary_linear_svc.predict(X_train),average= None))\n",
    "print(\"Recall - CV \")\n",
    "print(recall_score(y_cv_oh,ovr_tfidf_binary_linear_svc.predict(X_cv),average= None))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our algorithm has on average higher precision than recall. This might be due to the fact that since we are binarizing our entries, the data for each binary classifier is skewed. \n",
    "\n",
    "What happens if we play with class weights to use the loss function  to compensate the skewness and penalize more false negatives? LetÂ´s balance class weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=Pipeline(memory=None,\n",
       "     steps=[('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=Tr...r',\n",
       "  max_iter=-1, probability=False, random_state=40, shrinking=True,\n",
       "  tol=0.001, verbose=False))]),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_weighted_SVC = SVC(kernel='linear',class_weight =\"balanced\",random_state=40)\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words = 'english',\n",
    "                                tokenizer = textPreprocessing,\n",
    "                                norm = \"l2\",\n",
    "                                ngram_range = (1,1),\n",
    "                                min_df = 1\n",
    "                                #max_features=5000\n",
    "                                       )\n",
    "tfidf_binary_linear_weighted_SVC = Pipeline([('vectorizer', tfidf), ('classifier', linear_weighted_SVC)])\n",
    "\n",
    "ovr_tfidf_binary_linear_weighted_SVC = OneVsRestClassifier(tfidf_binary_linear_weighted_SVC)\n",
    "ovr_tfidf_binary_linear_weighted_SVC.fit(X_train, y_train_oh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WhatÂ´s F1 looking like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1 0.94668059061\n",
      "CV F1 0.595408020506\n"
     ]
    }
   ],
   "source": [
    "print(\"Train F1\",f1_score(y_train_oh,\n",
    "                       ovr_tfidf_binary_linear_weighted_SVC.predict(X_train),average= \"weighted\"))\n",
    "print(\"CV F1\",f1_score(y_cv_oh,\n",
    "                       ovr_tfidf_binary_linear_weighted_SVC.predict(X_cv),average= \"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ThatÂ´s slightly better. Take a  look at precision  and  recall..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision - CV \n",
      "[ 0.58080808  0.51612903  0.66798419  0.51260504  0.70247934  0.71153846\n",
      "  0.58695652  0.57142857  0.40740741  0.56410256  0.48701299  0.6\n",
      "  0.58767773]\n",
      "Recall - CV \n",
      "[ 0.70552147  0.58181818  0.64015152  0.68539326  0.70637119  0.42528736\n",
      "  0.40909091  0.42105263  0.26190476  0.45517241  0.56818182  0.44776119\n",
      "  0.67027027]\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision - CV \")\n",
    "print(precision_score(y_cv_oh,ovr_tfidf_binary_linear_weighted_SVC.predict(X_cv),average= None))\n",
    "\n",
    "print(\"Recall - CV \")\n",
    "print(recall_score(y_cv_oh,ovr_tfidf_binary_linear_weighted_SVC.predict(X_cv),average= None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like we got slightly better results sacrificing precision to gain recall. But results are still bad in the CV set.\n",
    "\n",
    "LetÂ´s make our model much simpler, to see if we can reduce overfitting even more. In particular, letÂ´s halve the C parameter (default value of 1) of our SVM. The C parameter controls the size of the margin, which is related to over-fitting: smaller values of C make the SVM generate a bigger margin at the expense of misclassifying some samples in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=Pipeline(memory=None,\n",
       "     steps=[('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=Tr...r',\n",
       "  max_iter=-1, probability=False, random_state=40, shrinking=True,\n",
       "  tol=0.001, verbose=False))]),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_weighted_SVC_reduced_c = SVC(C= 0.5,kernel='linear',class_weight =\"balanced\",random_state=40)\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words = 'english',\n",
    "                                tokenizer = textPreprocessing,\n",
    "                                norm = \"l2\",\n",
    "                                ngram_range = (1,1),\n",
    "                                min_df = 1,\n",
    "                                       )\n",
    "tfidf_binary_linear_weighted_SVC_reduced_c = Pipeline([('vectorizer', tfidf), \n",
    "                                             ('classifier', linear_weighted_SVC_reduced_c)])\n",
    "\n",
    "ovr_tfidf_binary_linear_weighted_SVC_reduced_c = OneVsRestClassifier(tfidf_binary_linear_weighted_SVC_reduced_c)\n",
    "ovr_tfidf_binary_linear_weighted_SVC_reduced_c.fit(X_train, y_train_oh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1 0.894076862833\n",
      "CV F1 0.611680570201\n"
     ]
    }
   ],
   "source": [
    "print(\"Train F1\",f1_score(y_train_oh,\n",
    "                       ovr_tfidf_binary_linear_weighted_SVC_reduced_c.predict(X_train),average= \"weighted\"))\n",
    "print(\"CV F1\",f1_score(y_cv_oh,\n",
    "                       ovr_tfidf_binary_linear_weighted_SVC_reduced_c.predict(X_cv),average= \"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That reduces overfitting slightly more!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LetÂ´s store the f1 scores in memory for comparison later on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_svm = dict(zip(genres,\n",
    "                  f1_score(y_cv_oh,\n",
    "                           ovr_tfidf_binary_linear_weighted_SVC_reduced_c.predict(X_cv),average= None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Action': 0.65384615384615374,\n",
       " 'Adventure': 0.5381526104417671,\n",
       " 'Comedy': 0.6729323308270676,\n",
       " 'Crime': 0.55299539170506917,\n",
       " 'Drama': 0.71625344352617082,\n",
       " 'Family': 0.55844155844155841,\n",
       " 'Fantasy': 0.5123966942148761,\n",
       " 'Horror': 0.54794520547945202,\n",
       " 'Mystery': 0.30588235294117649,\n",
       " 'Others': 0.54109589041095896,\n",
       " 'Romance': 0.54000000000000004,\n",
       " 'Science Fiction': 0.53543307086614178,\n",
       " 'Thriller': 0.64516129032258063}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Could we get more data?\n",
    "\n",
    "The classic solution for overfitting, besides from working with less complex models, is getting more data.\n",
    "\n",
    "IÂ´ve assumed I cannot get more data for this exercise. However, one option to do so inexpensively would be to download a dump of the wikipedia, and use itÂ´s hierarchy to  get movie descriptions for each genre. For instance, here https://en.wikipedia.org/wiki/List_of_action_films_of_the_2010s you have a list of all the action  movies of 2010 (you can do the same for other decades and genres).\n",
    "\n",
    "Notice that you can also download wikipedia data for any language...\n",
    "\n",
    "By getting more data - even if it doesnÂ´t exactly resemble the data of our dataset - we can improve our algorithms. This is known as data augmentation - getting or generating data that resembles your distribution. We would treat the content of each article - or windows of it with the same size as  the original training data - as the text of our overview and fit a bigger model without fearing overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving forward... proper grid search\n",
    "\n",
    "So far I have shown how to start a ML task with a simple approach, and then iteratively work out how to make it better by understanding the types of mistakes the model is making. We have diagnosed high variance (overfitting) and skewed classes. The theory says that the solution for these issues is 1) getting more data, 2) building  a simpler model (we switched from RF to Linear SVM, tuning C), 3) applying weights to the classes and 4) using precision-recall-f-measure for diagnosing the modelÂ´s performance.\n",
    "\n",
    "I have iteratively build new models to show how applying the theory we can improve our results, rather than doing brute force search over an algorithm/parameter space. However, to speed things up, we would do grid search to select algorithms and parameters. This can  be done in SkLearn with GridSearchCV.\n",
    "\n",
    "Other alternatives would be to build an ensemble of smaller models and testing new features. Particularly, potentially other features like director and actors would allow us to better model the genre of a film. After all, it is known that Swarzeneger usually does action and Hugh Grant does romantic comedies...\n",
    "\n",
    "Another way to address the shortage of text is to use pre-trained word embeddings. Word embeddings are matrices codifying the meaning of a specific word by using neural networks and looking at their co-occurrence in very large corpora of text. In word embeddings, similar words like love,romance, wedding would be represented with very similar vectors. That way, we could leverage a pre-existing language knowledge base.\n",
    "\n",
    "LetÂ´s give word embeddings a try, along with a very simple Neural Network with lots of regularization. (I acknowledge from scratch that 5000 films is not big enough for deep learning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the embeddings\n",
    "\n",
    "For this exercise, IÂ´ll use a Standford Glove embedding generated using wikipedia data, with 400,000 words and 100 dimensions per token. There are more powerful embeddings available - more tokens and more dimensions per token - but I need to be able to squeeze the embeddings into my GPU with limited memory :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WhatÂ´s the maximum num of words a review can have?\n",
    "max(map(lambda x: len(x.split(\" \")),X_train+X_test+X_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_DIR = \"./\"\n",
    "EMBEDDING_DIM = 100\n",
    "MAX_NB_WORDS = 400000\n",
    "MAX_SEQUENCE_LENGTH = 200 # Rounded the 179 maximum sequence we found in the previous point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us load the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'),encoding = \"utf8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And tokenize the text using KerasÂ´s procedures.\n",
    "\n",
    "Note that I fit the tokenizer on the whole X. \n",
    "\n",
    "Is this cheating?\n",
    "\n",
    "Nope. In the next cell, we pass the embedding  to a matrix. Rather than fitting the whole embedding into memory - which would make my GPU unable to handle the training - we only load the entries of the words that we will use. By loading the entries of all the words - including X_train, X_cv and X_test - we will leverage the pre-trained embeddings to be able to understand words not seen in  X_train.\n",
    "\n",
    "Say for instance katana is in the test or cv sets and is not in the description of movies in X_train... But sword is... katana and sword probably have vectors that are very similar. If we see sword in the training data, why should not we treat katana as a sword when making predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24099 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(X_train)\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To account for varying sequences, we use padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_padded = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cv_padded = pad_sequences(tokenizer.texts_to_sequences(X_cv),maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X_test_padded = pad_sequences(tokenizer.texts_to_sequences(X_test),maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our embedding as a dictionary. We transform it into a matrix so that it can be used by Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create a NN and train it for each category. \n",
    "\n",
    "For this exercise will use a  very small network, with  one LSTM and one dense output layer, to avoid overfitting. For normalization, we can use dropout.\n",
    "\n",
    "Note that neural networks can  be perfectly used in  a  multi-label context depending on the activation function that you use on the last layer. If you uses softmax, you are expecting each instance in your dataset to have only one category. On the other hand, if you use sigmoids, then  you can work with a multi-label setting.\n",
    "\n",
    "Given that we  chose to  binarize data before, I will keep this setting. Binary cross entropy is the standard loss function\n",
    "\n",
    "I tried using class weight, but didnÂ´t manage to get better results.\n",
    "\n",
    "We also set callbacks to 1) store model weights on disk and pick the one with highest accuracy and 2) stop if we donÂ´t see any improvements on the CV set.  \n",
    "\n",
    "50 epochs should be fine as we donÂ´t have that much data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comedy\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 200, 100)          2410000   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 200, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,527,377\n",
      "Trainable params: 117,377\n",
      "Non-trainable params: 2,410,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 3362 samples, validate on 721 samples\n",
      "Epoch 1/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.6555 - acc: 0.6286\n",
      "Epoch 00001: saving model to nn/Comedy/proc-weights-improvement-01-0.63.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.6552 - acc: 0.6288 - val_loss: 0.6434 - val_acc: 0.6338\n",
      "Epoch 2/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.6284 - acc: 0.6526\n",
      "Epoch 00002: saving model to nn/Comedy/proc-weights-improvement-02-0.64.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.6286 - acc: 0.6514 - val_loss: 0.6283 - val_acc: 0.6408\n",
      "Epoch 3/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.6072 - acc: 0.6680\n",
      "Epoch 00003: saving model to nn/Comedy/proc-weights-improvement-03-0.68.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.6073 - acc: 0.6678 - val_loss: 0.5918 - val_acc: 0.6824\n",
      "Epoch 4/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.5574 - acc: 0.7112\n",
      "Epoch 00004: saving model to nn/Comedy/proc-weights-improvement-04-0.66.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.5574 - acc: 0.7109 - val_loss: 0.6050 - val_acc: 0.6560\n",
      "Epoch 5/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.5574 - acc: 0.7145\n",
      "Epoch 00005: saving model to nn/Comedy/proc-weights-improvement-05-0.75.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.5562 - acc: 0.7156 - val_loss: 0.5346 - val_acc: 0.7462\n",
      "Epoch 6/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.5189 - acc: 0.7377\n",
      "Epoch 00006: saving model to nn/Comedy/proc-weights-improvement-06-0.71.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.5207 - acc: 0.7362 - val_loss: 0.5505 - val_acc: 0.7074\n",
      "Epoch 7/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.5363 - acc: 0.7218\n",
      "Epoch 00007: saving model to nn/Comedy/proc-weights-improvement-07-0.74.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.5366 - acc: 0.7216 - val_loss: 0.5357 - val_acc: 0.7420\n",
      "Epoch 8/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.5181 - acc: 0.7410\n",
      "Epoch 00008: saving model to nn/Comedy/proc-weights-improvement-08-0.76.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.5189 - acc: 0.7397 - val_loss: 0.5235 - val_acc: 0.7601\n",
      "Epoch 9/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4990 - acc: 0.7548\n",
      "Epoch 00009: saving model to nn/Comedy/proc-weights-improvement-09-0.75.hdf5\n",
      "3362/3362 [==============================] - 8s 2ms/step - loss: 0.4992 - acc: 0.7546 - val_loss: 0.5198 - val_acc: 0.7476\n",
      "Epoch 10/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4966 - acc: 0.7572\n",
      "Epoch 00010: saving model to nn/Comedy/proc-weights-improvement-10-0.77.hdf5\n",
      "3362/3362 [==============================] - 8s 2ms/step - loss: 0.4963 - acc: 0.7573 - val_loss: 0.5415 - val_acc: 0.7656\n",
      "Epoch 11/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4923 - acc: 0.7572\n",
      "Epoch 00011: saving model to nn/Comedy/proc-weights-improvement-11-0.73.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.4916 - acc: 0.7579 - val_loss: 0.5323 - val_acc: 0.7268\n",
      "Epoch 12/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4988 - acc: 0.7575\n",
      "Epoch 00012: saving model to nn/Comedy/proc-weights-improvement-12-0.76.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.4983 - acc: 0.7579 - val_loss: 0.5168 - val_acc: 0.7587\n",
      "Epoch 13/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4826 - acc: 0.7686\n",
      "Epoch 00013: saving model to nn/Comedy/proc-weights-improvement-13-0.76.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.4831 - acc: 0.7674 - val_loss: 0.5189 - val_acc: 0.7573\n",
      "Epoch 14/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4775 - acc: 0.7743\n",
      "Epoch 00014: saving model to nn/Comedy/proc-weights-improvement-14-0.76.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.4775 - acc: 0.7739 - val_loss: 0.5204 - val_acc: 0.7601\n",
      "Epoch 15/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4713 - acc: 0.7764\n",
      "Epoch 00015: saving model to nn/Comedy/proc-weights-improvement-15-0.77.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.4716 - acc: 0.7760 - val_loss: 0.5291 - val_acc: 0.7656\n",
      "Epoch 16/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4774 - acc: 0.7749\n",
      "Epoch 00016: saving model to nn/Comedy/proc-weights-improvement-16-0.76.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.4772 - acc: 0.7748 - val_loss: 0.5371 - val_acc: 0.7642\n",
      "Epoch 17/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4646 - acc: 0.7834\n",
      "Epoch 00017: saving model to nn/Comedy/proc-weights-improvement-17-0.76.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.4644 - acc: 0.7829 - val_loss: 0.5163 - val_acc: 0.7559\n",
      "Epoch 18/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4430 - acc: 0.7885\n",
      "Epoch 00018: saving model to nn/Comedy/proc-weights-improvement-18-0.75.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.4441 - acc: 0.7879 - val_loss: 0.5263 - val_acc: 0.7545\n",
      "Epoch 19/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4486 - acc: 0.7936\n",
      "Epoch 00019: saving model to nn/Comedy/proc-weights-improvement-19-0.73.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.4502 - acc: 0.7927 - val_loss: 0.5582 - val_acc: 0.7323\n",
      "Epoch 20/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4609 - acc: 0.7876\n",
      "Epoch 00020: saving model to nn/Comedy/proc-weights-improvement-20-0.76.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.4615 - acc: 0.7876 - val_loss: 0.5403 - val_acc: 0.7573\n",
      "Epoch 21/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4611 - acc: 0.7855\n",
      "Epoch 00021: saving model to nn/Comedy/proc-weights-improvement-21-0.76.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.4608 - acc: 0.7864 - val_loss: 0.5389 - val_acc: 0.7614\n",
      "Epoch 22/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4386 - acc: 0.7918\n",
      "Epoch 00022: saving model to nn/Comedy/proc-weights-improvement-22-0.74.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.4381 - acc: 0.7927 - val_loss: 0.5344 - val_acc: 0.7448\n",
      "Epoch 23/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4232 - acc: 0.8116\n",
      "Epoch 00023: saving model to nn/Comedy/proc-weights-improvement-23-0.77.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.4228 - acc: 0.8114 - val_loss: 0.5488 - val_acc: 0.7656\n",
      "Epoch 24/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4164 - acc: 0.8101\n",
      "Epoch 00024: saving model to nn/Comedy/proc-weights-improvement-24-0.77.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.4153 - acc: 0.8105 - val_loss: 0.5649 - val_acc: 0.7656\n",
      "Epoch 25/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4082 - acc: 0.8122\n",
      "Epoch 00025: saving model to nn/Comedy/proc-weights-improvement-25-0.77.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.4084 - acc: 0.8120 - val_loss: 0.5330 - val_acc: 0.7670\n",
      "Epoch 26/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4081 - acc: 0.8206\n",
      "Epoch 00026: saving model to nn/Comedy/proc-weights-improvement-26-0.75.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.4071 - acc: 0.8212 - val_loss: 0.5927 - val_acc: 0.7476\n",
      "Epoch 27/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3924 - acc: 0.8197\n",
      "Epoch 00027: saving model to nn/Comedy/proc-weights-improvement-27-0.77.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.3908 - acc: 0.8206 - val_loss: 0.5611 - val_acc: 0.7684\n",
      "Epoch 28/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3801 - acc: 0.8314\n",
      "Epoch 00028: saving model to nn/Comedy/proc-weights-improvement-28-0.76.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.3807 - acc: 0.8308 - val_loss: 0.5581 - val_acc: 0.7573\n",
      "Epoch 29/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3807 - acc: 0.8293\n",
      "Epoch 00029: saving model to nn/Comedy/proc-weights-improvement-29-0.76.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.3791 - acc: 0.8302 - val_loss: 0.6113 - val_acc: 0.7628\n",
      "Epoch 30/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3552 - acc: 0.8468\n",
      "Epoch 00030: saving model to nn/Comedy/proc-weights-improvement-30-0.74.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.3564 - acc: 0.8462 - val_loss: 0.5830 - val_acc: 0.7406\n",
      "Epoch 31/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3452 - acc: 0.8465\n",
      "Epoch 00031: saving model to nn/Comedy/proc-weights-improvement-31-0.74.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.3479 - acc: 0.8462 - val_loss: 0.5631 - val_acc: 0.7434\n",
      "Epoch 32/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3446 - acc: 0.8525\n",
      "Epoch 00032: saving model to nn/Comedy/proc-weights-improvement-32-0.75.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.3441 - acc: 0.8528 - val_loss: 0.5839 - val_acc: 0.7476\n",
      "Epoch 33/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3138 - acc: 0.8603\n",
      "Epoch 00033: saving model to nn/Comedy/proc-weights-improvement-33-0.74.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.3131 - acc: 0.8608 - val_loss: 0.6237 - val_acc: 0.7379\n",
      "Epoch 34/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2928 - acc: 0.8723\n",
      "Epoch 00034: saving model to nn/Comedy/proc-weights-improvement-34-0.72.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.2920 - acc: 0.8730 - val_loss: 0.6643 - val_acc: 0.7212\n",
      "Epoch 35/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2955 - acc: 0.8723\n",
      "Epoch 00035: saving model to nn/Comedy/proc-weights-improvement-35-0.73.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.2952 - acc: 0.8724 - val_loss: 0.6223 - val_acc: 0.7309\n",
      "Epoch 36/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2769 - acc: 0.8831\n",
      "Epoch 00036: saving model to nn/Comedy/proc-weights-improvement-36-0.74.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.2785 - acc: 0.8828 - val_loss: 0.6629 - val_acc: 0.7420\n",
      "Epoch 37/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2748 - acc: 0.8861\n",
      "Epoch 00037: saving model to nn/Comedy/proc-weights-improvement-37-0.69.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2754 - acc: 0.8858 - val_loss: 0.7115 - val_acc: 0.6907\n",
      "Epoch 38/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2778 - acc: 0.8798\n",
      "Epoch 00038: saving model to nn/Comedy/proc-weights-improvement-38-0.72.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.2762 - acc: 0.8807 - val_loss: 0.7032 - val_acc: 0.7198\n",
      "Epoch 39/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2406 - acc: 0.8987\n",
      "Epoch 00039: saving model to nn/Comedy/proc-weights-improvement-39-0.73.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2399 - acc: 0.8995 - val_loss: 0.6898 - val_acc: 0.7337\n",
      "Epoch 40/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2133 - acc: 0.9147\n",
      "Epoch 00040: saving model to nn/Comedy/proc-weights-improvement-40-0.71.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2126 - acc: 0.9149 - val_loss: 0.7122 - val_acc: 0.7101\n",
      "Epoch 41/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1996 - acc: 0.9243\n",
      "Epoch 00041: saving model to nn/Comedy/proc-weights-improvement-41-0.73.hdf5\n",
      "3362/3362 [==============================] - 11s 3ms/step - loss: 0.1992 - acc: 0.9244 - val_loss: 0.7544 - val_acc: 0.7282\n",
      "Epoch 42/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1909 - acc: 0.9249\n",
      "Epoch 00042: saving model to nn/Comedy/proc-weights-improvement-42-0.72.hdf5\n",
      "3362/3362 [==============================] - 10s 3ms/step - loss: 0.1903 - acc: 0.9253 - val_loss: 0.8047 - val_acc: 0.7226\n",
      "Epoch 43/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2059 - acc: 0.9141\n",
      "Epoch 00043: saving model to nn/Comedy/proc-weights-improvement-43-0.74.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2051 - acc: 0.9143 - val_loss: 0.7517 - val_acc: 0.7406\n",
      "Epoch 44/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2018 - acc: 0.9195\n",
      "Epoch 00044: saving model to nn/Comedy/proc-weights-improvement-44-0.72.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2025 - acc: 0.9194 - val_loss: 0.8879 - val_acc: 0.7240\n",
      "Epoch 45/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1817 - acc: 0.9261\n",
      "Epoch 00045: saving model to nn/Comedy/proc-weights-improvement-45-0.73.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.1811 - acc: 0.9262 - val_loss: 0.7673 - val_acc: 0.7337\n",
      "Epoch 46/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1712 - acc: 0.9336\n",
      "Epoch 00046: saving model to nn/Comedy/proc-weights-improvement-46-0.72.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.1707 - acc: 0.9337 - val_loss: 0.8672 - val_acc: 0.7212\n",
      "Epoch 47/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1393 - acc: 0.9489\n",
      "Epoch 00047: saving model to nn/Comedy/proc-weights-improvement-47-0.72.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.1395 - acc: 0.9488 - val_loss: 0.9107 - val_acc: 0.7240\n",
      "Epoch 48/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1499 - acc: 0.9399\n",
      "Epoch 00048: saving model to nn/Comedy/proc-weights-improvement-48-0.72.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.1500 - acc: 0.9396 - val_loss: 0.7726 - val_acc: 0.7198\n",
      "Epoch 49/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1447 - acc: 0.9420\n",
      "Epoch 00049: saving model to nn/Comedy/proc-weights-improvement-49-0.72.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.1439 - acc: 0.9423 - val_loss: 0.8661 - val_acc: 0.7198\n",
      "Epoch 50/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1197 - acc: 0.9561\n",
      "Epoch 00050: saving model to nn/Comedy/proc-weights-improvement-50-0.70.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1195 - acc: 0.9563 - val_loss: 0.9179 - val_acc: 0.7004\n",
      "Crime\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 200, 100)          2410000   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 200, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,527,377\n",
      "Trainable params: 117,377\n",
      "Non-trainable params: 2,410,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3362 samples, validate on 721 samples\n",
      "Epoch 1/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4933 - acc: 0.8158\n",
      "Epoch 00001: saving model to nn/Crime/proc-weights-improvement-01-0.88.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.4932 - acc: 0.8159 - val_loss: 0.3689 - val_acc: 0.8766\n",
      "Epoch 2/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4199 - acc: 0.8507\n",
      "Epoch 00002: saving model to nn/Crime/proc-weights-improvement-02-0.88.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.4204 - acc: 0.8504 - val_loss: 0.3674 - val_acc: 0.8766\n",
      "Epoch 3/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4083 - acc: 0.8498\n",
      "Epoch 00003: saving model to nn/Crime/proc-weights-improvement-03-0.88.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.4073 - acc: 0.8504 - val_loss: 0.3554 - val_acc: 0.8766\n",
      "Epoch 4/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3951 - acc: 0.8513\n",
      "Epoch 00004: saving model to nn/Crime/proc-weights-improvement-04-0.88.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.3962 - acc: 0.8507 - val_loss: 0.3466 - val_acc: 0.8752\n",
      "Epoch 5/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3697 - acc: 0.8507\n",
      "Epoch 00005: saving model to nn/Crime/proc-weights-improvement-05-0.88.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.3709 - acc: 0.8498 - val_loss: 0.2965 - val_acc: 0.8807\n",
      "Epoch 6/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3312 - acc: 0.8654\n",
      "Epoch 00006: saving model to nn/Crime/proc-weights-improvement-06-0.89.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.3296 - acc: 0.8662 - val_loss: 0.2786 - val_acc: 0.8932\n",
      "Epoch 7/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3315 - acc: 0.8615\n",
      "Epoch 00007: saving model to nn/Crime/proc-weights-improvement-07-0.88.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.3319 - acc: 0.8608 - val_loss: 0.2995 - val_acc: 0.8821\n",
      "Epoch 8/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3212 - acc: 0.8654\n",
      "Epoch 00008: saving model to nn/Crime/proc-weights-improvement-08-0.87.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.3209 - acc: 0.8656 - val_loss: 0.2865 - val_acc: 0.8696\n",
      "Epoch 9/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2980 - acc: 0.8780\n",
      "Epoch 00009: saving model to nn/Crime/proc-weights-improvement-09-0.88.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2990 - acc: 0.8778 - val_loss: 0.2619 - val_acc: 0.8835\n",
      "Epoch 10/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2996 - acc: 0.8774\n",
      "Epoch 00010: saving model to nn/Crime/proc-weights-improvement-10-0.90.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.3005 - acc: 0.8769 - val_loss: 0.2695 - val_acc: 0.9001\n",
      "Epoch 11/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2885 - acc: 0.8828\n",
      "Epoch 00011: saving model to nn/Crime/proc-weights-improvement-11-0.89.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.2872 - acc: 0.8834 - val_loss: 0.2576 - val_acc: 0.8904\n",
      "Epoch 12/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2825 - acc: 0.8828\n",
      "Epoch 00012: saving model to nn/Crime/proc-weights-improvement-12-0.89.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.2848 - acc: 0.8819 - val_loss: 0.2604 - val_acc: 0.8932\n",
      "Epoch 13/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2922 - acc: 0.8750\n",
      "Epoch 00013: saving model to nn/Crime/proc-weights-improvement-13-0.90.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.2905 - acc: 0.8763 - val_loss: 0.2553 - val_acc: 0.9015\n",
      "Epoch 14/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2953 - acc: 0.8801\n",
      "Epoch 00014: saving model to nn/Crime/proc-weights-improvement-14-0.89.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.2954 - acc: 0.8798 - val_loss: 0.2544 - val_acc: 0.8904\n",
      "Epoch 15/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2765 - acc: 0.8819\n",
      "Epoch 00015: saving model to nn/Crime/proc-weights-improvement-15-0.88.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.2759 - acc: 0.8825 - val_loss: 0.2667 - val_acc: 0.8807\n",
      "Epoch 16/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2785 - acc: 0.8876\n",
      "Epoch 00016: saving model to nn/Crime/proc-weights-improvement-16-0.90.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.2787 - acc: 0.8876 - val_loss: 0.2582 - val_acc: 0.8960\n",
      "Epoch 17/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2695 - acc: 0.8879\n",
      "Epoch 00017: saving model to nn/Crime/proc-weights-improvement-17-0.86.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.2709 - acc: 0.8879 - val_loss: 0.2786 - val_acc: 0.8613\n",
      "Epoch 18/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2911 - acc: 0.8750\n",
      "Epoch 00018: saving model to nn/Crime/proc-weights-improvement-18-0.90.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.2912 - acc: 0.8748 - val_loss: 0.2683 - val_acc: 0.8960\n",
      "Epoch 19/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2729 - acc: 0.8852\n",
      "Epoch 00019: saving model to nn/Crime/proc-weights-improvement-19-0.89.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2727 - acc: 0.8849 - val_loss: 0.2552 - val_acc: 0.8946\n",
      "Epoch 20/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2651 - acc: 0.8903\n",
      "Epoch 00020: saving model to nn/Crime/proc-weights-improvement-20-0.90.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.2642 - acc: 0.8908 - val_loss: 0.2566 - val_acc: 0.9043\n",
      "Epoch 21/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2631 - acc: 0.8885\n",
      "Epoch 00021: saving model to nn/Crime/proc-weights-improvement-21-0.89.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2621 - acc: 0.8891 - val_loss: 0.2959 - val_acc: 0.8932\n",
      "Epoch 22/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2776 - acc: 0.8861\n",
      "Epoch 00022: saving model to nn/Crime/proc-weights-improvement-22-0.90.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.2762 - acc: 0.8870 - val_loss: 0.2624 - val_acc: 0.9001\n",
      "Epoch 23/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2543 - acc: 0.8906\n",
      "Epoch 00023: saving model to nn/Crime/proc-weights-improvement-23-0.89.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.2561 - acc: 0.8896 - val_loss: 0.2560 - val_acc: 0.8918\n",
      "Epoch 24/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2482 - acc: 0.8990\n",
      "Epoch 00024: saving model to nn/Crime/proc-weights-improvement-24-0.88.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.2485 - acc: 0.8983 - val_loss: 0.2659 - val_acc: 0.8849\n",
      "Epoch 25/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2385 - acc: 0.9032\n",
      "Epoch 00025: saving model to nn/Crime/proc-weights-improvement-25-0.88.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2391 - acc: 0.9024 - val_loss: 0.2774 - val_acc: 0.8779\n",
      "Epoch 26/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2299 - acc: 0.8996\n",
      "Epoch 00026: saving model to nn/Crime/proc-weights-improvement-26-0.90.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2291 - acc: 0.9004 - val_loss: 0.2462 - val_acc: 0.9015\n",
      "Epoch 27/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2266 - acc: 0.9072\n",
      "Epoch 00027: saving model to nn/Crime/proc-weights-improvement-27-0.90.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2280 - acc: 0.9066 - val_loss: 0.2677 - val_acc: 0.8988\n",
      "Epoch 28/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2280 - acc: 0.9084\n",
      "Epoch 00028: saving model to nn/Crime/proc-weights-improvement-28-0.89.hdf5\n",
      "3362/3362 [==============================] - 9s 3ms/step - loss: 0.2273 - acc: 0.9090 - val_loss: 0.2664 - val_acc: 0.8890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2174 - acc: 0.9123\n",
      "Epoch 00029: saving model to nn/Crime/proc-weights-improvement-29-0.89.hdf5\n",
      "3362/3362 [==============================] - 9s 3ms/step - loss: 0.2180 - acc: 0.9123 - val_loss: 0.2676 - val_acc: 0.8877\n",
      "Epoch 30/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2078 - acc: 0.9162\n",
      "Epoch 00030: saving model to nn/Crime/proc-weights-improvement-30-0.90.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.2077 - acc: 0.9167 - val_loss: 0.2664 - val_acc: 0.8974\n",
      "Epoch 31/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2006 - acc: 0.9198\n",
      "Epoch 00031: saving model to nn/Crime/proc-weights-improvement-31-0.87.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2001 - acc: 0.9200 - val_loss: 0.3008 - val_acc: 0.8669\n",
      "Epoch 32/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1899 - acc: 0.9243\n",
      "Epoch 00032: saving model to nn/Crime/proc-weights-improvement-32-0.90.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.1905 - acc: 0.9239 - val_loss: 0.2879 - val_acc: 0.9043\n",
      "Epoch 33/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1799 - acc: 0.9243\n",
      "Epoch 00033: saving model to nn/Crime/proc-weights-improvement-33-0.87.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.1794 - acc: 0.9247 - val_loss: 0.3295 - val_acc: 0.8682\n",
      "Epoch 34/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1869 - acc: 0.9204\n",
      "Epoch 00034: saving model to nn/Crime/proc-weights-improvement-34-0.89.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.1862 - acc: 0.9209 - val_loss: 0.2878 - val_acc: 0.8918\n",
      "Epoch 35/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1700 - acc: 0.9255\n",
      "Epoch 00035: saving model to nn/Crime/proc-weights-improvement-35-0.89.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.1690 - acc: 0.9262 - val_loss: 0.2923 - val_acc: 0.8863\n",
      "Epoch 36/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1539 - acc: 0.9384\n",
      "Epoch 00036: saving model to nn/Crime/proc-weights-improvement-36-0.88.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.1533 - acc: 0.9387 - val_loss: 0.3047 - val_acc: 0.8835\n",
      "Epoch 37/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1423 - acc: 0.9396\n",
      "Epoch 00037: saving model to nn/Crime/proc-weights-improvement-37-0.88.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.1422 - acc: 0.9396 - val_loss: 0.3542 - val_acc: 0.8821\n",
      "Epoch 38/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1469 - acc: 0.9420\n",
      "Epoch 00038: saving model to nn/Crime/proc-weights-improvement-38-0.87.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.1465 - acc: 0.9423 - val_loss: 0.3098 - val_acc: 0.8738\n",
      "Epoch 39/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1314 - acc: 0.9492\n",
      "Epoch 00039: saving model to nn/Crime/proc-weights-improvement-39-0.87.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.1308 - acc: 0.9494 - val_loss: 0.3280 - val_acc: 0.8724\n",
      "Epoch 40/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1175 - acc: 0.9558\n",
      "Epoch 00040: saving model to nn/Crime/proc-weights-improvement-40-0.88.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1182 - acc: 0.9557 - val_loss: 0.3208 - val_acc: 0.8849\n",
      "Epoch 41/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1232 - acc: 0.9549\n",
      "Epoch 00041: saving model to nn/Crime/proc-weights-improvement-41-0.89.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.1245 - acc: 0.9542 - val_loss: 0.3175 - val_acc: 0.8932\n",
      "Epoch 42/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1172 - acc: 0.9525\n",
      "Epoch 00042: saving model to nn/Crime/proc-weights-improvement-42-0.88.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.1169 - acc: 0.9527 - val_loss: 0.3225 - val_acc: 0.8821\n",
      "Epoch 43/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1035 - acc: 0.9591\n",
      "Epoch 00043: saving model to nn/Crime/proc-weights-improvement-43-0.86.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1027 - acc: 0.9595 - val_loss: 0.3598 - val_acc: 0.8641\n",
      "Epoch 44/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0976 - acc: 0.9630\n",
      "Epoch 00044: saving model to nn/Crime/proc-weights-improvement-44-0.89.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.0978 - acc: 0.9628 - val_loss: 0.3727 - val_acc: 0.8918\n",
      "Epoch 45/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0911 - acc: 0.9654\n",
      "Epoch 00045: saving model to nn/Crime/proc-weights-improvement-45-0.87.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.0914 - acc: 0.9649 - val_loss: 0.3922 - val_acc: 0.8724\n",
      "Epoch 46/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0834 - acc: 0.9700\n",
      "Epoch 00046: saving model to nn/Crime/proc-weights-improvement-46-0.88.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.0831 - acc: 0.9703 - val_loss: 0.3990 - val_acc: 0.8835\n",
      "Epoch 47/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0766 - acc: 0.9672\n",
      "Epoch 00047: saving model to nn/Crime/proc-weights-improvement-47-0.90.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.0771 - acc: 0.9670 - val_loss: 0.4100 - val_acc: 0.9001\n",
      "Epoch 48/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0939 - acc: 0.9636\n",
      "Epoch 00048: saving model to nn/Crime/proc-weights-improvement-48-0.88.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.0942 - acc: 0.9634 - val_loss: 0.3516 - val_acc: 0.8849\n",
      "Epoch 49/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0807 - acc: 0.9688\n",
      "Epoch 00049: saving model to nn/Crime/proc-weights-improvement-49-0.88.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.0805 - acc: 0.9691 - val_loss: 0.3941 - val_acc: 0.8849\n",
      "Epoch 50/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0711 - acc: 0.9772\n",
      "Epoch 00050: saving model to nn/Crime/proc-weights-improvement-50-0.89.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.0707 - acc: 0.9774 - val_loss: 0.4111 - val_acc: 0.8946\n",
      "Drama\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 200, 100)          2410000   \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 200, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,527,377\n",
      "Trainable params: 117,377\n",
      "Non-trainable params: 2,410,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 3362 samples, validate on 721 samples\n",
      "Epoch 1/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.6864 - acc: 0.5538\n",
      "Epoch 00001: saving model to nn/Drama/proc-weights-improvement-01-0.60.hdf5\n",
      "3362/3362 [==============================] - 10s 3ms/step - loss: 0.6862 - acc: 0.5541 - val_loss: 0.6651 - val_acc: 0.5978\n",
      "Epoch 2/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.6455 - acc: 0.6211\n",
      "Epoch 00002: saving model to nn/Drama/proc-weights-improvement-02-0.66.hdf5\n",
      "3362/3362 [==============================] - 8s 2ms/step - loss: 0.6449 - acc: 0.6214 - val_loss: 0.6159 - val_acc: 0.6560\n",
      "Epoch 3/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.6139 - acc: 0.6698\n",
      "Epoch 00003: saving model to nn/Drama/proc-weights-improvement-03-0.67.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.6148 - acc: 0.6686 - val_loss: 0.5895 - val_acc: 0.6741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.5982 - acc: 0.6791\n",
      "Epoch 00004: saving model to nn/Drama/proc-weights-improvement-04-0.66.hdf5\n",
      "3362/3362 [==============================] - 8s 2ms/step - loss: 0.5978 - acc: 0.6794 - val_loss: 0.6143 - val_acc: 0.6644\n",
      "Epoch 5/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.5918 - acc: 0.6839\n",
      "Epoch 00005: saving model to nn/Drama/proc-weights-improvement-05-0.68.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.5916 - acc: 0.6841 - val_loss: 0.5978 - val_acc: 0.6838\n",
      "Epoch 6/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.5795 - acc: 0.6962\n",
      "Epoch 00006: saving model to nn/Drama/proc-weights-improvement-06-0.70.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.5814 - acc: 0.6942 - val_loss: 0.5682 - val_acc: 0.7046\n",
      "Epoch 7/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.5715 - acc: 0.6932\n",
      "Epoch 00007: saving model to nn/Drama/proc-weights-improvement-07-0.69.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.5726 - acc: 0.6933 - val_loss: 0.5764 - val_acc: 0.6879\n",
      "Epoch 8/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.5647 - acc: 0.7136\n",
      "Epoch 00008: saving model to nn/Drama/proc-weights-improvement-08-0.69.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.5648 - acc: 0.7133 - val_loss: 0.6014 - val_acc: 0.6949\n",
      "Epoch 9/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.5587 - acc: 0.7106\n",
      "Epoch 00009: saving model to nn/Drama/proc-weights-improvement-09-0.69.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.5589 - acc: 0.7103 - val_loss: 0.5676 - val_acc: 0.6907\n",
      "Epoch 10/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.5520 - acc: 0.7194\n",
      "Epoch 00010: saving model to nn/Drama/proc-weights-improvement-10-0.70.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.5515 - acc: 0.7195 - val_loss: 0.5629 - val_acc: 0.6976\n",
      "Epoch 11/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.5398 - acc: 0.7308\n",
      "Epoch 00011: saving model to nn/Drama/proc-weights-improvement-11-0.66.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.5399 - acc: 0.7299 - val_loss: 0.5968 - val_acc: 0.6630\n",
      "Epoch 12/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.5415 - acc: 0.7308\n",
      "Epoch 00012: saving model to nn/Drama/proc-weights-improvement-12-0.70.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.5411 - acc: 0.7308 - val_loss: 0.5605 - val_acc: 0.6976\n",
      "Epoch 13/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.5335 - acc: 0.7290\n",
      "Epoch 00013: saving model to nn/Drama/proc-weights-improvement-13-0.68.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.5334 - acc: 0.7281 - val_loss: 0.5737 - val_acc: 0.6810\n",
      "Epoch 14/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.5244 - acc: 0.7365\n",
      "Epoch 00014: saving model to nn/Drama/proc-weights-improvement-14-0.66.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.5245 - acc: 0.7365 - val_loss: 0.5972 - val_acc: 0.6574\n",
      "Epoch 15/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.5436 - acc: 0.7194\n",
      "Epoch 00015: saving model to nn/Drama/proc-weights-improvement-15-0.70.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.5430 - acc: 0.7189 - val_loss: 0.5768 - val_acc: 0.7032\n",
      "Epoch 16/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.5188 - acc: 0.7407\n",
      "Epoch 00016: saving model to nn/Drama/proc-weights-improvement-16-0.71.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.5191 - acc: 0.7403 - val_loss: 0.5681 - val_acc: 0.7143\n",
      "Epoch 17/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.5129 - acc: 0.7434\n",
      "Epoch 00017: saving model to nn/Drama/proc-weights-improvement-17-0.70.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.5150 - acc: 0.7415 - val_loss: 0.5693 - val_acc: 0.7032\n",
      "Epoch 18/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.5132 - acc: 0.7416\n",
      "Epoch 00018: saving model to nn/Drama/proc-weights-improvement-18-0.70.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.5135 - acc: 0.7406 - val_loss: 0.5856 - val_acc: 0.6976\n",
      "Epoch 19/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.5081 - acc: 0.7449\n",
      "Epoch 00019: saving model to nn/Drama/proc-weights-improvement-19-0.70.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.5080 - acc: 0.7451 - val_loss: 0.5984 - val_acc: 0.6963\n",
      "Epoch 20/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.5044 - acc: 0.7482\n",
      "Epoch 00020: saving model to nn/Drama/proc-weights-improvement-20-0.69.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.5038 - acc: 0.7490 - val_loss: 0.5632 - val_acc: 0.6852\n",
      "Epoch 21/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4853 - acc: 0.7635\n",
      "Epoch 00021: saving model to nn/Drama/proc-weights-improvement-21-0.71.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.4861 - acc: 0.7632 - val_loss: 0.5686 - val_acc: 0.7074\n",
      "Epoch 22/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4714 - acc: 0.7731\n",
      "Epoch 00022: saving model to nn/Drama/proc-weights-improvement-22-0.71.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.4731 - acc: 0.7710 - val_loss: 0.5733 - val_acc: 0.7115\n",
      "Epoch 23/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4876 - acc: 0.7602\n",
      "Epoch 00023: saving model to nn/Drama/proc-weights-improvement-23-0.70.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.4866 - acc: 0.7606 - val_loss: 0.5847 - val_acc: 0.7046\n",
      "Epoch 24/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4850 - acc: 0.7671\n",
      "Epoch 00024: saving model to nn/Drama/proc-weights-improvement-24-0.70.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.4851 - acc: 0.7671 - val_loss: 0.5801 - val_acc: 0.7032\n",
      "Epoch 25/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4579 - acc: 0.7819\n",
      "Epoch 00025: saving model to nn/Drama/proc-weights-improvement-25-0.70.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.4582 - acc: 0.7817 - val_loss: 0.5918 - val_acc: 0.7046\n",
      "Epoch 26/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4461 - acc: 0.7888\n",
      "Epoch 00026: saving model to nn/Drama/proc-weights-improvement-26-0.71.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.4453 - acc: 0.7888 - val_loss: 0.5789 - val_acc: 0.7115\n",
      "Epoch 27/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4432 - acc: 0.7900\n",
      "Epoch 00027: saving model to nn/Drama/proc-weights-improvement-27-0.70.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.4436 - acc: 0.7900 - val_loss: 0.6218 - val_acc: 0.7018\n",
      "Epoch 28/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4498 - acc: 0.7903\n",
      "Epoch 00028: saving model to nn/Drama/proc-weights-improvement-28-0.65.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.4490 - acc: 0.7906 - val_loss: 0.6280 - val_acc: 0.6546\n",
      "Epoch 29/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4397 - acc: 0.7945\n",
      "Epoch 00029: saving model to nn/Drama/proc-weights-improvement-29-0.71.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.4395 - acc: 0.7951 - val_loss: 0.6011 - val_acc: 0.7129\n",
      "Epoch 30/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3955 - acc: 0.8158\n",
      "Epoch 00030: saving model to nn/Drama/proc-weights-improvement-30-0.72.hdf5\n",
      "3362/3362 [==============================] - 8s 2ms/step - loss: 0.3965 - acc: 0.8150 - val_loss: 0.5750 - val_acc: 0.7212\n",
      "Epoch 31/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3979 - acc: 0.8191\n",
      "Epoch 00031: saving model to nn/Drama/proc-weights-improvement-31-0.68.hdf5\n",
      "3362/3362 [==============================] - 8s 2ms/step - loss: 0.3994 - acc: 0.8177 - val_loss: 0.6360 - val_acc: 0.6782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3915 - acc: 0.8233\n",
      "Epoch 00032: saving model to nn/Drama/proc-weights-improvement-32-0.71.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.3907 - acc: 0.8242 - val_loss: 0.6601 - val_acc: 0.7143\n",
      "Epoch 33/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3687 - acc: 0.8356\n",
      "Epoch 00033: saving model to nn/Drama/proc-weights-improvement-33-0.70.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.3689 - acc: 0.8355 - val_loss: 0.6597 - val_acc: 0.6990\n",
      "Epoch 34/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3375 - acc: 0.8540\n",
      "Epoch 00034: saving model to nn/Drama/proc-weights-improvement-34-0.68.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.3393 - acc: 0.8528 - val_loss: 0.6798 - val_acc: 0.6782\n",
      "Epoch 35/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3424 - acc: 0.8531\n",
      "Epoch 00035: saving model to nn/Drama/proc-weights-improvement-35-0.71.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.3422 - acc: 0.8525 - val_loss: 0.6568 - val_acc: 0.7129\n",
      "Epoch 36/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3149 - acc: 0.8600\n",
      "Epoch 00036: saving model to nn/Drama/proc-weights-improvement-36-0.68.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.3169 - acc: 0.8578 - val_loss: 0.6693 - val_acc: 0.6768\n",
      "Epoch 37/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3414 - acc: 0.8462\n",
      "Epoch 00037: saving model to nn/Drama/proc-weights-improvement-37-0.66.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.3407 - acc: 0.8465 - val_loss: 0.6477 - val_acc: 0.6644\n",
      "Epoch 38/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3092 - acc: 0.8723\n",
      "Epoch 00038: saving model to nn/Drama/proc-weights-improvement-38-0.68.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.3081 - acc: 0.8727 - val_loss: 0.7492 - val_acc: 0.6810\n",
      "Epoch 39/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2875 - acc: 0.8828\n",
      "Epoch 00039: saving model to nn/Drama/proc-weights-improvement-39-0.70.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.2878 - acc: 0.8828 - val_loss: 0.7419 - val_acc: 0.6990\n",
      "Epoch 40/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2604 - acc: 0.8861\n",
      "Epoch 00040: saving model to nn/Drama/proc-weights-improvement-40-0.70.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2610 - acc: 0.8849 - val_loss: 0.7319 - val_acc: 0.7046\n",
      "Epoch 41/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2621 - acc: 0.8894\n",
      "Epoch 00041: saving model to nn/Drama/proc-weights-improvement-41-0.69.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.2636 - acc: 0.8891 - val_loss: 0.7082 - val_acc: 0.6935\n",
      "Epoch 42/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2744 - acc: 0.8867\n",
      "Epoch 00042: saving model to nn/Drama/proc-weights-improvement-42-0.69.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2734 - acc: 0.8876 - val_loss: 0.7611 - val_acc: 0.6921\n",
      "Epoch 43/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2489 - acc: 0.8909\n",
      "Epoch 00043: saving model to nn/Drama/proc-weights-improvement-43-0.69.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.2481 - acc: 0.8914 - val_loss: 0.7674 - val_acc: 0.6865\n",
      "Epoch 44/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2250 - acc: 0.9096\n",
      "Epoch 00044: saving model to nn/Drama/proc-weights-improvement-44-0.69.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2262 - acc: 0.9087 - val_loss: 0.7951 - val_acc: 0.6865\n",
      "Epoch 45/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2503 - acc: 0.8954\n",
      "Epoch 00045: saving model to nn/Drama/proc-weights-improvement-45-0.68.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2512 - acc: 0.8944 - val_loss: 0.7326 - val_acc: 0.6810\n",
      "Epoch 46/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2266 - acc: 0.9105\n",
      "Epoch 00046: saving model to nn/Drama/proc-weights-improvement-46-0.67.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.2268 - acc: 0.9105 - val_loss: 0.8352 - val_acc: 0.6657\n",
      "Epoch 47/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2032 - acc: 0.9219\n",
      "Epoch 00047: saving model to nn/Drama/proc-weights-improvement-47-0.68.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2048 - acc: 0.9212 - val_loss: 0.7873 - val_acc: 0.6838\n",
      "Epoch 48/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1910 - acc: 0.9231\n",
      "Epoch 00048: saving model to nn/Drama/proc-weights-improvement-48-0.70.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1917 - acc: 0.9227 - val_loss: 0.8627 - val_acc: 0.6976\n",
      "Epoch 49/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1722 - acc: 0.9303\n",
      "Epoch 00049: saving model to nn/Drama/proc-weights-improvement-49-0.68.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1715 - acc: 0.9307 - val_loss: 0.8780 - val_acc: 0.6782\n",
      "Epoch 50/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1445 - acc: 0.9468\n",
      "Epoch 00050: saving model to nn/Drama/proc-weights-improvement-50-0.67.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.1446 - acc: 0.9465 - val_loss: 0.9512 - val_acc: 0.6685\n",
      "Family\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 200, 100)          2410000   \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 200, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,527,377\n",
      "Trainable params: 117,377\n",
      "Non-trainable params: 2,410,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 3362 samples, validate on 721 samples\n",
      "Epoch 1/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3894 - acc: 0.8849\n",
      "Epoch 00001: saving model to nn/Family/proc-weights-improvement-01-0.88.hdf5\n",
      "3362/3362 [==============================] - 10s 3ms/step - loss: 0.3878 - acc: 0.8855 - val_loss: 0.3846 - val_acc: 0.8793\n",
      "Epoch 2/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3373 - acc: 0.8942\n",
      "Epoch 00002: saving model to nn/Family/proc-weights-improvement-02-0.88.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.3364 - acc: 0.8947 - val_loss: 0.3645 - val_acc: 0.8793\n",
      "Epoch 3/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3281 - acc: 0.8957\n",
      "Epoch 00003: saving model to nn/Family/proc-weights-improvement-03-0.88.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.3300 - acc: 0.8950 - val_loss: 0.3647 - val_acc: 0.8793\n",
      "Epoch 4/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3210 - acc: 0.8960\n",
      "Epoch 00004: saving model to nn/Family/proc-weights-improvement-04-0.88.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.3234 - acc: 0.8950 - val_loss: 0.3556 - val_acc: 0.8793\n",
      "Epoch 5/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3163 - acc: 0.8948\n",
      "Epoch 00005: saving model to nn/Family/proc-weights-improvement-05-0.88.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.3161 - acc: 0.8950 - val_loss: 0.3332 - val_acc: 0.8793\n",
      "Epoch 6/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2801 - acc: 0.8954\n",
      "Epoch 00006: saving model to nn/Family/proc-weights-improvement-06-0.88.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2792 - acc: 0.8959 - val_loss: 0.2834 - val_acc: 0.8821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2703 - acc: 0.8999\n",
      "Epoch 00007: saving model to nn/Family/proc-weights-improvement-07-0.87.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.2715 - acc: 0.8992 - val_loss: 0.3117 - val_acc: 0.8710\n",
      "Epoch 8/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2800 - acc: 0.8960\n",
      "Epoch 00008: saving model to nn/Family/proc-weights-improvement-08-0.87.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2801 - acc: 0.8959 - val_loss: 0.2965 - val_acc: 0.8724\n",
      "Epoch 9/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2578 - acc: 0.9005\n",
      "Epoch 00009: saving model to nn/Family/proc-weights-improvement-09-0.88.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2575 - acc: 0.8998 - val_loss: 0.2948 - val_acc: 0.8835\n",
      "Epoch 10/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2470 - acc: 0.9041\n",
      "Epoch 00010: saving model to nn/Family/proc-weights-improvement-10-0.89.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2453 - acc: 0.9051 - val_loss: 0.2837 - val_acc: 0.8863\n",
      "Epoch 11/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2396 - acc: 0.9099\n",
      "Epoch 00011: saving model to nn/Family/proc-weights-improvement-11-0.89.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2394 - acc: 0.9099 - val_loss: 0.2892 - val_acc: 0.8890\n",
      "Epoch 12/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2445 - acc: 0.9023\n",
      "Epoch 00012: saving model to nn/Family/proc-weights-improvement-12-0.89.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2442 - acc: 0.9021 - val_loss: 0.2900 - val_acc: 0.8863\n",
      "Epoch 13/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2386 - acc: 0.9102\n",
      "Epoch 00013: saving model to nn/Family/proc-weights-improvement-13-0.90.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2379 - acc: 0.9102 - val_loss: 0.2735 - val_acc: 0.9029\n",
      "Epoch 14/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2232 - acc: 0.9159\n",
      "Epoch 00014: saving model to nn/Family/proc-weights-improvement-14-0.89.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2222 - acc: 0.9161 - val_loss: 0.2964 - val_acc: 0.8946\n",
      "Epoch 15/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2179 - acc: 0.9177\n",
      "Epoch 00015: saving model to nn/Family/proc-weights-improvement-15-0.90.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.2190 - acc: 0.9167 - val_loss: 0.2618 - val_acc: 0.9029\n",
      "Epoch 16/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2120 - acc: 0.9177\n",
      "Epoch 00016: saving model to nn/Family/proc-weights-improvement-16-0.91.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2115 - acc: 0.9179 - val_loss: 0.2763 - val_acc: 0.9071\n",
      "Epoch 17/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2102 - acc: 0.9195\n",
      "Epoch 00017: saving model to nn/Family/proc-weights-improvement-17-0.90.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.2108 - acc: 0.9191 - val_loss: 0.2685 - val_acc: 0.9029\n",
      "Epoch 18/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2055 - acc: 0.9210\n",
      "Epoch 00018: saving model to nn/Family/proc-weights-improvement-18-0.91.hdf5\n",
      "3362/3362 [==============================] - 8s 2ms/step - loss: 0.2048 - acc: 0.9215 - val_loss: 0.2840 - val_acc: 0.9057\n",
      "Epoch 19/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2029 - acc: 0.9210\n",
      "Epoch 00019: saving model to nn/Family/proc-weights-improvement-19-0.91.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2045 - acc: 0.9203 - val_loss: 0.2819 - val_acc: 0.9057\n",
      "Epoch 20/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1974 - acc: 0.9243\n",
      "Epoch 00020: saving model to nn/Family/proc-weights-improvement-20-0.90.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1974 - acc: 0.9244 - val_loss: 0.2583 - val_acc: 0.9001\n",
      "Epoch 21/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1882 - acc: 0.9312\n",
      "Epoch 00021: saving model to nn/Family/proc-weights-improvement-21-0.90.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.1883 - acc: 0.9307 - val_loss: 0.2637 - val_acc: 0.9001\n",
      "Epoch 22/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1833 - acc: 0.9297\n",
      "Epoch 00022: saving model to nn/Family/proc-weights-improvement-22-0.89.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1825 - acc: 0.9301 - val_loss: 0.2761 - val_acc: 0.8877\n",
      "Epoch 23/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1853 - acc: 0.9297\n",
      "Epoch 00023: saving model to nn/Family/proc-weights-improvement-23-0.89.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1842 - acc: 0.9301 - val_loss: 0.2850 - val_acc: 0.8946\n",
      "Epoch 24/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1728 - acc: 0.9345\n",
      "Epoch 00024: saving model to nn/Family/proc-weights-improvement-24-0.87.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.1750 - acc: 0.9340 - val_loss: 0.3038 - val_acc: 0.8724\n",
      "Epoch 25/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2043 - acc: 0.9225\n",
      "Epoch 00025: saving model to nn/Family/proc-weights-improvement-25-0.90.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.2041 - acc: 0.9224 - val_loss: 0.2711 - val_acc: 0.8974\n",
      "Epoch 26/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1788 - acc: 0.9330\n",
      "Epoch 00026: saving model to nn/Family/proc-weights-improvement-26-0.90.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.1794 - acc: 0.9325 - val_loss: 0.2617 - val_acc: 0.9015\n",
      "Epoch 27/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1804 - acc: 0.9348\n",
      "Epoch 00027: saving model to nn/Family/proc-weights-improvement-27-0.90.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.1811 - acc: 0.9346 - val_loss: 0.2702 - val_acc: 0.8974\n",
      "Epoch 28/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1751 - acc: 0.9327\n",
      "Epoch 00028: saving model to nn/Family/proc-weights-improvement-28-0.90.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.1741 - acc: 0.9331 - val_loss: 0.2936 - val_acc: 0.9001\n",
      "Epoch 29/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1659 - acc: 0.9408\n",
      "Epoch 00029: saving model to nn/Family/proc-weights-improvement-29-0.90.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.1652 - acc: 0.9411 - val_loss: 0.3267 - val_acc: 0.9001\n",
      "Epoch 30/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1744 - acc: 0.9333\n",
      "Epoch 00030: saving model to nn/Family/proc-weights-improvement-30-0.90.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.1740 - acc: 0.9334 - val_loss: 0.2898 - val_acc: 0.9001\n",
      "Epoch 31/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1555 - acc: 0.9402\n",
      "Epoch 00031: saving model to nn/Family/proc-weights-improvement-31-0.89.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.1551 - acc: 0.9405 - val_loss: 0.2980 - val_acc: 0.8877\n",
      "Epoch 32/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1444 - acc: 0.9486\n",
      "Epoch 00032: saving model to nn/Family/proc-weights-improvement-32-0.90.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.1456 - acc: 0.9479 - val_loss: 0.2788 - val_acc: 0.8974\n",
      "Epoch 33/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1482 - acc: 0.9444\n",
      "Epoch 00033: saving model to nn/Family/proc-weights-improvement-33-0.90.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.1476 - acc: 0.9450 - val_loss: 0.2769 - val_acc: 0.8974\n",
      "Epoch 34/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1489 - acc: 0.9426\n",
      "Epoch 00034: saving model to nn/Family/proc-weights-improvement-34-0.89.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.1486 - acc: 0.9429 - val_loss: 0.2934 - val_acc: 0.8918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1344 - acc: 0.9495\n",
      "Epoch 00035: saving model to nn/Family/proc-weights-improvement-35-0.89.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.1352 - acc: 0.9491 - val_loss: 0.2969 - val_acc: 0.8932\n",
      "Epoch 36/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1284 - acc: 0.9504\n",
      "Epoch 00036: saving model to nn/Family/proc-weights-improvement-36-0.90.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.1286 - acc: 0.9500 - val_loss: 0.3425 - val_acc: 0.8988\n",
      "Epoch 37/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1345 - acc: 0.9462\n",
      "Epoch 00037: saving model to nn/Family/proc-weights-improvement-37-0.89.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.1359 - acc: 0.9453 - val_loss: 0.2845 - val_acc: 0.8877\n",
      "Epoch 38/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1221 - acc: 0.9519\n",
      "Epoch 00038: saving model to nn/Family/proc-weights-improvement-38-0.89.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.1216 - acc: 0.9521 - val_loss: 0.3200 - val_acc: 0.8904\n",
      "Epoch 39/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1192 - acc: 0.9564\n",
      "Epoch 00039: saving model to nn/Family/proc-weights-improvement-39-0.88.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1216 - acc: 0.9554 - val_loss: 0.2925 - val_acc: 0.8766\n",
      "Epoch 40/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1248 - acc: 0.9555\n",
      "Epoch 00040: saving model to nn/Family/proc-weights-improvement-40-0.89.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1240 - acc: 0.9560 - val_loss: 0.3150 - val_acc: 0.8877\n",
      "Epoch 41/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1068 - acc: 0.9606\n",
      "Epoch 00041: saving model to nn/Family/proc-weights-improvement-41-0.89.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1058 - acc: 0.9610 - val_loss: 0.3460 - val_acc: 0.8890\n",
      "Epoch 42/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0931 - acc: 0.9630\n",
      "Epoch 00042: saving model to nn/Family/proc-weights-improvement-42-0.90.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.0924 - acc: 0.9634 - val_loss: 0.3801 - val_acc: 0.8960\n",
      "Epoch 43/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0926 - acc: 0.9666\n",
      "Epoch 00043: saving model to nn/Family/proc-weights-improvement-43-0.88.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.0932 - acc: 0.9661 - val_loss: 0.3552 - val_acc: 0.8849\n",
      "Epoch 44/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0931 - acc: 0.9672\n",
      "Epoch 00044: saving model to nn/Family/proc-weights-improvement-44-0.89.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.0931 - acc: 0.9670 - val_loss: 0.3710 - val_acc: 0.8877\n",
      "Epoch 45/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0874 - acc: 0.9666\n",
      "Epoch 00045: saving model to nn/Family/proc-weights-improvement-45-0.87.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.0876 - acc: 0.9664 - val_loss: 0.3559 - val_acc: 0.8724\n",
      "Epoch 46/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0851 - acc: 0.9700\n",
      "Epoch 00046: saving model to nn/Family/proc-weights-improvement-46-0.90.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.0845 - acc: 0.9703 - val_loss: 0.3818 - val_acc: 0.8960\n",
      "Fantasy\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 200, 100)          2410000   \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 200, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,527,377\n",
      "Trainable params: 117,377\n",
      "Non-trainable params: 2,410,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 3362 samples, validate on 721 samples\n",
      "Epoch 1/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3812 - acc: 0.8894\n",
      "Epoch 00001: saving model to nn/Fantasy/proc-weights-improvement-01-0.91.hdf5\n",
      "3362/3362 [==============================] - 10s 3ms/step - loss: 0.3804 - acc: 0.8896 - val_loss: 0.3204 - val_acc: 0.9085\n",
      "Epoch 2/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3014 - acc: 0.9132\n",
      "Epoch 00002: saving model to nn/Fantasy/proc-weights-improvement-02-0.91.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.3028 - acc: 0.9123 - val_loss: 0.3031 - val_acc: 0.9085\n",
      "Epoch 3/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2949 - acc: 0.9117\n",
      "Epoch 00003: saving model to nn/Fantasy/proc-weights-improvement-03-0.91.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2936 - acc: 0.9123 - val_loss: 0.2990 - val_acc: 0.9085\n",
      "Epoch 4/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2929 - acc: 0.9114\n",
      "Epoch 00004: saving model to nn/Fantasy/proc-weights-improvement-04-0.91.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2909 - acc: 0.9123 - val_loss: 0.2946 - val_acc: 0.9085\n",
      "Epoch 5/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2863 - acc: 0.9123\n",
      "Epoch 00005: saving model to nn/Fantasy/proc-weights-improvement-05-0.91.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2865 - acc: 0.9123 - val_loss: 0.2901 - val_acc: 0.9085\n",
      "Epoch 6/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2804 - acc: 0.9129\n",
      "Epoch 00006: saving model to nn/Fantasy/proc-weights-improvement-06-0.91.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2810 - acc: 0.9126 - val_loss: 0.2819 - val_acc: 0.9085\n",
      "Epoch 7/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2683 - acc: 0.9129\n",
      "Epoch 00007: saving model to nn/Fantasy/proc-weights-improvement-07-0.91.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2683 - acc: 0.9126 - val_loss: 0.2659 - val_acc: 0.9085\n",
      "Epoch 8/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2516 - acc: 0.9108\n",
      "Epoch 00008: saving model to nn/Fantasy/proc-weights-improvement-08-0.91.hdf5\n",
      "3362/3362 [==============================] - 8s 2ms/step - loss: 0.2511 - acc: 0.9111 - val_loss: 0.2466 - val_acc: 0.9140\n",
      "Epoch 9/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2405 - acc: 0.9108\n",
      "Epoch 00009: saving model to nn/Fantasy/proc-weights-improvement-09-0.91.hdf5\n",
      "3362/3362 [==============================] - 8s 2ms/step - loss: 0.2411 - acc: 0.9108 - val_loss: 0.2372 - val_acc: 0.9140\n",
      "Epoch 10/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2536 - acc: 0.9135\n",
      "Epoch 00010: saving model to nn/Fantasy/proc-weights-improvement-10-0.91.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2536 - acc: 0.9137 - val_loss: 0.2593 - val_acc: 0.9085\n",
      "Epoch 11/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2344 - acc: 0.9129\n",
      "Epoch 00011: saving model to nn/Fantasy/proc-weights-improvement-11-0.92.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2339 - acc: 0.9131 - val_loss: 0.2432 - val_acc: 0.9168\n",
      "Epoch 12/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2347 - acc: 0.9138\n",
      "Epoch 00012: saving model to nn/Fantasy/proc-weights-improvement-12-0.92.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2346 - acc: 0.9134 - val_loss: 0.2297 - val_acc: 0.9196\n",
      "Epoch 13/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2191 - acc: 0.9147\n",
      "Epoch 00013: saving model to nn/Fantasy/proc-weights-improvement-13-0.92.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2188 - acc: 0.9149 - val_loss: 0.2149 - val_acc: 0.9196\n",
      "Epoch 14/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2184 - acc: 0.9174\n",
      "Epoch 00014: saving model to nn/Fantasy/proc-weights-improvement-14-0.92.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2179 - acc: 0.9173 - val_loss: 0.2106 - val_acc: 0.9196\n",
      "Epoch 15/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2146 - acc: 0.9216\n",
      "Epoch 00015: saving model to nn/Fantasy/proc-weights-improvement-15-0.92.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2145 - acc: 0.9215 - val_loss: 0.2151 - val_acc: 0.9223\n",
      "Epoch 16/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2043 - acc: 0.9213\n",
      "Epoch 00016: saving model to nn/Fantasy/proc-weights-improvement-16-0.92.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.2038 - acc: 0.9212 - val_loss: 0.2063 - val_acc: 0.9168\n",
      "Epoch 17/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2058 - acc: 0.9240\n",
      "Epoch 00017: saving model to nn/Fantasy/proc-weights-improvement-17-0.92.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2047 - acc: 0.9239 - val_loss: 0.2319 - val_acc: 0.9223\n",
      "Epoch 18/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2005 - acc: 0.9213\n",
      "Epoch 00018: saving model to nn/Fantasy/proc-weights-improvement-18-0.92.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1996 - acc: 0.9212 - val_loss: 0.2081 - val_acc: 0.9223\n",
      "Epoch 19/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1957 - acc: 0.9249\n",
      "Epoch 00019: saving model to nn/Fantasy/proc-weights-improvement-19-0.92.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.1951 - acc: 0.9247 - val_loss: 0.2092 - val_acc: 0.9237\n",
      "Epoch 20/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2011 - acc: 0.9291\n",
      "Epoch 00020: saving model to nn/Fantasy/proc-weights-improvement-20-0.93.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.2010 - acc: 0.9292 - val_loss: 0.2242 - val_acc: 0.9279\n",
      "Epoch 21/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1887 - acc: 0.9288\n",
      "Epoch 00021: saving model to nn/Fantasy/proc-weights-improvement-21-0.93.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1885 - acc: 0.9286 - val_loss: 0.1992 - val_acc: 0.9279\n",
      "Epoch 22/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1790 - acc: 0.9297\n",
      "Epoch 00022: saving model to nn/Fantasy/proc-weights-improvement-22-0.90.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1799 - acc: 0.9289 - val_loss: 0.2119 - val_acc: 0.9043\n",
      "Epoch 23/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1827 - acc: 0.9324\n",
      "Epoch 00023: saving model to nn/Fantasy/proc-weights-improvement-23-0.91.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1841 - acc: 0.9319 - val_loss: 0.2252 - val_acc: 0.9098\n",
      "Epoch 24/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1816 - acc: 0.9336\n",
      "Epoch 00024: saving model to nn/Fantasy/proc-weights-improvement-24-0.93.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1811 - acc: 0.9340 - val_loss: 0.1973 - val_acc: 0.9279\n",
      "Epoch 25/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1744 - acc: 0.9303\n",
      "Epoch 00025: saving model to nn/Fantasy/proc-weights-improvement-25-0.92.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1751 - acc: 0.9301 - val_loss: 0.2092 - val_acc: 0.9168\n",
      "Epoch 26/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1672 - acc: 0.9348\n",
      "Epoch 00026: saving model to nn/Fantasy/proc-weights-improvement-26-0.92.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1677 - acc: 0.9349 - val_loss: 0.2101 - val_acc: 0.9182\n",
      "Epoch 27/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1632 - acc: 0.9387\n",
      "Epoch 00027: saving model to nn/Fantasy/proc-weights-improvement-27-0.92.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1622 - acc: 0.9393 - val_loss: 0.2150 - val_acc: 0.9209\n",
      "Epoch 28/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1609 - acc: 0.9372\n",
      "Epoch 00028: saving model to nn/Fantasy/proc-weights-improvement-28-0.93.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.1615 - acc: 0.9366 - val_loss: 0.2021 - val_acc: 0.9251\n",
      "Epoch 29/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1539 - acc: 0.9405\n",
      "Epoch 00029: saving model to nn/Fantasy/proc-weights-improvement-29-0.92.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1531 - acc: 0.9411 - val_loss: 0.2107 - val_acc: 0.9196\n",
      "Epoch 30/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1420 - acc: 0.9468\n",
      "Epoch 00030: saving model to nn/Fantasy/proc-weights-improvement-30-0.89.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1423 - acc: 0.9462 - val_loss: 0.2408 - val_acc: 0.8863\n",
      "Epoch 31/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1684 - acc: 0.9348\n",
      "Epoch 00031: saving model to nn/Fantasy/proc-weights-improvement-31-0.92.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1682 - acc: 0.9346 - val_loss: 0.2152 - val_acc: 0.9237\n",
      "Epoch 32/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1510 - acc: 0.9435\n",
      "Epoch 00032: saving model to nn/Fantasy/proc-weights-improvement-32-0.92.hdf5\n",
      "3362/3362 [==============================] - 9s 3ms/step - loss: 0.1511 - acc: 0.9435 - val_loss: 0.2104 - val_acc: 0.9209\n",
      "Epoch 33/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1412 - acc: 0.9510\n",
      "Epoch 00033: saving model to nn/Fantasy/proc-weights-improvement-33-0.92.hdf5\n",
      "3362/3362 [==============================] - 8s 2ms/step - loss: 0.1413 - acc: 0.9506 - val_loss: 0.2218 - val_acc: 0.9223\n",
      "Epoch 34/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1342 - acc: 0.9495\n",
      "Epoch 00034: saving model to nn/Fantasy/proc-weights-improvement-34-0.91.hdf5\n",
      "3362/3362 [==============================] - 8s 2ms/step - loss: 0.1332 - acc: 0.9500 - val_loss: 0.2535 - val_acc: 0.9140\n",
      "Epoch 35/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1349 - acc: 0.9486\n",
      "Epoch 00035: saving model to nn/Fantasy/proc-weights-improvement-35-0.92.hdf5\n",
      "3362/3362 [==============================] - 8s 3ms/step - loss: 0.1352 - acc: 0.9485 - val_loss: 0.2291 - val_acc: 0.9209\n",
      "Epoch 36/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1205 - acc: 0.9522\n",
      "Epoch 00036: saving model to nn/Fantasy/proc-weights-improvement-36-0.91.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.1196 - acc: 0.9527 - val_loss: 0.2486 - val_acc: 0.9112\n",
      "Epoch 37/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1162 - acc: 0.9564\n",
      "Epoch 00037: saving model to nn/Fantasy/proc-weights-improvement-37-0.91.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.1157 - acc: 0.9566 - val_loss: 0.2546 - val_acc: 0.9140\n",
      "Epoch 38/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1103 - acc: 0.9567\n",
      "Epoch 00038: saving model to nn/Fantasy/proc-weights-improvement-38-0.90.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.1095 - acc: 0.9572 - val_loss: 0.2441 - val_acc: 0.8960\n",
      "Epoch 39/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1151 - acc: 0.9573\n",
      "Epoch 00039: saving model to nn/Fantasy/proc-weights-improvement-39-0.91.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.1153 - acc: 0.9569 - val_loss: 0.2400 - val_acc: 0.9085\n",
      "Epoch 40/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1090 - acc: 0.9585\n",
      "Epoch 00040: saving model to nn/Fantasy/proc-weights-improvement-40-0.92.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.1092 - acc: 0.9587 - val_loss: 0.2636 - val_acc: 0.9168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0954 - acc: 0.9669\n",
      "Epoch 00041: saving model to nn/Fantasy/proc-weights-improvement-41-0.91.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.0958 - acc: 0.9664 - val_loss: 0.2588 - val_acc: 0.9126\n",
      "Epoch 42/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0803 - acc: 0.9733\n",
      "Epoch 00042: saving model to nn/Fantasy/proc-weights-improvement-42-0.90.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.0808 - acc: 0.9729 - val_loss: 0.2770 - val_acc: 0.9001\n",
      "Epoch 43/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0867 - acc: 0.9678\n",
      "Epoch 00043: saving model to nn/Fantasy/proc-weights-improvement-43-0.91.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.0863 - acc: 0.9682 - val_loss: 0.2574 - val_acc: 0.9098\n",
      "Epoch 44/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0795 - acc: 0.9751\n",
      "Epoch 00044: saving model to nn/Fantasy/proc-weights-improvement-44-0.91.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.0795 - acc: 0.9750 - val_loss: 0.3110 - val_acc: 0.9071\n",
      "Epoch 45/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0679 - acc: 0.9760\n",
      "Epoch 00045: saving model to nn/Fantasy/proc-weights-improvement-45-0.91.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.0685 - acc: 0.9756 - val_loss: 0.2911 - val_acc: 0.9085\n",
      "Epoch 46/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0737 - acc: 0.9760\n",
      "Epoch 00046: saving model to nn/Fantasy/proc-weights-improvement-46-0.92.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.0736 - acc: 0.9759 - val_loss: 0.2849 - val_acc: 0.9154\n",
      "Epoch 47/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0627 - acc: 0.9778\n",
      "Epoch 00047: saving model to nn/Fantasy/proc-weights-improvement-47-0.91.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.0631 - acc: 0.9774 - val_loss: 0.3325 - val_acc: 0.9098\n",
      "Epoch 48/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0682 - acc: 0.9733\n",
      "Epoch 00048: saving model to nn/Fantasy/proc-weights-improvement-48-0.90.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.0688 - acc: 0.9729 - val_loss: 0.2515 - val_acc: 0.8960\n",
      "Epoch 49/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0600 - acc: 0.9817\n",
      "Epoch 00049: saving model to nn/Fantasy/proc-weights-improvement-49-0.91.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.0599 - acc: 0.9819 - val_loss: 0.3016 - val_acc: 0.9098\n",
      "Epoch 50/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0535 - acc: 0.9820\n",
      "Epoch 00050: saving model to nn/Fantasy/proc-weights-improvement-50-0.91.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.0533 - acc: 0.9819 - val_loss: 0.2952 - val_acc: 0.9071\n",
      "Horror\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 200, 100)          2410000   \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 200, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,527,377\n",
      "Trainable params: 117,377\n",
      "Non-trainable params: 2,410,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 3362 samples, validate on 721 samples\n",
      "Epoch 1/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4157 - acc: 0.8525\n",
      "Epoch 00001: saving model to nn/Horror/proc-weights-improvement-01-0.89.hdf5\n",
      "3362/3362 [==============================] - 10s 3ms/step - loss: 0.4180 - acc: 0.8519 - val_loss: 0.3372 - val_acc: 0.8946\n",
      "Epoch 2/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3408 - acc: 0.8915\n",
      "Epoch 00002: saving model to nn/Horror/proc-weights-improvement-02-0.89.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.3415 - acc: 0.8911 - val_loss: 0.3252 - val_acc: 0.8946\n",
      "Epoch 3/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3364 - acc: 0.8906\n",
      "Epoch 00003: saving model to nn/Horror/proc-weights-improvement-03-0.89.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.3361 - acc: 0.8908 - val_loss: 0.3169 - val_acc: 0.8946\n",
      "Epoch 4/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3286 - acc: 0.8921\n",
      "Epoch 00004: saving model to nn/Horror/proc-weights-improvement-04-0.89.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.3304 - acc: 0.8911 - val_loss: 0.3106 - val_acc: 0.8946\n",
      "Epoch 5/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3156 - acc: 0.8918\n",
      "Epoch 00005: saving model to nn/Horror/proc-weights-improvement-05-0.89.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.3165 - acc: 0.8911 - val_loss: 0.2964 - val_acc: 0.8946\n",
      "Epoch 6/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2910 - acc: 0.8924\n",
      "Epoch 00006: saving model to nn/Horror/proc-weights-improvement-06-0.89.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.2905 - acc: 0.8920 - val_loss: 0.2710 - val_acc: 0.8946\n",
      "Epoch 7/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2877 - acc: 0.8939\n",
      "Epoch 00007: saving model to nn/Horror/proc-weights-improvement-07-0.89.hdf5\n",
      "3362/3362 [==============================] - 8s 2ms/step - loss: 0.2867 - acc: 0.8944 - val_loss: 0.2829 - val_acc: 0.8932\n",
      "Epoch 8/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2737 - acc: 0.8990\n",
      "Epoch 00008: saving model to nn/Horror/proc-weights-improvement-08-0.89.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2720 - acc: 0.8998 - val_loss: 0.2789 - val_acc: 0.8946\n",
      "Epoch 9/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2791 - acc: 0.8930\n",
      "Epoch 00009: saving model to nn/Horror/proc-weights-improvement-09-0.90.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.2778 - acc: 0.8938 - val_loss: 0.2631 - val_acc: 0.8960\n",
      "Epoch 10/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2575 - acc: 0.8960\n",
      "Epoch 00010: saving model to nn/Horror/proc-weights-improvement-10-0.90.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2572 - acc: 0.8965 - val_loss: 0.2497 - val_acc: 0.8988\n",
      "Epoch 11/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2465 - acc: 0.9044\n",
      "Epoch 00011: saving model to nn/Horror/proc-weights-improvement-11-0.89.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2455 - acc: 0.9048 - val_loss: 0.2594 - val_acc: 0.8932\n",
      "Epoch 12/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2401 - acc: 0.9050\n",
      "Epoch 00012: saving model to nn/Horror/proc-weights-improvement-12-0.90.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2405 - acc: 0.9045 - val_loss: 0.2477 - val_acc: 0.9043\n",
      "Epoch 13/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2416 - acc: 0.9032\n",
      "Epoch 00013: saving model to nn/Horror/proc-weights-improvement-13-0.90.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2409 - acc: 0.9036 - val_loss: 0.2400 - val_acc: 0.9029\n",
      "Epoch 14/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2228 - acc: 0.9105\n",
      "Epoch 00014: saving model to nn/Horror/proc-weights-improvement-14-0.90.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2230 - acc: 0.9102 - val_loss: 0.2456 - val_acc: 0.9029\n",
      "Epoch 15/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2255 - acc: 0.9129\n",
      "Epoch 00015: saving model to nn/Horror/proc-weights-improvement-15-0.90.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.2242 - acc: 0.9134 - val_loss: 0.2576 - val_acc: 0.9015\n",
      "Epoch 16/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2231 - acc: 0.9087\n",
      "Epoch 00016: saving model to nn/Horror/proc-weights-improvement-16-0.90.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2237 - acc: 0.9084 - val_loss: 0.2314 - val_acc: 0.9001\n",
      "Epoch 17/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2190 - acc: 0.9147\n",
      "Epoch 00017: saving model to nn/Horror/proc-weights-improvement-17-0.90.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.2193 - acc: 0.9146 - val_loss: 0.2314 - val_acc: 0.8988\n",
      "Epoch 18/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2022 - acc: 0.9144\n",
      "Epoch 00018: saving model to nn/Horror/proc-weights-improvement-18-0.86.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2021 - acc: 0.9143 - val_loss: 0.2845 - val_acc: 0.8585\n",
      "Epoch 19/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2079 - acc: 0.9090\n",
      "Epoch 00019: saving model to nn/Horror/proc-weights-improvement-19-0.91.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2085 - acc: 0.9093 - val_loss: 0.2229 - val_acc: 0.9071\n",
      "Epoch 20/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1959 - acc: 0.9159\n",
      "Epoch 00020: saving model to nn/Horror/proc-weights-improvement-20-0.91.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1979 - acc: 0.9152 - val_loss: 0.2209 - val_acc: 0.9140\n",
      "Epoch 21/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1879 - acc: 0.9240\n",
      "Epoch 00021: saving model to nn/Horror/proc-weights-improvement-21-0.91.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1885 - acc: 0.9239 - val_loss: 0.2342 - val_acc: 0.9098\n",
      "Epoch 22/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2010 - acc: 0.9129\n",
      "Epoch 00022: saving model to nn/Horror/proc-weights-improvement-22-0.90.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2014 - acc: 0.9123 - val_loss: 0.2350 - val_acc: 0.9015\n",
      "Epoch 23/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2095 - acc: 0.9156\n",
      "Epoch 00023: saving model to nn/Horror/proc-weights-improvement-23-0.90.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.2102 - acc: 0.9155 - val_loss: 0.2297 - val_acc: 0.9029\n",
      "Epoch 24/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1904 - acc: 0.9234\n",
      "Epoch 00024: saving model to nn/Horror/proc-weights-improvement-24-0.91.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1907 - acc: 0.9230 - val_loss: 0.2165 - val_acc: 0.9140\n",
      "Epoch 25/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1822 - acc: 0.9249\n",
      "Epoch 00025: saving model to nn/Horror/proc-weights-improvement-25-0.90.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1822 - acc: 0.9250 - val_loss: 0.2380 - val_acc: 0.8988\n",
      "Epoch 26/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1787 - acc: 0.9303\n",
      "Epoch 00026: saving model to nn/Horror/proc-weights-improvement-26-0.91.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.1782 - acc: 0.9307 - val_loss: 0.2194 - val_acc: 0.9071\n",
      "Epoch 27/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1605 - acc: 0.9366\n",
      "Epoch 00027: saving model to nn/Horror/proc-weights-improvement-27-0.90.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1594 - acc: 0.9372 - val_loss: 0.2332 - val_acc: 0.9015\n",
      "Epoch 28/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1551 - acc: 0.9375\n",
      "Epoch 00028: saving model to nn/Horror/proc-weights-improvement-28-0.91.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.1547 - acc: 0.9375 - val_loss: 0.2254 - val_acc: 0.9112\n",
      "Epoch 29/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1420 - acc: 0.9420\n",
      "Epoch 00029: saving model to nn/Horror/proc-weights-improvement-29-0.91.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.1420 - acc: 0.9420 - val_loss: 0.2496 - val_acc: 0.9057\n",
      "Epoch 30/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1445 - acc: 0.9435\n",
      "Epoch 00030: saving model to nn/Horror/proc-weights-improvement-30-0.91.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1445 - acc: 0.9429 - val_loss: 0.2394 - val_acc: 0.9126\n",
      "Epoch 31/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1352 - acc: 0.9453\n",
      "Epoch 00031: saving model to nn/Horror/proc-weights-improvement-31-0.91.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.1364 - acc: 0.9453 - val_loss: 0.2332 - val_acc: 0.9098\n",
      "Epoch 32/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1286 - acc: 0.9522\n",
      "Epoch 00032: saving model to nn/Horror/proc-weights-improvement-32-0.91.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.1293 - acc: 0.9518 - val_loss: 0.2270 - val_acc: 0.9140\n",
      "Epoch 33/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1230 - acc: 0.9519\n",
      "Epoch 00033: saving model to nn/Horror/proc-weights-improvement-33-0.91.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1226 - acc: 0.9521 - val_loss: 0.2300 - val_acc: 0.9057\n",
      "Epoch 34/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1236 - acc: 0.9522\n",
      "Epoch 00034: saving model to nn/Horror/proc-weights-improvement-34-0.91.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.1236 - acc: 0.9521 - val_loss: 0.2375 - val_acc: 0.9085\n",
      "Epoch 35/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1265 - acc: 0.9504\n",
      "Epoch 00035: saving model to nn/Horror/proc-weights-improvement-35-0.91.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1263 - acc: 0.9506 - val_loss: 0.2429 - val_acc: 0.9098\n",
      "Epoch 36/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1129 - acc: 0.9531\n",
      "Epoch 00036: saving model to nn/Horror/proc-weights-improvement-36-0.91.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1148 - acc: 0.9527 - val_loss: 0.2419 - val_acc: 0.9140\n",
      "Epoch 37/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1114 - acc: 0.9570\n",
      "Epoch 00037: saving model to nn/Horror/proc-weights-improvement-37-0.91.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1120 - acc: 0.9563 - val_loss: 0.2416 - val_acc: 0.9126\n",
      "Epoch 38/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1010 - acc: 0.9688\n",
      "Epoch 00038: saving model to nn/Horror/proc-weights-improvement-38-0.91.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.1007 - acc: 0.9688 - val_loss: 0.2630 - val_acc: 0.9126\n",
      "Epoch 39/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0907 - acc: 0.9627\n",
      "Epoch 00039: saving model to nn/Horror/proc-weights-improvement-39-0.90.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.0906 - acc: 0.9625 - val_loss: 0.2735 - val_acc: 0.8974\n",
      "Epoch 40/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0840 - acc: 0.9694\n",
      "Epoch 00040: saving model to nn/Horror/proc-weights-improvement-40-0.91.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.0835 - acc: 0.9697 - val_loss: 0.3040 - val_acc: 0.9140\n",
      "Epoch 41/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0814 - acc: 0.9684\n",
      "Epoch 00041: saving model to nn/Horror/proc-weights-improvement-41-0.91.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.0823 - acc: 0.9676 - val_loss: 0.2683 - val_acc: 0.9085\n",
      "Epoch 42/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0782 - acc: 0.9691\n",
      "Epoch 00042: saving model to nn/Horror/proc-weights-improvement-42-0.91.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.0778 - acc: 0.9694 - val_loss: 0.2519 - val_acc: 0.9112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0706 - acc: 0.9736\n",
      "Epoch 00043: saving model to nn/Horror/proc-weights-improvement-43-0.91.hdf5\n",
      "3362/3362 [==============================] - 9s 3ms/step - loss: 0.0704 - acc: 0.9738 - val_loss: 0.3002 - val_acc: 0.9057\n",
      "Epoch 44/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9766\n",
      "Epoch 00044: saving model to nn/Horror/proc-weights-improvement-44-0.91.hdf5\n",
      "3362/3362 [==============================] - 8s 2ms/step - loss: 0.0591 - acc: 0.9768 - val_loss: 0.2898 - val_acc: 0.9112\n",
      "Epoch 45/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0656 - acc: 0.9769\n",
      "Epoch 00045: saving model to nn/Horror/proc-weights-improvement-45-0.92.hdf5\n",
      "3362/3362 [==============================] - 8s 2ms/step - loss: 0.0652 - acc: 0.9771 - val_loss: 0.3174 - val_acc: 0.9209\n",
      "Epoch 46/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0688 - acc: 0.9754\n",
      "Epoch 00046: saving model to nn/Horror/proc-weights-improvement-46-0.92.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.0682 - acc: 0.9756 - val_loss: 0.2670 - val_acc: 0.9182\n",
      "Epoch 47/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0483 - acc: 0.9817\n",
      "Epoch 00047: saving model to nn/Horror/proc-weights-improvement-47-0.91.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.0481 - acc: 0.9819 - val_loss: 0.3109 - val_acc: 0.9071\n",
      "Epoch 48/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0467 - acc: 0.9862\n",
      "Epoch 00048: saving model to nn/Horror/proc-weights-improvement-48-0.92.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.0473 - acc: 0.9860 - val_loss: 0.3043 - val_acc: 0.9223\n",
      "Epoch 49/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9826\n",
      "Epoch 00049: saving model to nn/Horror/proc-weights-improvement-49-0.91.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.0565 - acc: 0.9827 - val_loss: 0.2903 - val_acc: 0.9071\n",
      "Epoch 50/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9859\n",
      "Epoch 00050: saving model to nn/Horror/proc-weights-improvement-50-0.91.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.0397 - acc: 0.9860 - val_loss: 0.3552 - val_acc: 0.9085\n",
      "Mystery\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 200, 100)          2410000   \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 200, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,527,377\n",
      "Trainable params: 117,377\n",
      "Non-trainable params: 2,410,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 3362 samples, validate on 721 samples\n",
      "Epoch 1/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3750 - acc: 0.8807\n",
      "Epoch 00001: saving model to nn/Mystery/proc-weights-improvement-01-0.94.hdf5\n",
      "3362/3362 [==============================] - 8s 2ms/step - loss: 0.3736 - acc: 0.8813 - val_loss: 0.2319 - val_acc: 0.9417\n",
      "Epoch 2/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2762 - acc: 0.9222\n",
      "Epoch 00002: saving model to nn/Mystery/proc-weights-improvement-02-0.94.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.2785 - acc: 0.9212 - val_loss: 0.2341 - val_acc: 0.9417\n",
      "Epoch 3/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2759 - acc: 0.9216\n",
      "Epoch 00003: saving model to nn/Mystery/proc-weights-improvement-03-0.94.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.2760 - acc: 0.9215 - val_loss: 0.2240 - val_acc: 0.9417\n",
      "Epoch 4/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2650 - acc: 0.9222\n",
      "Epoch 00004: saving model to nn/Mystery/proc-weights-improvement-04-0.94.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2677 - acc: 0.9212 - val_loss: 0.2224 - val_acc: 0.9417\n",
      "Epoch 5/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2663 - acc: 0.9222\n",
      "Epoch 00005: saving model to nn/Mystery/proc-weights-improvement-05-0.94.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2678 - acc: 0.9215 - val_loss: 0.2245 - val_acc: 0.9417\n",
      "Epoch 6/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2585 - acc: 0.9228\n",
      "Epoch 00006: saving model to nn/Mystery/proc-weights-improvement-06-0.94.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.2613 - acc: 0.9215 - val_loss: 0.2201 - val_acc: 0.9417\n",
      "Epoch 7/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2583 - acc: 0.9216\n",
      "Epoch 00007: saving model to nn/Mystery/proc-weights-improvement-07-0.94.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2586 - acc: 0.9215 - val_loss: 0.2189 - val_acc: 0.9417\n",
      "Epoch 8/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2539 - acc: 0.9207\n",
      "Epoch 00008: saving model to nn/Mystery/proc-weights-improvement-08-0.94.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.2523 - acc: 0.9215 - val_loss: 0.2093 - val_acc: 0.9417\n",
      "Epoch 9/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2488 - acc: 0.9213\n",
      "Epoch 00009: saving model to nn/Mystery/proc-weights-improvement-09-0.94.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2486 - acc: 0.9215 - val_loss: 0.2384 - val_acc: 0.9417\n",
      "Epoch 10/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2452 - acc: 0.9219\n",
      "Epoch 00010: saving model to nn/Mystery/proc-weights-improvement-10-0.94.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2465 - acc: 0.9212 - val_loss: 0.2255 - val_acc: 0.9417\n",
      "Epoch 11/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2403 - acc: 0.9216\n",
      "Epoch 00011: saving model to nn/Mystery/proc-weights-improvement-11-0.94.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2401 - acc: 0.9218 - val_loss: 0.2187 - val_acc: 0.9390\n",
      "Epoch 12/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2293 - acc: 0.9204\n",
      "Epoch 00012: saving model to nn/Mystery/proc-weights-improvement-12-0.94.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2279 - acc: 0.9212 - val_loss: 0.2076 - val_acc: 0.9404\n",
      "Epoch 13/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2339 - acc: 0.9213\n",
      "Epoch 00013: saving model to nn/Mystery/proc-weights-improvement-13-0.94.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2334 - acc: 0.9215 - val_loss: 0.2151 - val_acc: 0.9417\n",
      "Epoch 14/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2349 - acc: 0.9219\n",
      "Epoch 00014: saving model to nn/Mystery/proc-weights-improvement-14-0.94.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2343 - acc: 0.9221 - val_loss: 0.2002 - val_acc: 0.9417\n",
      "Epoch 15/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2198 - acc: 0.9231\n",
      "Epoch 00015: saving model to nn/Mystery/proc-weights-improvement-15-0.94.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2186 - acc: 0.9233 - val_loss: 0.2007 - val_acc: 0.9390\n",
      "Epoch 16/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2152 - acc: 0.9210\n",
      "Epoch 00016: saving model to nn/Mystery/proc-weights-improvement-16-0.94.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2143 - acc: 0.9215 - val_loss: 0.1987 - val_acc: 0.9390\n",
      "Epoch 17/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2131 - acc: 0.9225\n",
      "Epoch 00017: saving model to nn/Mystery/proc-weights-improvement-17-0.94.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2116 - acc: 0.9233 - val_loss: 0.1984 - val_acc: 0.9417\n",
      "Epoch 18/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2069 - acc: 0.9243\n",
      "Epoch 00018: saving model to nn/Mystery/proc-weights-improvement-18-0.94.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.2065 - acc: 0.9239 - val_loss: 0.1960 - val_acc: 0.9390\n",
      "Epoch 19/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2112 - acc: 0.9243\n",
      "Epoch 00019: saving model to nn/Mystery/proc-weights-improvement-19-0.94.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2107 - acc: 0.9242 - val_loss: 0.1980 - val_acc: 0.9404\n",
      "Epoch 20/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2023 - acc: 0.9243\n",
      "Epoch 00020: saving model to nn/Mystery/proc-weights-improvement-20-0.94.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.2031 - acc: 0.9239 - val_loss: 0.1962 - val_acc: 0.9390\n",
      "Epoch 21/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1982 - acc: 0.9282\n",
      "Epoch 00021: saving model to nn/Mystery/proc-weights-improvement-21-0.93.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1999 - acc: 0.9277 - val_loss: 0.2050 - val_acc: 0.9320\n",
      "Epoch 22/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1995 - acc: 0.9276\n",
      "Epoch 00022: saving model to nn/Mystery/proc-weights-improvement-22-0.92.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1998 - acc: 0.9280 - val_loss: 0.2465 - val_acc: 0.9237\n",
      "Epoch 23/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2031 - acc: 0.9249\n",
      "Epoch 00023: saving model to nn/Mystery/proc-weights-improvement-23-0.94.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2036 - acc: 0.9247 - val_loss: 0.2070 - val_acc: 0.9376\n",
      "Epoch 24/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1928 - acc: 0.9261\n",
      "Epoch 00024: saving model to nn/Mystery/proc-weights-improvement-24-0.93.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.1925 - acc: 0.9265 - val_loss: 0.2089 - val_acc: 0.9251\n",
      "Epoch 25/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1904 - acc: 0.9273\n",
      "Epoch 00025: saving model to nn/Mystery/proc-weights-improvement-25-0.93.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.1897 - acc: 0.9280 - val_loss: 0.2048 - val_acc: 0.9334\n",
      "Epoch 26/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1860 - acc: 0.9273\n",
      "Epoch 00026: saving model to nn/Mystery/proc-weights-improvement-26-0.93.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1854 - acc: 0.9274 - val_loss: 0.2053 - val_acc: 0.9320\n",
      "Epoch 27/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1815 - acc: 0.9279\n",
      "Epoch 00027: saving model to nn/Mystery/proc-weights-improvement-27-0.93.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1816 - acc: 0.9274 - val_loss: 0.2005 - val_acc: 0.9307\n",
      "Epoch 28/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1756 - acc: 0.9321\n",
      "Epoch 00028: saving model to nn/Mystery/proc-weights-improvement-28-0.93.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.1764 - acc: 0.9316 - val_loss: 0.2088 - val_acc: 0.9265\n",
      "Epoch 29/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1735 - acc: 0.9345\n",
      "Epoch 00029: saving model to nn/Mystery/proc-weights-improvement-29-0.91.hdf5\n",
      "3362/3362 [==============================] - 9s 3ms/step - loss: 0.1735 - acc: 0.9343 - val_loss: 0.2184 - val_acc: 0.9140\n",
      "Epoch 30/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1659 - acc: 0.9366\n",
      "Epoch 00030: saving model to nn/Mystery/proc-weights-improvement-30-0.92.hdf5\n",
      "3362/3362 [==============================] - 9s 3ms/step - loss: 0.1661 - acc: 0.9358 - val_loss: 0.2098 - val_acc: 0.9223\n",
      "Epoch 31/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1529 - acc: 0.9408\n",
      "Epoch 00031: saving model to nn/Mystery/proc-weights-improvement-31-0.92.hdf5\n",
      "3362/3362 [==============================] - 8s 2ms/step - loss: 0.1523 - acc: 0.9411 - val_loss: 0.2232 - val_acc: 0.9154\n",
      "Others\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 200, 100)          2410000   \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 200, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,527,377\n",
      "Trainable params: 117,377\n",
      "Non-trainable params: 2,410,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 3362 samples, validate on 721 samples\n",
      "Epoch 1/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.5084 - acc: 0.7960\n",
      "Epoch 00001: saving model to nn/Others/proc-weights-improvement-01-0.80.hdf5\n",
      "3362/3362 [==============================] - 10s 3ms/step - loss: 0.5083 - acc: 0.7960 - val_loss: 0.5003 - val_acc: 0.7989\n",
      "Epoch 2/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4691 - acc: 0.8182\n",
      "Epoch 00002: saving model to nn/Others/proc-weights-improvement-02-0.80.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.4680 - acc: 0.8186 - val_loss: 0.5000 - val_acc: 0.7989\n",
      "Epoch 3/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4568 - acc: 0.8197\n",
      "Epoch 00003: saving model to nn/Others/proc-weights-improvement-03-0.80.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.4578 - acc: 0.8189 - val_loss: 0.4952 - val_acc: 0.7989\n",
      "Epoch 4/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4511 - acc: 0.8197\n",
      "Epoch 00004: saving model to nn/Others/proc-weights-improvement-04-0.80.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.4503 - acc: 0.8200 - val_loss: 0.4963 - val_acc: 0.7989\n",
      "Epoch 5/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4398 - acc: 0.8227\n",
      "Epoch 00005: saving model to nn/Others/proc-weights-improvement-05-0.79.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.4397 - acc: 0.8224 - val_loss: 0.4891 - val_acc: 0.7933\n",
      "Epoch 6/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4260 - acc: 0.8275\n",
      "Epoch 00006: saving model to nn/Others/proc-weights-improvement-06-0.80.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.4249 - acc: 0.8281 - val_loss: 0.4638 - val_acc: 0.7975\n",
      "Epoch 7/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4073 - acc: 0.8242\n",
      "Epoch 00007: saving model to nn/Others/proc-weights-improvement-07-0.81.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.4061 - acc: 0.8245 - val_loss: 0.4737 - val_acc: 0.8072\n",
      "Epoch 8/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3863 - acc: 0.8332\n",
      "Epoch 00008: saving model to nn/Others/proc-weights-improvement-08-0.79.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.3912 - acc: 0.8311 - val_loss: 0.4631 - val_acc: 0.7864\n",
      "Epoch 9/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4157 - acc: 0.8248\n",
      "Epoch 00009: saving model to nn/Others/proc-weights-improvement-09-0.80.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.4152 - acc: 0.8251 - val_loss: 0.4571 - val_acc: 0.8031\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3912 - acc: 0.8326\n",
      "Epoch 00010: saving model to nn/Others/proc-weights-improvement-10-0.79.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.3902 - acc: 0.8331 - val_loss: 0.4519 - val_acc: 0.7933\n",
      "Epoch 11/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3947 - acc: 0.8302\n",
      "Epoch 00011: saving model to nn/Others/proc-weights-improvement-11-0.81.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.3932 - acc: 0.8314 - val_loss: 0.4434 - val_acc: 0.8086\n",
      "Epoch 12/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3707 - acc: 0.8344\n",
      "Epoch 00012: saving model to nn/Others/proc-weights-improvement-12-0.80.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.3708 - acc: 0.8337 - val_loss: 0.4543 - val_acc: 0.7989\n",
      "Epoch 13/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3875 - acc: 0.8383\n",
      "Epoch 00013: saving model to nn/Others/proc-weights-improvement-13-0.80.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.3869 - acc: 0.8385 - val_loss: 0.4496 - val_acc: 0.8031\n",
      "Epoch 14/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3709 - acc: 0.8407\n",
      "Epoch 00014: saving model to nn/Others/proc-weights-improvement-14-0.82.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.3703 - acc: 0.8412 - val_loss: 0.4316 - val_acc: 0.8225\n",
      "Epoch 15/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3676 - acc: 0.8392\n",
      "Epoch 00015: saving model to nn/Others/proc-weights-improvement-15-0.81.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.3677 - acc: 0.8394 - val_loss: 0.4388 - val_acc: 0.8114\n",
      "Epoch 16/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3569 - acc: 0.8444\n",
      "Epoch 00016: saving model to nn/Others/proc-weights-improvement-16-0.83.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.3567 - acc: 0.8444 - val_loss: 0.4361 - val_acc: 0.8252\n",
      "Epoch 17/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3574 - acc: 0.8504\n",
      "Epoch 00017: saving model to nn/Others/proc-weights-improvement-17-0.82.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.3557 - acc: 0.8513 - val_loss: 0.4399 - val_acc: 0.8211\n",
      "Epoch 18/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3406 - acc: 0.8489\n",
      "Epoch 00018: saving model to nn/Others/proc-weights-improvement-18-0.82.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.3403 - acc: 0.8489 - val_loss: 0.4315 - val_acc: 0.8225\n",
      "Epoch 19/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3318 - acc: 0.8588\n",
      "Epoch 00019: saving model to nn/Others/proc-weights-improvement-19-0.82.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.3327 - acc: 0.8584 - val_loss: 0.4323 - val_acc: 0.8169\n",
      "Epoch 20/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3451 - acc: 0.8561\n",
      "Epoch 00020: saving model to nn/Others/proc-weights-improvement-20-0.83.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.3455 - acc: 0.8557 - val_loss: 0.4368 - val_acc: 0.8322\n",
      "Epoch 21/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3222 - acc: 0.8594\n",
      "Epoch 00021: saving model to nn/Others/proc-weights-improvement-21-0.83.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.3218 - acc: 0.8596 - val_loss: 0.4388 - val_acc: 0.8322\n",
      "Epoch 22/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3159 - acc: 0.8669\n",
      "Epoch 00022: saving model to nn/Others/proc-weights-improvement-22-0.84.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.3153 - acc: 0.8673 - val_loss: 0.4355 - val_acc: 0.8363\n",
      "Epoch 23/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3241 - acc: 0.8657\n",
      "Epoch 00023: saving model to nn/Others/proc-weights-improvement-23-0.83.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.3225 - acc: 0.8664 - val_loss: 0.4408 - val_acc: 0.8336\n",
      "Epoch 24/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3138 - acc: 0.8678\n",
      "Epoch 00024: saving model to nn/Others/proc-weights-improvement-24-0.83.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.3138 - acc: 0.8673 - val_loss: 0.4646 - val_acc: 0.8322\n",
      "Epoch 25/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3035 - acc: 0.8714\n",
      "Epoch 00025: saving model to nn/Others/proc-weights-improvement-25-0.82.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.3044 - acc: 0.8700 - val_loss: 0.4293 - val_acc: 0.8211\n",
      "Epoch 26/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2984 - acc: 0.8735\n",
      "Epoch 00026: saving model to nn/Others/proc-weights-improvement-26-0.82.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2990 - acc: 0.8736 - val_loss: 0.4487 - val_acc: 0.8169\n",
      "Epoch 27/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2911 - acc: 0.8693\n",
      "Epoch 00027: saving model to nn/Others/proc-weights-improvement-27-0.81.hdf5\n",
      "3362/3362 [==============================] - 8s 2ms/step - loss: 0.2908 - acc: 0.8694 - val_loss: 0.4535 - val_acc: 0.8072\n",
      "Epoch 28/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2782 - acc: 0.8813\n",
      "Epoch 00028: saving model to nn/Others/proc-weights-improvement-28-0.82.hdf5\n",
      "3362/3362 [==============================] - 8s 2ms/step - loss: 0.2785 - acc: 0.8813 - val_loss: 0.4587 - val_acc: 0.8239\n",
      "Epoch 29/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2649 - acc: 0.8861\n",
      "Epoch 00029: saving model to nn/Others/proc-weights-improvement-29-0.77.hdf5\n",
      "3362/3362 [==============================] - 8s 2ms/step - loss: 0.2653 - acc: 0.8864 - val_loss: 0.5449 - val_acc: 0.7739\n",
      "Epoch 30/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2801 - acc: 0.8822\n",
      "Epoch 00030: saving model to nn/Others/proc-weights-improvement-30-0.83.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.2792 - acc: 0.8828 - val_loss: 0.4932 - val_acc: 0.8266\n",
      "Epoch 31/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2909 - acc: 0.8795\n",
      "Epoch 00031: saving model to nn/Others/proc-weights-improvement-31-0.82.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2910 - acc: 0.8789 - val_loss: 0.4951 - val_acc: 0.8169\n",
      "Epoch 32/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2593 - acc: 0.8921\n",
      "Epoch 00032: saving model to nn/Others/proc-weights-improvement-32-0.82.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2585 - acc: 0.8923 - val_loss: 0.5029 - val_acc: 0.8211\n",
      "Epoch 33/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2458 - acc: 0.9029\n",
      "Epoch 00033: saving model to nn/Others/proc-weights-improvement-33-0.80.hdf5\n",
      "3362/3362 [==============================] - 8s 2ms/step - loss: 0.2447 - acc: 0.9033 - val_loss: 0.5074 - val_acc: 0.8044\n",
      "Epoch 34/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2319 - acc: 0.9014\n",
      "Epoch 00034: saving model to nn/Others/proc-weights-improvement-34-0.80.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2317 - acc: 0.9015 - val_loss: 0.5141 - val_acc: 0.8017\n",
      "Epoch 35/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2196 - acc: 0.9105\n",
      "Epoch 00035: saving model to nn/Others/proc-weights-improvement-35-0.82.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2194 - acc: 0.9102 - val_loss: 0.5186 - val_acc: 0.8197\n",
      "Epoch 36/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2057 - acc: 0.9129\n",
      "Epoch 00036: saving model to nn/Others/proc-weights-improvement-36-0.82.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2060 - acc: 0.9126 - val_loss: 0.5143 - val_acc: 0.8211\n",
      "Epoch 37/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2150 - acc: 0.9144\n",
      "Epoch 00037: saving model to nn/Others/proc-weights-improvement-37-0.82.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.2157 - acc: 0.9137 - val_loss: 0.5032 - val_acc: 0.8225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1970 - acc: 0.9174\n",
      "Epoch 00038: saving model to nn/Others/proc-weights-improvement-38-0.80.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.1984 - acc: 0.9167 - val_loss: 0.5649 - val_acc: 0.8044\n",
      "Epoch 39/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1854 - acc: 0.9258\n",
      "Epoch 00039: saving model to nn/Others/proc-weights-improvement-39-0.82.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.1857 - acc: 0.9259 - val_loss: 0.5282 - val_acc: 0.8183\n",
      "Epoch 40/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1986 - acc: 0.9177\n",
      "Epoch 00040: saving model to nn/Others/proc-weights-improvement-40-0.81.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1982 - acc: 0.9179 - val_loss: 0.5152 - val_acc: 0.8072\n",
      "Epoch 41/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1762 - acc: 0.9321\n",
      "Epoch 00041: saving model to nn/Others/proc-weights-improvement-41-0.83.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1765 - acc: 0.9316 - val_loss: 0.6026 - val_acc: 0.8266\n",
      "Epoch 42/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1626 - acc: 0.9369\n",
      "Epoch 00042: saving model to nn/Others/proc-weights-improvement-42-0.81.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1621 - acc: 0.9372 - val_loss: 0.5462 - val_acc: 0.8141\n",
      "Epoch 43/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1417 - acc: 0.9438\n",
      "Epoch 00043: saving model to nn/Others/proc-weights-improvement-43-0.82.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1412 - acc: 0.9444 - val_loss: 0.6280 - val_acc: 0.8197\n",
      "Epoch 44/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1214 - acc: 0.9591\n",
      "Epoch 00044: saving model to nn/Others/proc-weights-improvement-44-0.82.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1211 - acc: 0.9593 - val_loss: 0.6801 - val_acc: 0.8197\n",
      "Epoch 45/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1206 - acc: 0.9537\n",
      "Epoch 00045: saving model to nn/Others/proc-weights-improvement-45-0.79.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1216 - acc: 0.9527 - val_loss: 0.6613 - val_acc: 0.7864\n",
      "Epoch 46/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1157 - acc: 0.9531\n",
      "Epoch 00046: saving model to nn/Others/proc-weights-improvement-46-0.78.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1158 - acc: 0.9527 - val_loss: 0.6459 - val_acc: 0.7822\n",
      "Epoch 47/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1272 - acc: 0.9546\n",
      "Epoch 00047: saving model to nn/Others/proc-weights-improvement-47-0.83.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.1272 - acc: 0.9542 - val_loss: 0.6791 - val_acc: 0.8350\n",
      "Epoch 48/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1126 - acc: 0.9573\n",
      "Epoch 00048: saving model to nn/Others/proc-weights-improvement-48-0.79.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1119 - acc: 0.9578 - val_loss: 0.7255 - val_acc: 0.7906\n",
      "Epoch 49/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1035 - acc: 0.9630\n",
      "Epoch 00049: saving model to nn/Others/proc-weights-improvement-49-0.82.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1029 - acc: 0.9631 - val_loss: 0.7518 - val_acc: 0.8225\n",
      "Epoch 50/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0869 - acc: 0.9712\n",
      "Epoch 00050: saving model to nn/Others/proc-weights-improvement-50-0.81.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.0869 - acc: 0.9711 - val_loss: 0.7036 - val_acc: 0.8114\n",
      "Romance\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, 200, 100)          2410000   \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 200, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,527,377\n",
      "Trainable params: 117,377\n",
      "Non-trainable params: 2,410,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 3362 samples, validate on 721 samples\n",
      "Epoch 1/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.5111 - acc: 0.7993\n",
      "Epoch 00001: saving model to nn/Romance/proc-weights-improvement-01-0.82.hdf5\n",
      "3362/3362 [==============================] - 12s 3ms/step - loss: 0.5104 - acc: 0.7995 - val_loss: 0.4653 - val_acc: 0.8169\n",
      "Epoch 2/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4668 - acc: 0.8119\n",
      "Epoch 00002: saving model to nn/Romance/proc-weights-improvement-02-0.82.hdf5\n",
      "3362/3362 [==============================] - 8s 2ms/step - loss: 0.4669 - acc: 0.8120 - val_loss: 0.4464 - val_acc: 0.8169\n",
      "Epoch 3/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4413 - acc: 0.8143\n",
      "Epoch 00003: saving model to nn/Romance/proc-weights-improvement-03-0.82.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.4401 - acc: 0.8156 - val_loss: 0.4004 - val_acc: 0.8169\n",
      "Epoch 4/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4512 - acc: 0.8098\n",
      "Epoch 00004: saving model to nn/Romance/proc-weights-improvement-04-0.82.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.4530 - acc: 0.8087 - val_loss: 0.4169 - val_acc: 0.8169\n",
      "Epoch 5/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4403 - acc: 0.8131\n",
      "Epoch 00005: saving model to nn/Romance/proc-weights-improvement-05-0.82.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.4394 - acc: 0.8135 - val_loss: 0.4070 - val_acc: 0.8169\n",
      "Epoch 6/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4168 - acc: 0.8143\n",
      "Epoch 00006: saving model to nn/Romance/proc-weights-improvement-06-0.82.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.4177 - acc: 0.8132 - val_loss: 0.4032 - val_acc: 0.8225\n",
      "Epoch 7/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4015 - acc: 0.8236\n",
      "Epoch 00007: saving model to nn/Romance/proc-weights-improvement-07-0.83.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.4018 - acc: 0.8242 - val_loss: 0.3886 - val_acc: 0.8322\n",
      "Epoch 8/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3872 - acc: 0.8314\n",
      "Epoch 00008: saving model to nn/Romance/proc-weights-improvement-08-0.82.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.3871 - acc: 0.8314 - val_loss: 0.3728 - val_acc: 0.8225\n",
      "Epoch 9/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3829 - acc: 0.8269\n",
      "Epoch 00009: saving model to nn/Romance/proc-weights-improvement-09-0.83.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.3824 - acc: 0.8278 - val_loss: 0.3683 - val_acc: 0.8280\n",
      "Epoch 10/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3656 - acc: 0.8386\n",
      "Epoch 00010: saving model to nn/Romance/proc-weights-improvement-10-0.83.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.3669 - acc: 0.8382 - val_loss: 0.3667 - val_acc: 0.8322\n",
      "Epoch 11/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3571 - acc: 0.8438\n",
      "Epoch 00011: saving model to nn/Romance/proc-weights-improvement-11-0.83.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.3578 - acc: 0.8432 - val_loss: 0.3783 - val_acc: 0.8294\n",
      "Epoch 12/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3673 - acc: 0.8434\n",
      "Epoch 00012: saving model to nn/Romance/proc-weights-improvement-12-0.82.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.3654 - acc: 0.8441 - val_loss: 0.3874 - val_acc: 0.8197\n",
      "Epoch 13/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3590 - acc: 0.8401\n",
      "Epoch 00013: saving model to nn/Romance/proc-weights-improvement-13-0.83.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.3586 - acc: 0.8403 - val_loss: 0.3893 - val_acc: 0.8280\n",
      "Epoch 14/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3547 - acc: 0.8425\n",
      "Epoch 00014: saving model to nn/Romance/proc-weights-improvement-14-0.83.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.3551 - acc: 0.8421 - val_loss: 0.3672 - val_acc: 0.8322\n",
      "Epoch 15/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3498 - acc: 0.8501\n",
      "Epoch 00015: saving model to nn/Romance/proc-weights-improvement-15-0.83.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.3490 - acc: 0.8504 - val_loss: 0.3654 - val_acc: 0.8350\n",
      "Epoch 16/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3484 - acc: 0.8462\n",
      "Epoch 00016: saving model to nn/Romance/proc-weights-improvement-16-0.84.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.3470 - acc: 0.8468 - val_loss: 0.3641 - val_acc: 0.8405\n",
      "Epoch 17/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3413 - acc: 0.8468\n",
      "Epoch 00017: saving model to nn/Romance/proc-weights-improvement-17-0.84.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.3405 - acc: 0.8468 - val_loss: 0.3680 - val_acc: 0.8377\n",
      "Epoch 18/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3335 - acc: 0.8540\n",
      "Epoch 00018: saving model to nn/Romance/proc-weights-improvement-18-0.83.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.3331 - acc: 0.8543 - val_loss: 0.3674 - val_acc: 0.8294\n",
      "Epoch 19/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3299 - acc: 0.8564\n",
      "Epoch 00019: saving model to nn/Romance/proc-weights-improvement-19-0.84.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.3285 - acc: 0.8572 - val_loss: 0.3556 - val_acc: 0.8419\n",
      "Epoch 20/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3264 - acc: 0.8606\n",
      "Epoch 00020: saving model to nn/Romance/proc-weights-improvement-20-0.84.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.3246 - acc: 0.8617 - val_loss: 0.3687 - val_acc: 0.8419\n",
      "Epoch 21/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3207 - acc: 0.8579\n",
      "Epoch 00021: saving model to nn/Romance/proc-weights-improvement-21-0.84.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.3195 - acc: 0.8584 - val_loss: 0.3868 - val_acc: 0.8419\n",
      "Epoch 22/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3172 - acc: 0.8624\n",
      "Epoch 00022: saving model to nn/Romance/proc-weights-improvement-22-0.83.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.3164 - acc: 0.8629 - val_loss: 0.3805 - val_acc: 0.8266\n",
      "Epoch 23/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3047 - acc: 0.8729\n",
      "Epoch 00023: saving model to nn/Romance/proc-weights-improvement-23-0.83.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.3038 - acc: 0.8739 - val_loss: 0.3783 - val_acc: 0.8280\n",
      "Epoch 24/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2992 - acc: 0.8681\n",
      "Epoch 00024: saving model to nn/Romance/proc-weights-improvement-24-0.76.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2997 - acc: 0.8685 - val_loss: 0.4529 - val_acc: 0.7573\n",
      "Epoch 25/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3207 - acc: 0.8627\n",
      "Epoch 00025: saving model to nn/Romance/proc-weights-improvement-25-0.83.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.3203 - acc: 0.8629 - val_loss: 0.3728 - val_acc: 0.8322\n",
      "Epoch 26/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2863 - acc: 0.8723\n",
      "Epoch 00026: saving model to nn/Romance/proc-weights-improvement-26-0.83.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.2875 - acc: 0.8718 - val_loss: 0.3885 - val_acc: 0.8266\n",
      "Epoch 27/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2859 - acc: 0.8852\n",
      "Epoch 00027: saving model to nn/Romance/proc-weights-improvement-27-0.83.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2855 - acc: 0.8855 - val_loss: 0.3757 - val_acc: 0.8252\n",
      "Epoch 28/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2712 - acc: 0.8858\n",
      "Epoch 00028: saving model to nn/Romance/proc-weights-improvement-28-0.84.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.2713 - acc: 0.8852 - val_loss: 0.3803 - val_acc: 0.8405\n",
      "Epoch 29/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2657 - acc: 0.8912\n",
      "Epoch 00029: saving model to nn/Romance/proc-weights-improvement-29-0.82.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.2665 - acc: 0.8905 - val_loss: 0.3763 - val_acc: 0.8225\n",
      "Epoch 30/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2592 - acc: 0.8966\n",
      "Epoch 00030: saving model to nn/Romance/proc-weights-improvement-30-0.83.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.2585 - acc: 0.8968 - val_loss: 0.3855 - val_acc: 0.8252\n",
      "Epoch 31/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2673 - acc: 0.8876\n",
      "Epoch 00031: saving model to nn/Romance/proc-weights-improvement-31-0.82.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.2663 - acc: 0.8882 - val_loss: 0.3799 - val_acc: 0.8211\n",
      "Epoch 32/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2431 - acc: 0.9014\n",
      "Epoch 00032: saving model to nn/Romance/proc-weights-improvement-32-0.83.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.2452 - acc: 0.9004 - val_loss: 0.3959 - val_acc: 0.8266\n",
      "Epoch 33/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2466 - acc: 0.9035\n",
      "Epoch 00033: saving model to nn/Romance/proc-weights-improvement-33-0.83.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.2458 - acc: 0.9039 - val_loss: 0.3886 - val_acc: 0.8294\n",
      "Epoch 34/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2406 - acc: 0.9005\n",
      "Epoch 00034: saving model to nn/Romance/proc-weights-improvement-34-0.80.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.2402 - acc: 0.9010 - val_loss: 0.4326 - val_acc: 0.8044\n",
      "Epoch 35/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2349 - acc: 0.9029\n",
      "Epoch 00035: saving model to nn/Romance/proc-weights-improvement-35-0.82.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2344 - acc: 0.9027 - val_loss: 0.3954 - val_acc: 0.8225\n",
      "Epoch 36/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2214 - acc: 0.9078\n",
      "Epoch 00036: saving model to nn/Romance/proc-weights-improvement-36-0.83.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2207 - acc: 0.9081 - val_loss: 0.4186 - val_acc: 0.8280\n",
      "Epoch 37/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2097 - acc: 0.9168\n",
      "Epoch 00037: saving model to nn/Romance/proc-weights-improvement-37-0.81.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2103 - acc: 0.9161 - val_loss: 0.4335 - val_acc: 0.8086\n",
      "Epoch 38/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2096 - acc: 0.9180\n",
      "Epoch 00038: saving model to nn/Romance/proc-weights-improvement-38-0.83.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2114 - acc: 0.9173 - val_loss: 0.4149 - val_acc: 0.8252\n",
      "Epoch 39/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1945 - acc: 0.9216\n",
      "Epoch 00039: saving model to nn/Romance/proc-weights-improvement-39-0.83.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.1943 - acc: 0.9212 - val_loss: 0.4722 - val_acc: 0.8252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2011 - acc: 0.9195\n",
      "Epoch 00040: saving model to nn/Romance/proc-weights-improvement-40-0.83.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.2021 - acc: 0.9191 - val_loss: 0.4104 - val_acc: 0.8280\n",
      "Epoch 41/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1873 - acc: 0.9264\n",
      "Epoch 00041: saving model to nn/Romance/proc-weights-improvement-41-0.83.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.1864 - acc: 0.9268 - val_loss: 0.5023 - val_acc: 0.8294\n",
      "Epoch 42/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1682 - acc: 0.9378\n",
      "Epoch 00042: saving model to nn/Romance/proc-weights-improvement-42-0.82.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.1695 - acc: 0.9366 - val_loss: 0.4567 - val_acc: 0.8169\n",
      "Epoch 43/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1702 - acc: 0.9333\n",
      "Epoch 00043: saving model to nn/Romance/proc-weights-improvement-43-0.83.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.1702 - acc: 0.9334 - val_loss: 0.4683 - val_acc: 0.8294\n",
      "Epoch 44/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1488 - acc: 0.9420\n",
      "Epoch 00044: saving model to nn/Romance/proc-weights-improvement-44-0.83.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1494 - acc: 0.9420 - val_loss: 0.4847 - val_acc: 0.8294\n",
      "Epoch 45/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1532 - acc: 0.9423\n",
      "Epoch 00045: saving model to nn/Romance/proc-weights-improvement-45-0.83.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.1543 - acc: 0.9420 - val_loss: 0.4764 - val_acc: 0.8350\n",
      "Epoch 46/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1414 - acc: 0.9492\n",
      "Epoch 00046: saving model to nn/Romance/proc-weights-improvement-46-0.81.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1436 - acc: 0.9485 - val_loss: 0.4820 - val_acc: 0.8128\n",
      "Epoch 47/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1523 - acc: 0.9405\n",
      "Epoch 00047: saving model to nn/Romance/proc-weights-improvement-47-0.82.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1517 - acc: 0.9408 - val_loss: 0.4869 - val_acc: 0.8225\n",
      "Epoch 48/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1242 - acc: 0.9543\n",
      "Epoch 00048: saving model to nn/Romance/proc-weights-improvement-48-0.83.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1236 - acc: 0.9545 - val_loss: 0.4797 - val_acc: 0.8280\n",
      "Epoch 49/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1072 - acc: 0.9609\n",
      "Epoch 00049: saving model to nn/Romance/proc-weights-improvement-49-0.82.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.1064 - acc: 0.9613 - val_loss: 0.6012 - val_acc: 0.8239\n",
      "Science Fiction\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 200, 100)          2410000   \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 200, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,527,377\n",
      "Trainable params: 117,377\n",
      "Non-trainable params: 2,410,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 3362 samples, validate on 721 samples\n",
      "Epoch 1/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4127 - acc: 0.8732\n",
      "Epoch 00001: saving model to nn/Science Fiction/proc-weights-improvement-01-0.91.hdf5\n",
      "3362/3362 [==============================] - 11s 3ms/step - loss: 0.4119 - acc: 0.8733 - val_loss: 0.3077 - val_acc: 0.9071\n",
      "Epoch 2/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3505 - acc: 0.8819\n",
      "Epoch 00002: saving model to nn/Science Fiction/proc-weights-improvement-02-0.91.hdf5\n",
      "3362/3362 [==============================] - 8s 2ms/step - loss: 0.3515 - acc: 0.8813 - val_loss: 0.2998 - val_acc: 0.9071\n",
      "Epoch 3/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3378 - acc: 0.8810\n",
      "Epoch 00003: saving model to nn/Science Fiction/proc-weights-improvement-03-0.91.hdf5\n",
      "3362/3362 [==============================] - 8s 2ms/step - loss: 0.3368 - acc: 0.8816 - val_loss: 0.2917 - val_acc: 0.9057\n",
      "Epoch 4/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3230 - acc: 0.8825\n",
      "Epoch 00004: saving model to nn/Science Fiction/proc-weights-improvement-04-0.91.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.3228 - acc: 0.8825 - val_loss: 0.2669 - val_acc: 0.9085\n",
      "Epoch 5/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2885 - acc: 0.8894\n",
      "Epoch 00005: saving model to nn/Science Fiction/proc-weights-improvement-05-0.88.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2896 - acc: 0.8888 - val_loss: 0.2786 - val_acc: 0.8835\n",
      "Epoch 6/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2722 - acc: 0.8954\n",
      "Epoch 00006: saving model to nn/Science Fiction/proc-weights-improvement-06-0.91.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.2726 - acc: 0.8950 - val_loss: 0.2496 - val_acc: 0.9098\n",
      "Epoch 7/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2842 - acc: 0.9014\n",
      "Epoch 00007: saving model to nn/Science Fiction/proc-weights-improvement-07-0.91.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2825 - acc: 0.9021 - val_loss: 0.2430 - val_acc: 0.9098\n",
      "Epoch 8/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2584 - acc: 0.9038\n",
      "Epoch 00008: saving model to nn/Science Fiction/proc-weights-improvement-08-0.84.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2594 - acc: 0.9030 - val_loss: 0.3400 - val_acc: 0.8419\n",
      "Epoch 9/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2613 - acc: 0.8990\n",
      "Epoch 00009: saving model to nn/Science Fiction/proc-weights-improvement-09-0.91.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.2621 - acc: 0.8986 - val_loss: 0.2591 - val_acc: 0.9112\n",
      "Epoch 10/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2500 - acc: 0.9053\n",
      "Epoch 00010: saving model to nn/Science Fiction/proc-weights-improvement-10-0.92.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2499 - acc: 0.9054 - val_loss: 0.2329 - val_acc: 0.9196\n",
      "Epoch 11/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2378 - acc: 0.9090\n",
      "Epoch 00011: saving model to nn/Science Fiction/proc-weights-improvement-11-0.92.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.2368 - acc: 0.9096 - val_loss: 0.2289 - val_acc: 0.9168\n",
      "Epoch 12/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2321 - acc: 0.9174\n",
      "Epoch 00012: saving model to nn/Science Fiction/proc-weights-improvement-12-0.92.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.2323 - acc: 0.9173 - val_loss: 0.2400 - val_acc: 0.9182\n",
      "Epoch 13/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2300 - acc: 0.9171\n",
      "Epoch 00013: saving model to nn/Science Fiction/proc-weights-improvement-13-0.92.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2289 - acc: 0.9176 - val_loss: 0.2207 - val_acc: 0.9182\n",
      "Epoch 14/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2158 - acc: 0.9180\n",
      "Epoch 00014: saving model to nn/Science Fiction/proc-weights-improvement-14-0.92.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2162 - acc: 0.9182 - val_loss: 0.2209 - val_acc: 0.9154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2156 - acc: 0.9189\n",
      "Epoch 00015: saving model to nn/Science Fiction/proc-weights-improvement-15-0.89.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.2156 - acc: 0.9191 - val_loss: 0.2885 - val_acc: 0.8904\n",
      "Epoch 16/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2367 - acc: 0.9081\n",
      "Epoch 00016: saving model to nn/Science Fiction/proc-weights-improvement-16-0.92.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2379 - acc: 0.9072 - val_loss: 0.2236 - val_acc: 0.9182\n",
      "Epoch 17/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2201 - acc: 0.9201\n",
      "Epoch 00017: saving model to nn/Science Fiction/proc-weights-improvement-17-0.93.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.2198 - acc: 0.9200 - val_loss: 0.2072 - val_acc: 0.9279\n",
      "Epoch 18/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2013 - acc: 0.9264\n",
      "Epoch 00018: saving model to nn/Science Fiction/proc-weights-improvement-18-0.93.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.2007 - acc: 0.9265 - val_loss: 0.2053 - val_acc: 0.9279\n",
      "Epoch 19/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1929 - acc: 0.9273\n",
      "Epoch 00019: saving model to nn/Science Fiction/proc-weights-improvement-19-0.93.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.1927 - acc: 0.9274 - val_loss: 0.2076 - val_acc: 0.9293\n",
      "Epoch 20/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1924 - acc: 0.9291\n",
      "Epoch 00020: saving model to nn/Science Fiction/proc-weights-improvement-20-0.92.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1943 - acc: 0.9283 - val_loss: 0.2318 - val_acc: 0.9196\n",
      "Epoch 21/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1923 - acc: 0.9282\n",
      "Epoch 00021: saving model to nn/Science Fiction/proc-weights-improvement-21-0.93.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1914 - acc: 0.9286 - val_loss: 0.2140 - val_acc: 0.9265\n",
      "Epoch 22/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1877 - acc: 0.9285\n",
      "Epoch 00022: saving model to nn/Science Fiction/proc-weights-improvement-22-0.93.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1879 - acc: 0.9289 - val_loss: 0.2027 - val_acc: 0.9293\n",
      "Epoch 23/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1808 - acc: 0.9315\n",
      "Epoch 00023: saving model to nn/Science Fiction/proc-weights-improvement-23-0.93.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1809 - acc: 0.9316 - val_loss: 0.2050 - val_acc: 0.9279\n",
      "Epoch 24/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1813 - acc: 0.9327\n",
      "Epoch 00024: saving model to nn/Science Fiction/proc-weights-improvement-24-0.92.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.1820 - acc: 0.9325 - val_loss: 0.2054 - val_acc: 0.9237\n",
      "Epoch 25/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1728 - acc: 0.9363\n",
      "Epoch 00025: saving model to nn/Science Fiction/proc-weights-improvement-25-0.93.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.1730 - acc: 0.9360 - val_loss: 0.2054 - val_acc: 0.9293\n",
      "Epoch 26/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1713 - acc: 0.9363\n",
      "Epoch 00026: saving model to nn/Science Fiction/proc-weights-improvement-26-0.92.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.1722 - acc: 0.9360 - val_loss: 0.2070 - val_acc: 0.9209\n",
      "Epoch 27/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1687 - acc: 0.9393\n",
      "Epoch 00027: saving model to nn/Science Fiction/proc-weights-improvement-27-0.93.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.1690 - acc: 0.9390 - val_loss: 0.2094 - val_acc: 0.9279\n",
      "Epoch 28/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1598 - acc: 0.9399\n",
      "Epoch 00028: saving model to nn/Science Fiction/proc-weights-improvement-28-0.93.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.1592 - acc: 0.9399 - val_loss: 0.2272 - val_acc: 0.9251\n",
      "Epoch 29/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1566 - acc: 0.9429\n",
      "Epoch 00029: saving model to nn/Science Fiction/proc-weights-improvement-29-0.92.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.1561 - acc: 0.9432 - val_loss: 0.2238 - val_acc: 0.9168\n",
      "Epoch 30/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1464 - acc: 0.9423\n",
      "Epoch 00030: saving model to nn/Science Fiction/proc-weights-improvement-30-0.91.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1481 - acc: 0.9414 - val_loss: 0.2517 - val_acc: 0.9057\n",
      "Epoch 31/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1574 - acc: 0.9411\n",
      "Epoch 00031: saving model to nn/Science Fiction/proc-weights-improvement-31-0.93.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1569 - acc: 0.9411 - val_loss: 0.2435 - val_acc: 0.9293\n",
      "Epoch 32/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1617 - acc: 0.9387\n",
      "Epoch 00032: saving model to nn/Science Fiction/proc-weights-improvement-32-0.93.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.1606 - acc: 0.9393 - val_loss: 0.2227 - val_acc: 0.9279\n",
      "Epoch 33/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1371 - acc: 0.9459\n",
      "Epoch 00033: saving model to nn/Science Fiction/proc-weights-improvement-33-0.93.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1364 - acc: 0.9462 - val_loss: 0.2457 - val_acc: 0.9279\n",
      "Epoch 34/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1371 - acc: 0.9495\n",
      "Epoch 00034: saving model to nn/Science Fiction/proc-weights-improvement-34-0.92.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1368 - acc: 0.9497 - val_loss: 0.2319 - val_acc: 0.9196\n",
      "Epoch 35/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1276 - acc: 0.9531\n",
      "Epoch 00035: saving model to nn/Science Fiction/proc-weights-improvement-35-0.92.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.1269 - acc: 0.9533 - val_loss: 0.2291 - val_acc: 0.9223\n",
      "Epoch 36/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1270 - acc: 0.9552\n",
      "Epoch 00036: saving model to nn/Science Fiction/proc-weights-improvement-36-0.92.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1261 - acc: 0.9557 - val_loss: 0.2432 - val_acc: 0.9223\n",
      "Epoch 37/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1141 - acc: 0.9588\n",
      "Epoch 00037: saving model to nn/Science Fiction/proc-weights-improvement-37-0.93.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.1134 - acc: 0.9593 - val_loss: 0.2413 - val_acc: 0.9251\n",
      "Epoch 38/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1050 - acc: 0.9579\n",
      "Epoch 00038: saving model to nn/Science Fiction/proc-weights-improvement-38-0.92.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.1044 - acc: 0.9581 - val_loss: 0.2623 - val_acc: 0.9237\n",
      "Epoch 39/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1068 - acc: 0.9636\n",
      "Epoch 00039: saving model to nn/Science Fiction/proc-weights-improvement-39-0.93.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.1074 - acc: 0.9634 - val_loss: 0.2511 - val_acc: 0.9265\n",
      "Epoch 40/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1121 - acc: 0.9609\n",
      "Epoch 00040: saving model to nn/Science Fiction/proc-weights-improvement-40-0.92.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.1120 - acc: 0.9607 - val_loss: 0.2435 - val_acc: 0.9209\n",
      "Epoch 41/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1306 - acc: 0.9579\n",
      "Epoch 00041: saving model to nn/Science Fiction/proc-weights-improvement-41-0.92.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.1302 - acc: 0.9581 - val_loss: 0.2460 - val_acc: 0.9182\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1110 - acc: 0.9573\n",
      "Epoch 00042: saving model to nn/Science Fiction/proc-weights-improvement-42-0.92.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.1105 - acc: 0.9578 - val_loss: 0.2612 - val_acc: 0.9223\n",
      "Epoch 43/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1007 - acc: 0.9609\n",
      "Epoch 00043: saving model to nn/Science Fiction/proc-weights-improvement-43-0.92.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.1007 - acc: 0.9610 - val_loss: 0.2514 - val_acc: 0.9237\n",
      "Epoch 44/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0981 - acc: 0.9600\n",
      "Epoch 00044: saving model to nn/Science Fiction/proc-weights-improvement-44-0.93.hdf5\n",
      "3362/3362 [==============================] - 8s 2ms/step - loss: 0.0973 - acc: 0.9604 - val_loss: 0.2696 - val_acc: 0.9279\n",
      "Epoch 45/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0843 - acc: 0.9703\n",
      "Epoch 00045: saving model to nn/Science Fiction/proc-weights-improvement-45-0.92.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.0840 - acc: 0.9706 - val_loss: 0.2967 - val_acc: 0.9223\n",
      "Epoch 46/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0896 - acc: 0.9666\n",
      "Epoch 00046: saving model to nn/Science Fiction/proc-weights-improvement-46-0.92.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.0892 - acc: 0.9670 - val_loss: 0.2762 - val_acc: 0.9182\n",
      "Epoch 47/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0718 - acc: 0.9742\n",
      "Epoch 00047: saving model to nn/Science Fiction/proc-weights-improvement-47-0.93.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.0731 - acc: 0.9738 - val_loss: 0.3017 - val_acc: 0.9307\n",
      "Epoch 48/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0760 - acc: 0.9736\n",
      "Epoch 00048: saving model to nn/Science Fiction/proc-weights-improvement-48-0.91.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.0761 - acc: 0.9732 - val_loss: 0.2921 - val_acc: 0.9140\n",
      "Epoch 49/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0652 - acc: 0.9796\n",
      "Epoch 00049: saving model to nn/Science Fiction/proc-weights-improvement-49-0.91.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.0651 - acc: 0.9798 - val_loss: 0.3260 - val_acc: 0.9057\n",
      "Epoch 50/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.0711 - acc: 0.9748\n",
      "Epoch 00050: saving model to nn/Science Fiction/proc-weights-improvement-50-0.93.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.0708 - acc: 0.9747 - val_loss: 0.2849 - val_acc: 0.9279\n",
      "Thriller\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_14 (Embedding)     (None, 200, 100)          2410000   \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 200, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,527,377\n",
      "Trainable params: 117,377\n",
      "Non-trainable params: 2,410,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 3362 samples, validate on 721 samples\n",
      "Epoch 1/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.5962 - acc: 0.7263\n",
      "Epoch 00001: saving model to nn/Thriller/proc-weights-improvement-01-0.74.hdf5\n",
      "3362/3362 [==============================] - 10s 3ms/step - loss: 0.5953 - acc: 0.7272 - val_loss: 0.5656 - val_acc: 0.7434\n",
      "Epoch 2/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.5564 - acc: 0.7326\n",
      "Epoch 00002: saving model to nn/Thriller/proc-weights-improvement-02-0.74.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.5560 - acc: 0.7332 - val_loss: 0.5352 - val_acc: 0.7393\n",
      "Epoch 3/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.5083 - acc: 0.7518\n",
      "Epoch 00003: saving model to nn/Thriller/proc-weights-improvement-03-0.71.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.5076 - acc: 0.7522 - val_loss: 0.5494 - val_acc: 0.7087\n",
      "Epoch 4/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4883 - acc: 0.7602\n",
      "Epoch 00004: saving model to nn/Thriller/proc-weights-improvement-04-0.77.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.4876 - acc: 0.7609 - val_loss: 0.4603 - val_acc: 0.7712\n",
      "Epoch 5/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4691 - acc: 0.7692\n",
      "Epoch 00005: saving model to nn/Thriller/proc-weights-improvement-05-0.77.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.4698 - acc: 0.7686 - val_loss: 0.4719 - val_acc: 0.7656\n",
      "Epoch 6/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4614 - acc: 0.7710\n",
      "Epoch 00006: saving model to nn/Thriller/proc-weights-improvement-06-0.78.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.4619 - acc: 0.7710 - val_loss: 0.4533 - val_acc: 0.7767\n",
      "Epoch 7/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4646 - acc: 0.7722\n",
      "Epoch 00007: saving model to nn/Thriller/proc-weights-improvement-07-0.77.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.4660 - acc: 0.7716 - val_loss: 0.4505 - val_acc: 0.7725\n",
      "Epoch 8/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4408 - acc: 0.7897\n",
      "Epoch 00008: saving model to nn/Thriller/proc-weights-improvement-08-0.78.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.4413 - acc: 0.7900 - val_loss: 0.4413 - val_acc: 0.7836\n",
      "Epoch 9/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4383 - acc: 0.7855\n",
      "Epoch 00009: saving model to nn/Thriller/proc-weights-improvement-09-0.78.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.4400 - acc: 0.7849 - val_loss: 0.4422 - val_acc: 0.7822\n",
      "Epoch 10/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4372 - acc: 0.7800\n",
      "Epoch 00010: saving model to nn/Thriller/proc-weights-improvement-10-0.79.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.4371 - acc: 0.7808 - val_loss: 0.4365 - val_acc: 0.7892\n",
      "Epoch 11/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4337 - acc: 0.7945\n",
      "Epoch 00011: saving model to nn/Thriller/proc-weights-improvement-11-0.78.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.4344 - acc: 0.7945 - val_loss: 0.4466 - val_acc: 0.7767\n",
      "Epoch 12/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4338 - acc: 0.7864\n",
      "Epoch 00012: saving model to nn/Thriller/proc-weights-improvement-12-0.78.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.4325 - acc: 0.7870 - val_loss: 0.4378 - val_acc: 0.7836\n",
      "Epoch 13/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4201 - acc: 0.7999\n",
      "Epoch 00013: saving model to nn/Thriller/proc-weights-improvement-13-0.80.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.4196 - acc: 0.8001 - val_loss: 0.4322 - val_acc: 0.7975\n",
      "Epoch 14/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4127 - acc: 0.8011\n",
      "Epoch 00014: saving model to nn/Thriller/proc-weights-improvement-14-0.79.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.4137 - acc: 0.8001 - val_loss: 0.4339 - val_acc: 0.7892\n",
      "Epoch 15/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4126 - acc: 0.7978\n",
      "Epoch 00015: saving model to nn/Thriller/proc-weights-improvement-15-0.80.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.4115 - acc: 0.7986 - val_loss: 0.4283 - val_acc: 0.7975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4111 - acc: 0.8011\n",
      "Epoch 00016: saving model to nn/Thriller/proc-weights-improvement-16-0.79.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.4120 - acc: 0.8004 - val_loss: 0.4250 - val_acc: 0.7920\n",
      "Epoch 17/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4045 - acc: 0.8074\n",
      "Epoch 00017: saving model to nn/Thriller/proc-weights-improvement-17-0.76.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.4062 - acc: 0.8064 - val_loss: 0.4703 - val_acc: 0.7614\n",
      "Epoch 18/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.4425 - acc: 0.7822\n",
      "Epoch 00018: saving model to nn/Thriller/proc-weights-improvement-18-0.79.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.4423 - acc: 0.7817 - val_loss: 0.4295 - val_acc: 0.7947\n",
      "Epoch 19/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3970 - acc: 0.8110\n",
      "Epoch 00019: saving model to nn/Thriller/proc-weights-improvement-19-0.78.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.3969 - acc: 0.8111 - val_loss: 0.4312 - val_acc: 0.7836\n",
      "Epoch 20/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3911 - acc: 0.8125\n",
      "Epoch 00020: saving model to nn/Thriller/proc-weights-improvement-20-0.78.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.3915 - acc: 0.8120 - val_loss: 0.4275 - val_acc: 0.7822\n",
      "Epoch 21/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3848 - acc: 0.8179\n",
      "Epoch 00021: saving model to nn/Thriller/proc-weights-improvement-21-0.79.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.3862 - acc: 0.8174 - val_loss: 0.4461 - val_acc: 0.7892\n",
      "Epoch 22/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3730 - acc: 0.8239\n",
      "Epoch 00022: saving model to nn/Thriller/proc-weights-improvement-22-0.77.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.3745 - acc: 0.8233 - val_loss: 0.4494 - val_acc: 0.7656\n",
      "Epoch 23/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3777 - acc: 0.8227\n",
      "Epoch 00023: saving model to nn/Thriller/proc-weights-improvement-23-0.80.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.3766 - acc: 0.8230 - val_loss: 0.4319 - val_acc: 0.8003\n",
      "Epoch 24/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3671 - acc: 0.8263\n",
      "Epoch 00024: saving model to nn/Thriller/proc-weights-improvement-24-0.76.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.3673 - acc: 0.8263 - val_loss: 0.4589 - val_acc: 0.7587\n",
      "Epoch 25/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3538 - acc: 0.8419\n",
      "Epoch 00025: saving model to nn/Thriller/proc-weights-improvement-25-0.78.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.3539 - acc: 0.8424 - val_loss: 0.4503 - val_acc: 0.7767\n",
      "Epoch 26/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3770 - acc: 0.8236\n",
      "Epoch 00026: saving model to nn/Thriller/proc-weights-improvement-26-0.77.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.3776 - acc: 0.8239 - val_loss: 0.4549 - val_acc: 0.7670\n",
      "Epoch 27/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3602 - acc: 0.8383\n",
      "Epoch 00027: saving model to nn/Thriller/proc-weights-improvement-27-0.77.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.3604 - acc: 0.8382 - val_loss: 0.4469 - val_acc: 0.7670\n",
      "Epoch 28/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3343 - acc: 0.8453\n",
      "Epoch 00028: saving model to nn/Thriller/proc-weights-improvement-28-0.79.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.3341 - acc: 0.8453 - val_loss: 0.4703 - val_acc: 0.7864\n",
      "Epoch 29/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.3132 - acc: 0.8675\n",
      "Epoch 00029: saving model to nn/Thriller/proc-weights-improvement-29-0.78.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.3132 - acc: 0.8676 - val_loss: 0.4762 - val_acc: 0.7809\n",
      "Epoch 30/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2981 - acc: 0.8699\n",
      "Epoch 00030: saving model to nn/Thriller/proc-weights-improvement-30-0.78.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.2989 - acc: 0.8691 - val_loss: 0.4606 - val_acc: 0.7836\n",
      "Epoch 31/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2922 - acc: 0.8705\n",
      "Epoch 00031: saving model to nn/Thriller/proc-weights-improvement-31-0.77.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.2918 - acc: 0.8709 - val_loss: 0.4721 - val_acc: 0.7739\n",
      "Epoch 32/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2840 - acc: 0.8753\n",
      "Epoch 00032: saving model to nn/Thriller/proc-weights-improvement-32-0.78.hdf5\n",
      "3362/3362 [==============================] - 4s 1ms/step - loss: 0.2845 - acc: 0.8748 - val_loss: 0.5146 - val_acc: 0.7822\n",
      "Epoch 33/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2621 - acc: 0.8864\n",
      "Epoch 00033: saving model to nn/Thriller/proc-weights-improvement-33-0.76.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2621 - acc: 0.8864 - val_loss: 0.4968 - val_acc: 0.7642\n",
      "Epoch 34/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2578 - acc: 0.8894\n",
      "Epoch 00034: saving model to nn/Thriller/proc-weights-improvement-34-0.75.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.2579 - acc: 0.8899 - val_loss: 0.5149 - val_acc: 0.7490\n",
      "Epoch 35/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2399 - acc: 0.9041\n",
      "Epoch 00035: saving model to nn/Thriller/proc-weights-improvement-35-0.78.hdf5\n",
      "3362/3362 [==============================] - 8s 2ms/step - loss: 0.2398 - acc: 0.9039 - val_loss: 0.5061 - val_acc: 0.7781\n",
      "Epoch 36/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2321 - acc: 0.8990\n",
      "Epoch 00036: saving model to nn/Thriller/proc-weights-improvement-36-0.75.hdf5\n",
      "3362/3362 [==============================] - 8s 2ms/step - loss: 0.2314 - acc: 0.8995 - val_loss: 0.5582 - val_acc: 0.7476\n",
      "Epoch 37/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2090 - acc: 0.9111\n",
      "Epoch 00037: saving model to nn/Thriller/proc-weights-improvement-37-0.77.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.2090 - acc: 0.9108 - val_loss: 0.5432 - val_acc: 0.7739\n",
      "Epoch 38/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1920 - acc: 0.9204\n",
      "Epoch 00038: saving model to nn/Thriller/proc-weights-improvement-38-0.76.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.1933 - acc: 0.9197 - val_loss: 0.6183 - val_acc: 0.7628\n",
      "Epoch 39/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2030 - acc: 0.9168\n",
      "Epoch 00039: saving model to nn/Thriller/proc-weights-improvement-39-0.78.hdf5\n",
      "3362/3362 [==============================] - 7s 2ms/step - loss: 0.2037 - acc: 0.9161 - val_loss: 0.5360 - val_acc: 0.7795\n",
      "Epoch 40/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.2026 - acc: 0.9195\n",
      "Epoch 00040: saving model to nn/Thriller/proc-weights-improvement-40-0.78.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.2026 - acc: 0.9194 - val_loss: 0.5788 - val_acc: 0.7753\n",
      "Epoch 41/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1789 - acc: 0.9315\n",
      "Epoch 00041: saving model to nn/Thriller/proc-weights-improvement-41-0.77.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.1798 - acc: 0.9307 - val_loss: 0.5940 - val_acc: 0.7739\n",
      "Epoch 42/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1530 - acc: 0.9426\n",
      "Epoch 00042: saving model to nn/Thriller/proc-weights-improvement-42-0.77.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.1529 - acc: 0.9429 - val_loss: 0.6398 - val_acc: 0.7712\n",
      "Epoch 43/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1522 - acc: 0.9417\n",
      "Epoch 00043: saving model to nn/Thriller/proc-weights-improvement-43-0.79.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.1530 - acc: 0.9411 - val_loss: 0.6320 - val_acc: 0.7864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1731 - acc: 0.9357\n",
      "Epoch 00044: saving model to nn/Thriller/proc-weights-improvement-44-0.76.hdf5\n",
      "3362/3362 [==============================] - 6s 2ms/step - loss: 0.1735 - acc: 0.9355 - val_loss: 0.5899 - val_acc: 0.7559\n",
      "Epoch 45/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1465 - acc: 0.9408\n",
      "Epoch 00045: saving model to nn/Thriller/proc-weights-improvement-45-0.76.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.1459 - acc: 0.9408 - val_loss: 0.6762 - val_acc: 0.7614\n",
      "Epoch 46/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1239 - acc: 0.9549\n",
      "Epoch 00046: saving model to nn/Thriller/proc-weights-improvement-46-0.75.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.1239 - acc: 0.9545 - val_loss: 0.6677 - val_acc: 0.7517\n",
      "Epoch 47/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1129 - acc: 0.9588\n",
      "Epoch 00047: saving model to nn/Thriller/proc-weights-improvement-47-0.77.hdf5\n",
      "3362/3362 [==============================] - 5s 2ms/step - loss: 0.1122 - acc: 0.9593 - val_loss: 0.7029 - val_acc: 0.7712\n",
      "Epoch 48/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1055 - acc: 0.9603\n",
      "Epoch 00048: saving model to nn/Thriller/proc-weights-improvement-48-0.76.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1054 - acc: 0.9601 - val_loss: 0.7030 - val_acc: 0.7628\n",
      "Epoch 49/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1019 - acc: 0.9618\n",
      "Epoch 00049: saving model to nn/Thriller/proc-weights-improvement-49-0.77.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1019 - acc: 0.9616 - val_loss: 0.7808 - val_acc: 0.7656\n",
      "Epoch 50/50\n",
      "3328/3362 [============================>.] - ETA: 0s - loss: 0.1018 - acc: 0.9621\n",
      "Epoch 00050: saving model to nn/Thriller/proc-weights-improvement-50-0.76.hdf5\n",
      "3362/3362 [==============================] - 5s 1ms/step - loss: 0.1040 - acc: 0.9610 - val_loss: 0.7253 - val_acc: 0.7573\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional\n",
    "from keras.callbacks import EarlyStopping\n",
    "for category in genres:\n",
    "\n",
    "    print(category)\n",
    "        \n",
    "    filepath= \"nn/\"+category+\"/proc-weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, verbose=1, save_best_only=False, mode='min')\n",
    "    callbacks_list = [checkpoint,EarlyStopping(monitor='val_acc', patience=30, verbose=0, mode='auto')]\n",
    "\n",
    "    y_train_binary = list(map(lambda x: 1 if category in x else 0, y_train))\n",
    "    y_cv_binary = list(map(lambda x: 1 if category in x else 0, y_cv))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(len(word_index) + 1,\n",
    "                                    EMBEDDING_DIM,\n",
    "                                    weights=[embedding_matrix],\n",
    "                                    input_length=MAX_SEQUENCE_LENGTH,\n",
    "                                    trainable=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "\n",
    "    # LetÂ´s set class weights inversely proportionate to class count\n",
    "    #class_weight = dict(map(lambda x: (x[0],1/(x[1]/len(y_train_binary))),Counter(y_train_binary).items()))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    model.fit(X_train_padded, np.asarray(list(map(lambda x: [x],y_train_binary))), \n",
    "#             class_weight=class_weight.\n",
    "              validation_data=(X_cv_padded, np.asarray(list(map(lambda x: [x],y_cv_binary)))),\n",
    "              epochs=50, batch_size=256,callbacks= callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the big differences in training and cv performance... our NN are definetely overfitting. LetÂ´s pick the one with the best performance on the CV set and get some metrics on it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                                EMBEDDING_DIM,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=MAX_SEQUENCE_LENGTH,\n",
    "                                trainable=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_lstm = {}\n",
    "for genre in genres:\n",
    "    filenames = os.listdir(\"./nn/\"+genre)\n",
    "    model.load_weights(\"./nn/\"+genre+\"/\"+filenames[len(filenames)-1])\n",
    "    y_cv_binary_pred = model.predict(X_cv_padded)\n",
    "    \n",
    "    y_cv_binary = list(map(lambda x: 1 if genre in x else 0, y_cv))\n",
    "    f1_lstm[genre] = f1_score(y_cv_binary,list(map(lambda x: 1 if x> 0.5 else 0,y_cv_binary_pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compare the results of the SVM and the LSTM. Note that LSTM outperforms SVM in some cases, whilst SVM predominates in the majority.\n",
    "\n",
    "Time permitting, we could come with some ensemble method.\n",
    "\n",
    "If we had more data, a deep learning model would possibly outperform SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSTM</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Action</th>\n",
       "      <td>0.704050</td>\n",
       "      <td>0.653846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adventure</th>\n",
       "      <td>0.512563</td>\n",
       "      <td>0.538153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comedy</th>\n",
       "      <td>0.654244</td>\n",
       "      <td>0.672932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crime</th>\n",
       "      <td>0.532468</td>\n",
       "      <td>0.552995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drama</th>\n",
       "      <td>0.730924</td>\n",
       "      <td>0.716253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Family</th>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.558442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fantasy</th>\n",
       "      <td>0.413043</td>\n",
       "      <td>0.512397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horror</th>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mystery</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.305882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Others</th>\n",
       "      <td>0.458716</td>\n",
       "      <td>0.541096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Romance</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.540000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Science Fiction</th>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.535433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thriller</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.645161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     LSTM       SVM\n",
       "Action           0.704050  0.653846\n",
       "Adventure        0.512563  0.538153\n",
       "Comedy           0.654244  0.672932\n",
       "Crime            0.532468  0.552995\n",
       "Drama            0.730924  0.716253\n",
       "Family           0.484848  0.558442\n",
       "Fantasy          0.413043  0.512397\n",
       "Horror           0.548387  0.547945\n",
       "Mystery          0.117647  0.305882\n",
       "Others           0.458716  0.541096\n",
       "Romance          0.444444  0.540000\n",
       "Science Fiction  0.518519  0.535433\n",
       "Thriller         0.600000  0.645161"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict({\"SVM\":f1_svm,\"LSTM\":f1_lstm})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we test our model on fresh test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_svm_test = dict(zip(genres,\n",
    "f1_score(y_test_oh,ovr_tfidf_binary_linear_weighted_SVC_reduced_c.predict(X_test),average=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action 0.631884057971 0.653846153846\n",
      "Adventure 0.398058252427 0.538152610442\n",
      "Comedy 0.646586345382 0.672932330827\n",
      "Crime 0.362573099415 0.552995391705\n",
      "Drama 0.68340306834 0.716253443526\n",
      "Family 0.380952380952 0.558441558442\n",
      "Fantasy 0.395604395604 0.512396694215\n",
      "Horror 0.496124031008 0.547945205479\n",
      "Mystery 0.0434782608696 0.305882352941\n",
      "Others 0.379888268156 0.541095890411\n",
      "Romance 0.409523809524 0.54\n",
      "Science Fiction 0.573643410853 0.535433070866\n",
      "Thriller 0.570637119114 0.645161290323\n"
     ]
    }
   ],
   "source": [
    "f1_lstm_test = {}\n",
    "for genre in genres:\n",
    "    filenames = os.listdir(\"./nn/\"+genre)\n",
    "    model.load_weights(\"./nn/\"+genre+\"/\"+filenames[len(filenames)-1])\n",
    "    y_test_binary_pred = model.predict(X_test_padded)\n",
    "    \n",
    "    y_test_binary = list(map(lambda x: 1 if genre in x else 0, y_test))\n",
    "    f1_lstm_test[genre] = f1_score(y_test_binary,list(map(lambda x: 1 if x> 0.5 else 0,y_test_binary_pred)))\n",
    "    print(genre,f1_lstm_test[genre],f1_svm[genre])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 measure - LSTM - test data</th>\n",
       "      <th>F1 measure - SVC - test data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Action</th>\n",
       "      <td>0.631884</td>\n",
       "      <td>0.656250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adventure</th>\n",
       "      <td>0.398058</td>\n",
       "      <td>0.548043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comedy</th>\n",
       "      <td>0.646586</td>\n",
       "      <td>0.691358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crime</th>\n",
       "      <td>0.362573</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drama</th>\n",
       "      <td>0.683403</td>\n",
       "      <td>0.661765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Family</th>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.496454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fantasy</th>\n",
       "      <td>0.395604</td>\n",
       "      <td>0.536585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horror</th>\n",
       "      <td>0.496124</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mystery</th>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.346939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Others</th>\n",
       "      <td>0.379888</td>\n",
       "      <td>0.507246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Romance</th>\n",
       "      <td>0.409524</td>\n",
       "      <td>0.520548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Science Fiction</th>\n",
       "      <td>0.573643</td>\n",
       "      <td>0.532468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thriller</th>\n",
       "      <td>0.570637</td>\n",
       "      <td>0.594203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 F1 measure - LSTM - test data  F1 measure - SVC - test data\n",
       "Action                                0.631884                      0.656250\n",
       "Adventure                             0.398058                      0.548043\n",
       "Comedy                                0.646586                      0.691358\n",
       "Crime                                 0.362573                      0.545455\n",
       "Drama                                 0.683403                      0.661765\n",
       "Family                                0.380952                      0.496454\n",
       "Fantasy                               0.395604                      0.536585\n",
       "Horror                                0.496124                      0.628571\n",
       "Mystery                               0.043478                      0.346939\n",
       "Others                                0.379888                      0.507246\n",
       "Romance                               0.409524                      0.520548\n",
       "Science Fiction                       0.573643                      0.532468\n",
       "Thriller                              0.570637                      0.594203"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict({\"F1 measure - SVC - test data\": f1_svm_test,\n",
    "                        \"F1 measure - LSTM - test data\": f1_lstm_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions and future work\n",
    "\n",
    "The obtained F1 scores are not good enough to rely on this classifier.\n",
    "\n",
    "We have seen that there is  an important overfitting problem while training all the algorithms we have used. We have argued that one way to solve this is by getting more data - potentially from the wikipedia -. The next recipe for  overfitting is using simpler models, or a collection of those. We could also use features with less diversity, such as authors and directors.\n",
    "\n",
    "From an algorithmic point of view, we could keep trying to choose  better combinations by using gridsearch. Knowing that we have overfitting, we would try to use algorithms that are not too complex."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
